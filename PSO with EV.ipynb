{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb66c813",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (3988386910.py, line 554)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 554\u001b[1;36m\u001b[0m\n\u001b[1;33m    stats_text = f\"\"\"\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.cluster import KMeans\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# ==========================\n",
    "# H√ÄM T√çNH TO√ÅN T·ªêC ƒê·ªò & TH·ªúI GIAN\n",
    "# ==========================\n",
    "\n",
    "def compute_vs(p1, p2, v_f, v_AUV):\n",
    "    \"\"\"T√≠nh v·∫≠n t·ªëc t·ªïng h·ª£p v_s gi·ªØa 2 v·ªã tr√≠ p1, p2\"\"\"\n",
    "    x1, y1, z1 = p1\n",
    "    x2, y2, z2 = p2\n",
    "    Lx, Ly, Lz = x2 - x1, y2 - y1, z2 - z1\n",
    "    L_mag = math.sqrt(Lx**2 + Ly**2 + Lz**2)\n",
    "    if L_mag == 0:\n",
    "        return v_AUV\n",
    "    cos_beta = Lz / L_mag\n",
    "    cos_beta = np.clip(cos_beta, -1, 1)\n",
    "    beta = math.acos(cos_beta)\n",
    "    if abs(cos_beta) < 1e-6:\n",
    "        cos_beta = 1e-6\n",
    "    inner = np.clip((v_f * cos_beta) / v_AUV, -1, 1)\n",
    "    angle = beta + math.acos(inner)\n",
    "    v_s = abs(math.cos(angle) * v_AUV / cos_beta)\n",
    "    return v_s\n",
    "\n",
    "\n",
    "def travel_time(path, coords, v_f, v_AUV):\n",
    "    \"\"\"T√≠nh t·ªïng th·ªùi gian di chuy·ªÉn theo ƒë∆∞·ªùng path\"\"\"\n",
    "    total_time = 0.0\n",
    "    for i in range(len(path) - 1):\n",
    "        p1, p2 = coords[path[i]], coords[path[i + 1]]\n",
    "        d = np.linalg.norm(np.array(p2) - np.array(p1))\n",
    "        v_s = compute_vs(tuple(p1), tuple(p2), v_f, v_AUV)\n",
    "        total_time += d / max(v_s, 1e-9)\n",
    "    # quay l·∫°i ƒëi·ªÉm ƒë·∫ßu\n",
    "    p1, p2 = coords[path[-1]], coords[path[0]]\n",
    "    d = np.linalg.norm(np.array(p2) - np.array(p1))\n",
    "    v_s = compute_vs(tuple(p1), tuple(p2), v_f, v_AUV)\n",
    "    total_time += d / max(v_s, 1e-9)\n",
    "    return total_time\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# L·ªöP PSO CHO TSP\n",
    "# ==========================\n",
    "\n",
    "class ClusterTSP_PSO:\n",
    "    def __init__(self, clusters, pso_params=None):\n",
    "        self.clusters = clusters\n",
    "        sorted_keys = sorted(clusters.keys(), key=lambda x: int(x))\n",
    "        self.index_to_ch = [None]\n",
    "        self.cluster_centers = [(0.0, 0.0, 0.0)]\n",
    "        \n",
    "        for k in sorted_keys:\n",
    "            c = clusters[k]['center']\n",
    "            self.cluster_centers.append(tuple(c))\n",
    "            self.index_to_ch.append(clusters[k].get('cluster_head', None))\n",
    "\n",
    "        self.n = len(self.cluster_centers)\n",
    "\n",
    "        defaults = {\n",
    "            'n_particles': 40,\n",
    "            'max_iter': 200,\n",
    "            'w_start': 0.9,\n",
    "            'w_end': 0.4,\n",
    "            'c1': 1.5,\n",
    "            'c2': 1.5,\n",
    "            'v_f': 1.2,\n",
    "            'v_AUV': 3.0,\n",
    "            'verbose': False\n",
    "        }\n",
    "        if pso_params:\n",
    "            defaults.update(pso_params)\n",
    "        self.params = defaults\n",
    "\n",
    "    def create_particle(self):\n",
    "        \"\"\"T·∫°o m·ªôt particle (ƒë∆∞·ªùng ƒëi ng·∫´u nhi√™n)\"\"\"\n",
    "        seq = list(range(1, self.n))\n",
    "        random.shuffle(seq)\n",
    "        return [0] + seq\n",
    "\n",
    "    def get_swap_sequence(self, A, B):\n",
    "        \"\"\"L·∫•y chu·ªói swap ƒë·ªÉ bi·∫øn ƒë·ªïi t·ª´ A sang B\"\"\"\n",
    "        seq = []\n",
    "        temp = A.copy()\n",
    "        for i in range(1, len(A)):\n",
    "            if temp[i] != B[i]:\n",
    "                j = temp.index(B[i])\n",
    "                seq.append((i, j))\n",
    "                temp[i], temp[j] = temp[j], temp[i]\n",
    "        return seq\n",
    "\n",
    "    def apply_velocity(self, position, velocity):\n",
    "        \"\"\"√Åp d·ª•ng velocity (swap operations) l√™n position\"\"\"\n",
    "        new_pos = position.copy()\n",
    "        for (i, j) in velocity:\n",
    "            if i == 0 or j == 0:\n",
    "                continue\n",
    "            new_pos[i], new_pos[j] = new_pos[j], new_pos[i]\n",
    "        return new_pos\n",
    "\n",
    "    def fitness(self, particle):\n",
    "        \"\"\"T√≠nh fitness (1/time)\"\"\"\n",
    "        t = travel_time(particle, self.cluster_centers, \n",
    "                       self.params['v_f'], self.params['v_AUV'])\n",
    "        return 1.0 / (t + 1e-9)\n",
    "\n",
    "    def evolve(self):\n",
    "        \"\"\"Thu·∫≠t to√°n PSO ch√≠nh\"\"\"\n",
    "        n_particles = self.params['n_particles']\n",
    "        max_iter = self.params['max_iter']\n",
    "        w_start = self.params['w_start']\n",
    "        w_end = self.params['w_end']\n",
    "        c1 = self.params['c1']\n",
    "        c2 = self.params['c2']\n",
    "\n",
    "        # Kh·ªüi t·∫°o swarm\n",
    "        swarm = [self.create_particle() for _ in range(n_particles)]\n",
    "        velocities = [[] for _ in range(n_particles)]\n",
    "\n",
    "        # T√≠nh fitness ban ƒë·∫ßu\n",
    "        costs = [travel_time(p, self.cluster_centers, \n",
    "                           self.params['v_f'], self.params['v_AUV']) \n",
    "                for p in swarm]\n",
    "        \n",
    "        # Personal best\n",
    "        pbest = [p.copy() for p in swarm]\n",
    "        pbest_cost = list(costs)\n",
    "\n",
    "        # Global best\n",
    "        gbest_idx = np.argmin(pbest_cost)\n",
    "        gbest = pbest[gbest_idx].copy()\n",
    "        gbest_cost = pbest_cost[gbest_idx]\n",
    "\n",
    "        # V√≤ng l·∫∑p ch√≠nh\n",
    "        for t in range(max_iter):\n",
    "            # C·∫≠p nh·∫≠t h·ªá s·ªë qu√°n t√≠nh\n",
    "            w = w_start - (w_start - w_end) * (t / max_iter)\n",
    "\n",
    "            for i in range(n_particles):\n",
    "                xi = swarm[i]\n",
    "                vi = velocities[i]\n",
    "\n",
    "                # T·∫°o velocity m·ªõi\n",
    "                v_new = []\n",
    "                \n",
    "                # Ph·∫ßn qu√°n t√≠nh\n",
    "                n_keep = int(w * len(vi))\n",
    "                v_new.extend(vi[:n_keep])\n",
    "\n",
    "                # Ph·∫ßn cognitive (h∆∞·ªõng v·ªÅ pbest)\n",
    "                if random.random() < c1:\n",
    "                    seq_pb = self.get_swap_sequence(xi, pbest[i])\n",
    "                    if seq_pb:\n",
    "                        n_select = max(1, int(c1 * len(seq_pb)))\n",
    "                        v_new.extend(random.sample(seq_pb, k=min(len(seq_pb), n_select)))\n",
    "\n",
    "                # Ph·∫ßn social (h∆∞·ªõng v·ªÅ gbest)\n",
    "                if random.random() < c2:\n",
    "                    seq_gb = self.get_swap_sequence(xi, gbest)\n",
    "                    if seq_gb:\n",
    "                        n_select = max(1, int(c2 * len(seq_gb)))\n",
    "                        v_new.extend(random.sample(seq_gb, k=min(len(seq_gb), n_select)))\n",
    "\n",
    "                # C·∫≠p nh·∫≠t velocity v√† position\n",
    "                velocities[i] = v_new\n",
    "                new_x = self.apply_velocity(xi, v_new)\n",
    "                swarm[i] = new_x\n",
    "\n",
    "                # T√≠nh cost m·ªõi\n",
    "                new_cost = travel_time(new_x, self.cluster_centers, \n",
    "                                     self.params['v_f'], self.params['v_AUV'])\n",
    "\n",
    "                # C·∫≠p nh·∫≠t pbest\n",
    "                if new_cost < pbest_cost[i]:\n",
    "                    pbest[i] = new_x.copy()\n",
    "                    pbest_cost[i] = new_cost\n",
    "\n",
    "                    # C·∫≠p nh·∫≠t gbest\n",
    "                    if new_cost < gbest_cost:\n",
    "                        gbest = new_x.copy()\n",
    "                        gbest_cost = new_cost\n",
    "\n",
    "            if self.params['verbose'] and t % 20 == 0:\n",
    "                print(f\"  Iteration {t}: Best time = {gbest_cost:.4f}s\")\n",
    "\n",
    "        # Map indices sang cluster_head IDs\n",
    "        mapped_path = ['O' if idx == 0 else self.index_to_ch[idx] for idx in gbest]\n",
    "        \n",
    "        return gbest, mapped_path, gbest_cost\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# H√ÄM NƒÇNG L∆Ø·ª¢NG\n",
    "# ==========================\n",
    "\n",
    "def compute_energy(best_time):\n",
    "    G, L, n = 100, 1024, 4\n",
    "    P_t, P_r, P_idle, DR, DR_i = 1.6e-3, 0.8e-3, 0.1e-3, 4000, 1e6\n",
    "    E_tx_MN = G * P_t * L / DR\n",
    "    E_idle_MN = (best_time - G * L / DR) * P_idle\n",
    "    E_total_MN = E_tx_MN + E_idle_MN\n",
    "    E_rx_TN = G * P_r * L * n / DR\n",
    "    E_tx_TN = G * P_t * L * n / DR_i\n",
    "    E_idle_TN = (best_time - (G * L * n / DR) - (G * L * n / DR_i)) * P_idle\n",
    "    E_total_TN = E_rx_TN + E_tx_TN + E_idle_TN\n",
    "    E_idle_solo = (best_time - (G * L * n / DR_i)) * P_idle\n",
    "    E_total_SOLO = E_tx_TN + E_idle_solo\n",
    "    return {\n",
    "        \"Member\": {\"E_tx\": E_tx_MN, \"E_idle\": E_idle_MN, \"E_total\": E_total_MN},\n",
    "        \"Target\": {\"E_rx\": E_rx_TN, \"E_tx\": E_tx_TN, \"E_idle\": E_idle_TN, \"E_total\": E_total_TN},\n",
    "        \"Solo\": {\"E_tx\": E_tx_TN, \"E_idle\": E_idle_solo, \"E_total\": E_total_SOLO}\n",
    "    }\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# H√ÄM PH√ÇN C·ª§M\n",
    "# ==========================\n",
    "\n",
    "def calculate_objective_function(nodes, labels, centers):\n",
    "    numerator = 0\n",
    "    for i in range(2):\n",
    "        cluster_nodes = nodes[labels == i]\n",
    "        if len(cluster_nodes) > 0:\n",
    "            distances = np.linalg.norm(cluster_nodes - centers[i], axis=1)\n",
    "            numerator += np.sum(distances)\n",
    "    denominator = np.linalg.norm(centers[0] - centers[1])\n",
    "    if denominator == 0:\n",
    "        return float('inf')\n",
    "    return numerator / denominator\n",
    "\n",
    "\n",
    "def check_subgroup_threshold(nodes, r_sen):\n",
    "    if len(nodes) <= 1:\n",
    "        return True\n",
    "    max_distance = 0\n",
    "    for i in range(len(nodes)):\n",
    "        for j in range(i + 1, len(nodes)):\n",
    "            dist = np.linalg.norm(nodes[i] - nodes[j])\n",
    "            max_distance = max(max_distance, dist)\n",
    "    return max_distance <= r_sen\n",
    "\n",
    "\n",
    "def kmeans_with_best_T(nodes, N=30):\n",
    "    best_T = float('inf')\n",
    "    best_labels = None\n",
    "    best_centers = None\n",
    "    for _ in range(N):\n",
    "        kmeans = KMeans(n_clusters=2, n_init=1)\n",
    "        labels = kmeans.fit_predict(nodes)\n",
    "        centers = kmeans.cluster_centers_\n",
    "        T = calculate_objective_function(nodes, labels, centers)\n",
    "        if T < best_T:\n",
    "            best_T = T\n",
    "            best_labels = labels.copy()\n",
    "            best_centers = centers.copy()\n",
    "    return best_labels, best_centers, best_T\n",
    "\n",
    "\n",
    "def cluster_split(nodes, node_ids, node_data=None, r_sen=60, R=20, N=30, max_depth=10, depth=0):\n",
    "    size_ok = len(nodes) <= R\n",
    "    distance_ok = check_subgroup_threshold(nodes, r_sen)\n",
    "    \n",
    "    if (size_ok and distance_ok) or depth >= max_depth:\n",
    "        center = np.mean(nodes, axis=0)\n",
    "        return [{\n",
    "            \"node_ids\": node_ids,\n",
    "            \"nodes\": nodes,\n",
    "            \"center\": center,\n",
    "            \"node_data\": node_data if node_data else {}\n",
    "        }]\n",
    "    \n",
    "    labels, centers, best_T = kmeans_with_best_T(nodes, N)\n",
    "    clusters = []\n",
    "    for i in range(2):\n",
    "        sub_nodes = nodes[labels == i]\n",
    "        sub_ids = [node_ids[j] for j in range(len(node_ids)) if labels[j] == i]\n",
    "        sub_node_data = {}\n",
    "        if node_data:\n",
    "            for node_id in sub_ids:\n",
    "                if node_id in node_data:\n",
    "                    sub_node_data[node_id] = node_data[node_id]\n",
    "        clusters += cluster_split(sub_nodes, sub_ids, sub_node_data, r_sen, R, N, max_depth, depth + 1)\n",
    "    return clusters\n",
    "\n",
    "\n",
    "def choose_cluster_head(cluster_info, node_data=None):\n",
    "    nodes = cluster_info[\"nodes\"]\n",
    "    center = cluster_info[\"center\"]\n",
    "    node_ids = cluster_info[\"node_ids\"]\n",
    "    \n",
    "    if node_data and len(node_data) > 0:\n",
    "        max_energy = -1\n",
    "        ch_id = node_ids[0]\n",
    "        for nid in node_ids:\n",
    "            if nid in node_data and \"residual_energy\" in node_data[nid]:\n",
    "                if node_data[nid][\"residual_energy\"] > max_energy:\n",
    "                    max_energy = node_data[nid][\"residual_energy\"]\n",
    "                    ch_id = nid\n",
    "        return ch_id\n",
    "    else:\n",
    "        distances = np.linalg.norm(nodes - center, axis=1)\n",
    "        min_idx = np.argmin(distances)\n",
    "        return node_ids[min_idx]\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# H√ÄM QU·∫¢N L√ù NƒÇNG L∆Ø·ª¢NG\n",
    "# ==========================\n",
    "\n",
    "def update_energy(all_nodes, clusters, energy_report):\n",
    "    for cid, cinfo in clusters.items():\n",
    "        nodes = cinfo.get('nodes', [])\n",
    "        ch = cinfo.get('cluster_head')\n",
    "        \n",
    "        if len(nodes) == 1:\n",
    "            nid = nodes[0]\n",
    "            if nid in all_nodes:\n",
    "                all_nodes[nid]['residual_energy'] -= energy_report['Solo']['E_total']\n",
    "                if all_nodes[nid]['residual_energy'] < 0:\n",
    "                    all_nodes[nid]['residual_energy'] = 0.0\n",
    "        else:\n",
    "            for nid in nodes:\n",
    "                if nid not in all_nodes:\n",
    "                    continue\n",
    "                if nid == ch:\n",
    "                    all_nodes[nid]['residual_energy'] -= energy_report['Target']['E_total']\n",
    "                else:\n",
    "                    all_nodes[nid]['residual_energy'] -= energy_report['Member']['E_total']\n",
    "                if all_nodes[nid]['residual_energy'] < 0:\n",
    "                    all_nodes[nid]['residual_energy'] = 0.0\n",
    "\n",
    "\n",
    "def remove_dead_nodes(all_nodes, clusters):\n",
    "    dead = [nid for nid, info in list(all_nodes.items()) if info['residual_energy'] <= 0]\n",
    "    for nid in dead:\n",
    "        del all_nodes[nid]\n",
    "    new_clusters = {}\n",
    "    for cid, cinfo in clusters.items():\n",
    "        alive_nodes = [nid for nid in cinfo.get('nodes', []) if nid in all_nodes]\n",
    "        if alive_nodes:\n",
    "            new_c = dict(cinfo)\n",
    "            new_c['nodes'] = alive_nodes\n",
    "            new_clusters[cid] = new_c\n",
    "    return new_clusters, dead\n",
    "\n",
    "\n",
    "def recluster(all_nodes, node_positions, r_sen=50, R=20):\n",
    "    ids = sorted(list(all_nodes.keys()))\n",
    "    if len(ids) == 0:\n",
    "        return {}\n",
    "    coords = np.array([node_positions[nid] for nid in ids])\n",
    "    raw_clusters = cluster_split(coords, ids, all_nodes, r_sen=r_sen, R=R)\n",
    "    clusters = {}\n",
    "    for i, c in enumerate(raw_clusters):\n",
    "        center = c['center'].tolist()\n",
    "        node_ids = c['node_ids']\n",
    "        ch = choose_cluster_head(c, all_nodes)\n",
    "        clusters[i] = {'nodes': node_ids, 'center': center, 'cluster_head': ch}\n",
    "    return clusters\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# H√ÄM V·∫º BI·ªÇU ƒê·ªí REAL-TIME\n",
    "# ==========================\n",
    "\n",
    "def plot_realtime_analysis(outputs, total_nodes, INITIAL_ENERGY, filename, output_dir, cycle):\n",
    "    \"\"\"V·∫Ω bi·ªÉu ƒë·ªì theo th·ªùi gian th·ª±c sau m·ªói chu k·ª≥\"\"\"\n",
    "    if len(outputs) == 0:\n",
    "        return\n",
    "    \n",
    "    cycles = [o['cycle'] for o in outputs]\n",
    "    alive_nodes = [o['alive_nodes'] for o in outputs]\n",
    "    cumulative_dead = [total_nodes - a for a in alive_nodes]\n",
    "    total_energy_remaining = [o['total_energy_remaining'] for o in outputs]\n",
    "    travel_times = [o['best_time'] for o in outputs]\n",
    "    \n",
    "    first_death_cycle = None\n",
    "    for o in outputs:\n",
    "        if o['dead_nodes']:\n",
    "            first_death_cycle = o['cycle']\n",
    "            break\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle(f'Real-time Monitoring (PSO) - {filename} (Chu k·ª≥ {cycle})', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Bi·ªÉu ƒë·ªì 1: S·ªë node s·ªëng\n",
    "    axes[0, 0].plot(cycles, alive_nodes, 'b-o', linewidth=2, markersize=6)\n",
    "    axes[0, 0].axhline(y=total_nodes * 0.9, color='r', linestyle='--', \n",
    "                       label=f'Ng∆∞·ª°ng 90% ({int(total_nodes * 0.9)} nodes)')\n",
    "    axes[0, 0].set_xlabel('Chu k·ª≥', fontsize=12)\n",
    "    axes[0, 0].set_ylabel('S·ªë node s·ªëng', fontsize=12)\n",
    "    axes[0, 0].set_title('S·ªë node s·ªëng theo th·ªùi gian', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].set_ylim(bottom=0, top=total_nodes * 1.1)\n",
    "    \n",
    "    # Bi·ªÉu ƒë·ªì 2: S·ªë node ch·∫øt t√≠ch l≈©y\n",
    "    axes[0, 1].plot(cycles, cumulative_dead, 'r-s', linewidth=2, markersize=6)\n",
    "    axes[0, 1].set_xlabel('Chu k·ª≥', fontsize=12)\n",
    "    axes[0, 1].set_ylabel('S·ªë node ch·∫øt (t√≠ch l≈©y)', fontsize=12)\n",
    "    axes[0, 1].set_title('S·ªë node ch·∫øt t√≠ch l≈©y theo th·ªùi gian', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    axes[0, 1].set_ylim(bottom=0)\n",
    "    \n",
    "    if first_death_cycle:\n",
    "        axes[0, 1].axvline(x=first_death_cycle, color='orange', linestyle='--', \n",
    "                          label=f'Chu k·ª≥ ƒë·∫ßu ti√™n: {first_death_cycle}')\n",
    "        axes[0, 1].legend()\n",
    "    \n",
    "    # Bi·ªÉu ƒë·ªì 3: T·ªïng nƒÉng l∆∞·ª£ng m·∫°ng\n",
    "    axes[1, 0].plot(cycles, total_energy_remaining, 'g-^', linewidth=2, markersize=6)\n",
    "    axes[1, 0].set_xlabel('Chu k·ª≥', fontsize=12)\n",
    "    axes[1, 0].set_ylabel('T·ªïng nƒÉng l∆∞·ª£ng c√≤n l·∫°i (J)', fontsize=12)\n",
    "    axes[1, 0].set_title('NƒÉng l∆∞·ª£ng t·ªïng th·ªÉ m·∫°ng', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    axes[1, 0].set_ylim(bottom=0)\n",
    "    \n",
    "    # Bi·ªÉu ƒë·ªì 4: Th·ªùi gian di chuy·ªÉn AUV\n",
    "    axes[1, 1].plot(cycles, travel_times, 'm-d', linewidth=2, markersize=6)\n",
    "    axes[1, 1].set_xlabel('Chu k·ª≥', fontsize=12)\n",
    "    axes[1, 1].set_ylabel('Th·ªùi gian di chuy·ªÉn (s)', fontsize=12)\n",
    "    axes[1, 1].set_title('Th·ªùi gian chu k·ª≥ AUV', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    if len(travel_times) > 0:\n",
    "        avg_time = np.mean(travel_times)\n",
    "        axes[1, 1].axhline(y=avg_time, color='r', linestyle='--', \n",
    "                          label=f'TB: {avg_time:.2f}s')\n",
    "        axes[1, 1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    latest_filename = os.path.join(output_dir, \n",
    "                                   f\"realtime_pso_latest_{os.path.splitext(filename)[0]}.png\")\n",
    "    \n",
    "    plt.savefig(latest_filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return latest_filename\n",
    "\n",
    "\n",
    "def save_realtime_results(outputs, meta_info, output_file):\n",
    "    \"\"\"L∆∞u k·∫øt qu·∫£ theo th·ªùi gian th·ª±c\"\"\"\n",
    "    meta_info['outputs'] = outputs\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(meta_info, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "\n",
    "def plot_final_analysis(outputs, total_nodes, INITIAL_ENERGY, filename, output_dir):\n",
    "    \"\"\"V·∫Ω bi·ªÉu ƒë·ªì t·ªïng h·ª£p chi ti·∫øt cu·ªëi c√πng\"\"\"\n",
    "    if len(outputs) == 0:\n",
    "        return None\n",
    "    \n",
    "    cycles = [o['cycle'] for o in outputs]\n",
    "    alive_nodes = [o['alive_nodes'] for o in outputs]\n",
    "    cumulative_dead = [total_nodes - a for a in alive_nodes]\n",
    "    total_energy_remaining = [o['total_energy_remaining'] for o in outputs]\n",
    "    travel_times = [o['best_time'] for o in outputs]\n",
    "    num_clusters = [o['num_clusters'] for o in outputs]\n",
    "    \n",
    "    first_death_cycle = None\n",
    "    for o in outputs:\n",
    "        if o['dead_nodes']:\n",
    "            first_death_cycle = o['cycle']\n",
    "            break\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 12))\n",
    "    gs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    fig.suptitle(f'Ph√¢n t√≠ch t·ªïng h·ª£p (PSO) - {filename} ({len(outputs)} chu k·ª≥)', \n",
    "                 fontsize=18, fontweight='bold', y=0.995)\n",
    "    \n",
    "    # Bi·ªÉu ƒë·ªì 1: S·ªë node s·ªëng\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax1.plot(cycles, alive_nodes, 'b-o', linewidth=2, markersize=5)\n",
    "    ax1.axhline(y=total_nodes * 0.9, color='r', linestyle='--', \n",
    "                label=f'Ng∆∞·ª°ng 90% ({int(total_nodes * 0.9)} nodes)')\n",
    "    ax1.fill_between(cycles, 0, alive_nodes, alpha=0.3, color='blue')\n",
    "    ax1.set_xlabel('Chu k·ª≥', fontsize=11)\n",
    "    ax1.set_ylabel('S·ªë node s·ªëng', fontsize=11)\n",
    "    ax1.set_title('S·ªë node s·ªëng theo th·ªùi gian', fontsize=13, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.legend()\n",
    "    ax1.set_ylim(bottom=0, top=total_nodes * 1.1)\n",
    "    \n",
    "    # Bi·ªÉu ƒë·ªì 2: S·ªë node ch·∫øt t√≠ch l≈©y\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax2.plot(cycles, cumulative_dead, 'r-s', linewidth=2, markersize=5)\n",
    "    ax2.fill_between(cycles, 0, cumulative_dead, alpha=0.3, color='red')\n",
    "    ax2.set_xlabel('Chu k·ª≥', fontsize=11)\n",
    "    ax2.set_ylabel('S·ªë node ch·∫øt (t√≠ch l≈©y)', fontsize=11)\n",
    "    ax2.set_title('S·ªë node ch·∫øt t√≠ch l≈©y theo th·ªùi gian', fontsize=13, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_ylim(bottom=0)\n",
    "    \n",
    "    if first_death_cycle:\n",
    "        ax2.axvline(x=first_death_cycle, color='orange', linestyle='--', linewidth=2,\n",
    "                   label=f'Chu k·ª≥ ƒë·∫ßu ti√™n: {first_death_cycle}')\n",
    "        ax2.legend()\n",
    "    \n",
    "    # Bi·ªÉu ƒë·ªì 3: T·ªïng nƒÉng l∆∞·ª£ng m·∫°ng\n",
    "    ax3 = fig.add_subplot(gs[1, 0])\n",
    "    ax3.plot(cycles, total_energy_remaining, 'g-^', linewidth=2, markersize=5)\n",
    "    ax3.fill_between(cycles, 0, total_energy_remaining, alpha=0.3, color='green')\n",
    "    ax3.set_xlabel('Chu k·ª≥', fontsize=11)\n",
    "    ax3.set_ylabel('T·ªïng nƒÉng l∆∞·ª£ng c√≤n l·∫°i (J)', fontsize=11)\n",
    "    ax3.set_title('NƒÉng l∆∞·ª£ng t·ªïng th·ªÉ m·∫°ng', fontsize=13, fontweight='bold')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.set_ylim(bottom=0)\n",
    "    \n",
    "    # Bi·ªÉu ƒë·ªì 4: Th·ªùi gian di chuy·ªÉn AUV\n",
    "    ax4 = fig.add_subplot(gs[1, 1])\n",
    "    ax4.plot(cycles, travel_times, 'm-d', linewidth=2, markersize=5)\n",
    "    ax4.set_xlabel('Chu k·ª≥', fontsize=11)\n",
    "    ax4.set_ylabel('Th·ªùi gian di chuy·ªÉn (s)', fontsize=11)\n",
    "    ax4.set_title('Th·ªùi gian chu k·ª≥ AUV', fontsize=13, fontweight='bold')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    if len(travel_times) > 0:\n",
    "        avg_time = np.mean(travel_times)\n",
    "        ax4.axhline(y=avg_time, color='r', linestyle='--', linewidth=2,\n",
    "                   label=f'Trung b√¨nh: {avg_time:.2f}s')\n",
    "        ax4.legend()\n",
    "    \n",
    "    # Bi·ªÉu ƒë·ªì 5: S·ªë c·ª•m theo chu k·ª≥\n",
    "    ax5 = fig.add_subplot(gs[2, 0])\n",
    "    ax5.plot(cycles, num_clusters, 'c-o', linewidth=2, markersize=5)\n",
    "    ax5.fill_between(cycles, 0, num_clusters, alpha=0.3, color='cyan')\n",
    "    ax5.set_xlabel('Chu k·ª≥', fontsize=11)\n",
    "    ax5.set_ylabel('S·ªë c·ª•m', fontsize=11)\n",
    "    ax5.set_title('S·ªë c·ª•m theo chu k·ª≥', fontsize=13, fontweight='bold')\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    ax5.set_ylim(bottom=0)\n",
    "    \n",
    "    # Bi·ªÉu ƒë·ªì 6: Th·ªëng k√™ t·ªïng h·ª£p\n",
    "    ax6 = fig.add_subplot(gs[2, 1])\n",
    "    ax6.axis('off')\n",
    "    \n",
    "    total_cycles = len(outputs)\n",
    "    total_time = outputs[-1]['cumulative_time']\n",
    "    avg_cycle_time = np.mean(travel_times)\n",
    "    total_deaths = total_nodes - alive_nodes[-1]\n",
    "    survival_rate = (alive_nodes[-1] / total_nodes) * 100\n",
    "    \n",
    "    stats_text = f\"\"\"\n",
    "    TH·ªêNG K√ä T·ªîNG H·ª¢P (PSO)\n",
    "    {'‚îÄ' * 40}\n",
    "    \n",
    "    T·ªïng s·ªë chu k·ª≥: {total_cycles}\n",
    "    T·ªïng th·ªùi gian: {total_time:.2f}s ({total_time/3600:.2f} gi·ªù)\n",
    "    Th·ªùi gian TB/chu k·ª≥: {avg_cycle_time:.2f}s\n",
    "    \n",
    "    Node ban ƒë·∫ßu: {total_nodes}\n",
    "    Node c√≤n s·ªëng: {alive_nodes[-1]}\n",
    "    Node ƒë√£ ch·∫øt: {total_deaths}\n",
    "    T·ª∑ l·ªá s·ªëng s√≥t: {survival_rate:.2f}%\n",
    "    \n",
    "    Chu k·ª≥ ch·∫øt ƒë·∫ßu ti√™n: {first_death_cycle if first_death_cycle else 'N/A'}\n",
    "    \n",
    "    S·ªë c·ª•m trung b√¨nh: {np.mean(num_clusters):.1f}\n",
    "    S·ªë c·ª•m min/max: {np.min(num_clusters)}/{np.max(num_clusters)}\n",
    "    \n",
    "    Th·ªùi gian chu k·ª≥ min: {np.min(travel_times):.2f}s\n",
    "    Th·ªùi gian chu k·ª≥ max: {np.max(travel_times):.2f}s\n",
    "    ƒê·ªô l·ªách chu·∫©n: {np.std(travel_times):.2f}s\n",
    "    \"\"\"\n",
    "    \n",
    "    ax6.text(0.1, 0.5, stats_text, fontsize=11, family='monospace',\n",
    "             verticalalignment='center', bbox=dict(boxstyle='round', \n",
    "             facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    final_chart_filename = os.path.join(output_dir, \n",
    "                                        f\"final_analysis_pso_{os.path.splitext(filename)[0]}.png\")\n",
    "    plt.savefig(final_chart_filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return final_chart_filename\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# MAIN v·ªõi Real-time Monitoring (PSO)\n",
    "# ==========================\n",
    "\n",
    "def main():\n",
    "    input_dir = \"/kaggle/input/input-cluster3/output_data_kmeans\"\n",
    "    output_dir = \"/kaggle/working/output_pso_multicycle\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    files = [f for f in os.listdir(input_dir) if f.endswith('.json')]\n",
    "\n",
    "    # Tham s·ªë PSO\n",
    "    pso_params = {\n",
    "        'n_particles': 40,\n",
    "        'max_iter': 200,\n",
    "        'w_start': 0.9,\n",
    "        'w_end': 0.4,\n",
    "        'c1': 1.5,\n",
    "        'c2': 1.5,\n",
    "        'v_f': 1.2,\n",
    "        'v_AUV': 3.0,\n",
    "        'verbose': False\n",
    "    }\n",
    "\n",
    "    INITIAL_ENERGY = 100.0\n",
    "\n",
    "    for filename in files:\n",
    "        input_path = os.path.join(input_dir, filename)\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"ƒêANG X·ª¨ L√ù FILE: {filename}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        with open(input_path, 'r') as f:\n",
    "            clusters_in = json.load(f)\n",
    "\n",
    "        node_positions = {}\n",
    "        all_nodes = {}\n",
    "\n",
    "        # Collect all node ids\n",
    "        all_node_ids = set()\n",
    "        for k, v in clusters_in.items():\n",
    "            for nid in v.get('nodes', []):\n",
    "                all_node_ids.add(nid)\n",
    "            ch = v.get('cluster_head')\n",
    "            if ch is not None:\n",
    "                all_node_ids.add(ch)\n",
    "\n",
    "        # Load node positions\n",
    "        nodes_pos_file = \"/kaggle/input/input-pos3/input_data_evenly_distributed/nodes_150.json\"\n",
    "        if os.path.exists(nodes_pos_file):\n",
    "            try:\n",
    "                with open(nodes_pos_file, 'r', encoding='utf-8') as f:\n",
    "                    nodes_data = json.load(f)\n",
    "                \n",
    "                node_positions = {}\n",
    "                for node in nodes_data:\n",
    "                    node_id = node['id']\n",
    "                    node_positions[node_id] = (node['x'], node['y'], node['z'])\n",
    "                \n",
    "                print(f\"‚úì ƒê√£ load {len(node_positions)} node positions t·ª´ {os.path.basename(nodes_pos_file)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚úó L·ªói khi ƒë·ªçc file v·ªã tr√≠: {e}\")\n",
    "\n",
    "        # Create approximate positions if needed\n",
    "        if not node_positions:\n",
    "            for k, v in clusters_in.items():\n",
    "                center = tuple(v.get('center', (0.0, 0.0, 0.0)))\n",
    "                for nid in v.get('nodes', []):\n",
    "                    offset = np.random.normal(scale=5.0, size=3)\n",
    "                    node_positions[nid] = tuple(np.array(center) + offset)\n",
    "                ch = v.get('cluster_head')\n",
    "                if ch is not None and ch not in node_positions:\n",
    "                    node_positions[ch] = center\n",
    "            print(\"‚ö† ƒê√£ t·∫°o v·ªã tr√≠ gi·∫£ l·∫≠p cho c√°c nodes\")\n",
    "\n",
    "        # Initialize energy\n",
    "        for nid in list(all_node_ids):\n",
    "            all_nodes[nid] = {\n",
    "                'initial_energy': INITIAL_ENERGY, \n",
    "                'residual_energy': INITIAL_ENERGY\n",
    "            }\n",
    "\n",
    "        total_nodes = len(all_nodes)\n",
    "        print(f\"‚úì T·ªïng s·ªë node ban ƒë·∫ßu: {total_nodes}\")\n",
    "\n",
    "        # Initialize clusters\n",
    "        clusters = {}\n",
    "        for k, v in clusters_in.items():\n",
    "            clusters[int(k)] = {\n",
    "                'nodes': v.get('nodes', []), \n",
    "                'center': v.get('center', []), \n",
    "                'cluster_head': v.get('cluster_head')\n",
    "            }\n",
    "\n",
    "        # Prepare output file\n",
    "        out_filename = os.path.join(output_dir, \n",
    "                                    f\"multicycle_pso_result_{os.path.splitext(filename)[0]}.json\")\n",
    "        \n",
    "        # Meta info\n",
    "        meta_info = {\n",
    "            'algorithm': 'PSO',\n",
    "            'input_file': filename,\n",
    "            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'initial_total_nodes': total_nodes,\n",
    "            'pso_params': pso_params,\n",
    "            'cycles': 0,\n",
    "            'total_operation_time': 0.0,\n",
    "            'first_death_cycle': None,\n",
    "            'first_death_time': None,\n",
    "            'final_alive_nodes': 0,\n",
    "            'survival_rate': 0.0\n",
    "        }\n",
    "\n",
    "        cycle = 0\n",
    "        outputs = []\n",
    "        cumulative_time = 0.0\n",
    "        first_death_cycle = None\n",
    "        first_death_time = None\n",
    "\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"B·∫ÆT ƒê·∫¶U M√î PH·ªéNG CHU K·ª≤ (PSO)\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "\n",
    "        # Main simulation loop\n",
    "        while True:\n",
    "            cycle += 1\n",
    "            print(f\"\\n{'‚îÄ'*70}\")\n",
    "            print(f\"CHU K·ª≤ {cycle}\")\n",
    "            print(f\"{'‚îÄ'*70}\")\n",
    "\n",
    "            alive_ratio = len(all_nodes) / total_nodes if total_nodes > 0 else 0\n",
    "            print(f\"T·ªâ l·ªá node s·ªëng: {alive_ratio*100:.2f}% ({len(all_nodes)}/{total_nodes})\")\n",
    "            \n",
    "            if alive_ratio < 0.9:\n",
    "                print(\"\\n‚ö† D·ª™NG: T·ªâ l·ªá node s·ªëng < 90%\")\n",
    "                break\n",
    "\n",
    "            if len(clusters) == 0:\n",
    "                print(\"\\n‚ö† D·ª™NG: Kh√¥ng c√≤n c·ª•m n√†o\")\n",
    "                break\n",
    "\n",
    "            # Run PSO\n",
    "            print(f\"ƒêang ch·∫°y PSO v·ªõi {len(clusters)} c·ª•m...\", end=\" \")\n",
    "            pso = ClusterTSP_PSO(clusters, pso_params)\n",
    "            best_indices, best_mapped_path, best_time = pso.evolve()\n",
    "            print(\"‚úì\")\n",
    "\n",
    "            cumulative_time += best_time\n",
    "            energy_report = compute_energy(best_time)\n",
    "\n",
    "            # Update energies\n",
    "            update_energy(all_nodes, clusters, energy_report)\n",
    "\n",
    "            # Remove dead nodes\n",
    "            clusters, dead_nodes = remove_dead_nodes(all_nodes, clusters)\n",
    "            for d in dead_nodes:\n",
    "                if d in node_positions:\n",
    "                    del node_positions[d]\n",
    "\n",
    "            # Calculate total energy\n",
    "            total_energy_remaining = sum(node['residual_energy'] for node in all_nodes.values())\n",
    "\n",
    "            # Track first death\n",
    "            if dead_nodes and first_death_cycle is None:\n",
    "                first_death_cycle = cycle\n",
    "                first_death_time = cumulative_time\n",
    "\n",
    "            # Log output\n",
    "            output_entry = {\n",
    "                'cycle': cycle,\n",
    "                'num_clusters': len(clusters),\n",
    "                'best_path_indices': best_indices,\n",
    "                'best_path_node_ids': best_mapped_path,\n",
    "                'best_time': best_time,\n",
    "                'cumulative_time': cumulative_time,\n",
    "                'dead_nodes': dead_nodes,\n",
    "                'alive_nodes': len(all_nodes),\n",
    "                'total_energy_remaining': total_energy_remaining\n",
    "            }\n",
    "            outputs.append(output_entry)\n",
    "\n",
    "            # Print cycle summary\n",
    "            print(f\"‚îú‚îÄ S·ªë c·ª•m: {len(clusters)}\")\n",
    "            print(f\"‚îú‚îÄ ƒê∆∞·ªùng ƒëi: {best_mapped_path}\")\n",
    "            print(f\"‚îú‚îÄ Th·ªùi gian chu k·ª≥: {best_time:.2f}s\")\n",
    "            print(f\"‚îú‚îÄ Th·ªùi gian t√≠ch l≈©y: {cumulative_time:.2f}s ({cumulative_time/3600:.2f}h)\")\n",
    "            print(f\"‚îú‚îÄ NƒÉng l∆∞·ª£ng c√≤n l·∫°i: {total_energy_remaining:.2f}J\")\n",
    "            \n",
    "            if dead_nodes:\n",
    "                print(f\"‚îî‚îÄ ‚ö† Node ch·∫øt: {len(dead_nodes)} node(s) - {dead_nodes}\")\n",
    "            else:\n",
    "                print(f\"‚îî‚îÄ ‚úì Kh√¥ng c√≥ node ch·∫øt\")\n",
    "\n",
    "            # ===== REAL-TIME UPDATES =====\n",
    "            \n",
    "            # 1. Save results to file\n",
    "            meta_info.update({\n",
    "                'cycles': cycle,\n",
    "                'total_operation_time': cumulative_time,\n",
    "                'first_death_cycle': first_death_cycle,\n",
    "                'first_death_time': first_death_time,\n",
    "                'final_alive_nodes': len(all_nodes),\n",
    "                'survival_rate': (len(all_nodes)/total_nodes)*100\n",
    "            })\n",
    "            save_realtime_results(outputs, meta_info, out_filename)\n",
    "            \n",
    "            # 2. Plot real-time chart\n",
    "            last_filename = plot_realtime_analysis(\n",
    "                outputs, total_nodes, INITIAL_ENERGY, filename, output_dir, cycle\n",
    "            )\n",
    "            display(Image(filename=last_filename))\n",
    "\n",
    "            # Recluster if nodes still alive\n",
    "            if len(all_nodes) > 0:\n",
    "                clusters = recluster(all_nodes, node_positions)\n",
    "                for k, v in clusters.items():\n",
    "                    clusters[k]['center'] = [float(x) for x in v['center']]\n",
    "\n",
    "        # ===== K·∫æT TH√öC M√î PH·ªéNG =====\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"PH√ÇN T√çCH K·∫æT QU·∫¢ CU·ªêI C√ôNG (PSO)\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"T·ªïng s·ªë chu k·ª≥: {cycle - 1}\")\n",
    "        print(f\"T·ªïng th·ªùi gian ho·∫°t ƒë·ªông: {cumulative_time:.2f}s ({cumulative_time/3600:.2f} gi·ªù)\")\n",
    "        \n",
    "        if first_death_cycle:\n",
    "            print(f\"\\nChu k·ª≥ ƒë·∫ßu ti√™n c√≥ node ch·∫øt: {first_death_cycle}\")\n",
    "            print(f\"Th·ªùi gian ƒë·∫øn l√∫c ch·∫øt ƒë·∫ßu ti√™n: {first_death_time:.2f}s ({first_death_time/3600:.2f} gi·ªù)\")\n",
    "            print(f\"T·ª∑ l·ªá th·ªùi gian: {(first_death_time/cumulative_time)*100:.2f}% t·ªïng th·ªùi gian\")\n",
    "        else:\n",
    "            print(\"\\nKh√¥ng c√≥ node n√†o ch·∫øt trong qu√° tr√¨nh m√¥ ph·ªèng\")\n",
    "        \n",
    "        print(f\"\\nS·ªë node c√≤n s·ªëng cu·ªëi c√πng: {len(all_nodes)}/{total_nodes}\")\n",
    "        print(f\"S·ªë node ƒë√£ ch·∫øt: {total_nodes - len(all_nodes)}\")\n",
    "        print(f\"T·ª∑ l·ªá s·ªëng s√≥t: {(len(all_nodes)/total_nodes)*100:.2f}%\")\n",
    "        \n",
    "        # Th·ªëng k√™ v·ªÅ th·ªùi gian chu k·ª≥\n",
    "        if outputs:\n",
    "            cycle_times = [o['best_time'] for o in outputs]\n",
    "            print(f\"\\nTh·ªùi gian chu k·ª≥ trung b√¨nh: {np.mean(cycle_times):.2f}s\")\n",
    "            print(f\"Th·ªùi gian chu k·ª≥ ng·∫Øn nh·∫•t: {np.min(cycle_times):.2f}s\")\n",
    "            print(f\"Th·ªùi gian chu k·ª≥ d√†i nh·∫•t: {np.max(cycle_times):.2f}s\")\n",
    "            print(f\"ƒê·ªô l·ªách chu·∫©n: {np.std(cycle_times):.2f}s\")\n",
    "        \n",
    "        # Th·ªëng k√™ v·ªÅ s·ªë node ch·∫øt m·ªói chu k·ª≥\n",
    "        deaths_per_cycle = [len(o['dead_nodes']) for o in outputs if o['dead_nodes']]\n",
    "        if deaths_per_cycle:\n",
    "            print(f\"\\nS·ªë node ch·∫øt trung b√¨nh/chu k·ª≥ (khi c√≥ ch·∫øt): {np.mean(deaths_per_cycle):.2f}\")\n",
    "            print(f\"S·ªë node ch·∫øt nhi·ªÅu nh·∫•t trong 1 chu k·ª≥: {np.max(deaths_per_cycle)}\")\n",
    "        \n",
    "        print(f\"{'='*70}\")\n",
    "\n",
    "        # Save final results\n",
    "        meta_info.update({\n",
    "            'cycles': cycle - 1,\n",
    "            'total_operation_time': cumulative_time,\n",
    "            'first_death_cycle': first_death_cycle,\n",
    "            'first_death_time': first_death_time,\n",
    "            'final_alive_nodes': len(all_nodes),\n",
    "            'survival_rate': (len(all_nodes)/total_nodes)*100,\n",
    "            'outputs': outputs\n",
    "        })\n",
    "        \n",
    "        with open(out_filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(meta_info, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "        print(f\"\\n‚úì K·∫øt qu·∫£ cu·ªëi c√πng ƒë√£ l∆∞u: {out_filename}\")\n",
    "        \n",
    "        # Create final comprehensive chart\n",
    "        if outputs:\n",
    "            print(\"\\nüìä ƒêang t·∫°o bi·ªÉu ƒë·ªì t·ªïng h·ª£p cu·ªëi c√πng...\")\n",
    "            final_chart = plot_final_analysis(outputs, total_nodes, INITIAL_ENERGY, \n",
    "                                              filename, output_dir)\n",
    "            print(f\"‚úì ƒê√£ l∆∞u bi·ªÉu ƒë·ªì t·ªïng h·ª£p: {os.path.basename(final_chart)}\")\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"HO√ÄN TH√ÄNH X·ª¨ L√ù FILE: {filename}\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
