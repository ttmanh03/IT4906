{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2577e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã tạo file input_data/nodes_20.json chứa 20 node.\n",
      "Đã tạo file input_data/nodes_100.json chứa 100 node.\n",
      "Đã tạo file input_data/nodes_200.json chứa 200 node.\n",
      "Đã tạo file input_data/nodes_500.json chứa 500 node.\n",
      "Đã tạo file input_data/nodes_1000.json chứa 1000 node.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "def generate_nodes(N, space_size=400, filename=\"nodes.json\", initial_energy=100.0):\n",
    "    \"\"\"\n",
    "    Sinh N node cảm biến ngẫu nhiên trong không gian 3D với residual energy\n",
    "    \n",
    "    N: số lượng node\n",
    "    space_size: kích thước không gian\n",
    "    filename: tên file lưu\n",
    "    initial_energy: năng lượng ban đầu (E0)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(0)  # để kết quả lặp lại\n",
    "    node_positions = np.random.rand(N, 3) * space_size\n",
    "    \n",
    "    # Sinh residual energy ngẫu nhiên (50-100% của initial energy)\n",
    "    np.random.seed(42)  # Seed khác để energy không phụ thuộc vào vị trí\n",
    "    residual_energies = np.random.uniform(0.5 * initial_energy, initial_energy, N)\n",
    "\n",
    "    data = []\n",
    "    for i in range(N):\n",
    "        data.append({\n",
    "            \"id\": i,\n",
    "            \"x\": float(node_positions[i][0]),\n",
    "            \"y\": float(node_positions[i][1]),\n",
    "            \"z\": float(node_positions[i][2]),\n",
    "            \"residual_energy\": float(residual_energies[i]),\n",
    "            \"initial_energy\": float(initial_energy)\n",
    "        })\n",
    "\n",
    "    \n",
    "    os.makedirs(\"input_data\", exist_ok=True)\n",
    "    filepath = f\"input_data/{filename}\"\n",
    "    with open(filepath, \"w\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "    print(f\"Đã tạo file {filepath} chứa {N} node với residual energy.\")\n",
    "    print(f\"Energy range: {residual_energies.min():.1f} - {residual_energies.max():.1f}\")\n",
    "\n",
    "# Sinh dữ liệu với energy information\n",
    "for N in [20, 100, 200, 500, 1000]:\n",
    "    generate_nodes(N, space_size=100, filename=f\"nodes_{N}.json\", initial_energy=100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e324e55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_number_clusters(nodes, base_station=(0, 0, 0), space_size=400):\n",
    "    \"\"\"\n",
    "    Tính số cụm optimal theo công thức từ bài báo:\n",
    "    K = √( / πd_tobs)\n",
    "    \n",
    "    nodes: tọa độ 3D của các node\n",
    "    base_station: tọa độ base station (mặc định tại gốc tọa độ)\n",
    "    \"\"\"\n",
    "    N = len(nodes)\n",
    "    base_pos = np.array(base_station)\n",
    "    \n",
    "    # Tính khoảng cách trung bình từ các node đến base station\n",
    "    distances = np.linalg.norm(nodes - base_pos, axis=1)\n",
    "    d_tobs = np.mean(distances)\n",
    "    \n",
    "    # Áp dụng công thức K = √(N*L / πd_tobs)\n",
    "    K_optimal = np.sqrt(N * space_size / (np.pi * d_tobs))\n",
    "    K_optimal = max(1, int(np.round(K_optimal)))  # Đảm bảo K >= 1 và là số nguyên\n",
    "    \n",
    "    print(f\"N = {N}, d_tobs = {d_tobs:.2f}, K_optimal = {K_optimal}\")\n",
    "    return K_optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65d189df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def cluster_split(nodes, node_ids, node_data=None, r_sen=100, R=20, max_depth=10, depth=0):\n",
    "    \"\"\"\n",
    "    Hàm phân cụm lặp theo Algorithm 1\n",
    "    nodes: tọa độ 3D của các node\n",
    "    node_ids: list id tương ứng của các node\n",
    "    node_data: dictionary chứa thông tin đầy đủ của nodes (bao gồm energy)\n",
    "    r_sen: bán kính truyền tải tối đa của node, giả sử là 100m\n",
    "    R: số lượng node tối đa trong 1 cụm, cho là 20\n",
    "    max_depth: độ sâu đệ quy tối đa\n",
    "    \"\"\"\n",
    "    \n",
    "    center = np.mean(nodes, axis=0)\n",
    "    dists = np.linalg.norm(nodes - center, axis=1) # khoảng cách từ tâm đến các node\n",
    "    if (len(nodes) <= R and np.all(dists <= r_sen)) or depth >= max_depth:\n",
    "        return [{\n",
    "            \"node_ids\": node_ids,\n",
    "            \"nodes\": nodes,\n",
    "            \"center\": center,\n",
    "            \"node_data\": node_data if node_data else {}\n",
    "        }]\n",
    "\n",
    "    # Kmeans với k=2 để chia cụm\n",
    "    kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(nodes)\n",
    "\n",
    "    clusters = []\n",
    "    for i in range(2):\n",
    "        sub_nodes = nodes[labels == i]\n",
    "        sub_ids = [node_ids[j] for j in range(len(node_ids)) if labels[j] == i]\n",
    "        \n",
    "        # Tạo sub_node_data cho cluster con\n",
    "        sub_node_data = {}\n",
    "        if node_data:\n",
    "            for node_id in sub_ids:\n",
    "                if node_id in node_data:\n",
    "                    sub_node_data[node_id] = node_data[node_id]\n",
    "        \n",
    "        clusters += cluster_split(sub_nodes, sub_ids, sub_node_data, r_sen, R, max_depth, depth + 1)\n",
    "\n",
    "    return clusters\n",
    "\n",
    "\n",
    "def choose_cluster_head(cluster, node_data_dict):\n",
    "    \"\"\"\n",
    "    Chọn cluster head theo công thức desirableness factor:\n",
    "    Q = d_tocenter^(E0/E_current)\n",
    "    \n",
    "    Node có Q MAX sẽ được chọn làm cluster head\n",
    "    \n",
    "    cluster: thông tin cluster\n",
    "    node_data_dict: dictionary chứa thông tin đầy đủ của tất cả nodes\n",
    "    \"\"\"\n",
    "    nodes = cluster[\"nodes\"]\n",
    "    center = cluster[\"center\"]\n",
    "    node_ids = cluster[\"node_ids\"]\n",
    "\n",
    "    # Tính khoảng cách từ mỗi node đến tâm cụm\n",
    "    dists_to_center = np.linalg.norm(nodes - center, axis=1)\n",
    "    \n",
    "    max_Q = -1\n",
    "    best_cluster_head = node_ids[0]  # Default fallback\n",
    "    \n",
    "    print(f\"\\n=== Chọn Cluster Head cho cụm có {len(node_ids)} nodes ===\")\n",
    "    \n",
    "    for i, node_id in enumerate(node_ids):\n",
    "        if node_id in node_data_dict:\n",
    "            node_info = node_data_dict[node_id]\n",
    "            \n",
    "            # Lấy thông tin energy\n",
    "            E_current = node_info.get('residual_energy', 100.0)\n",
    "            E0 = node_info.get('initial_energy', 100.0)\n",
    "            \n",
    "            # Tính desirableness factor: Q = d_tocenter^(E0/E_current)\n",
    "            d_tocenter = dists_to_center[i]\n",
    "            \n",
    "            # Tránh chia cho 0 và overflow\n",
    "            if E_current <= 0:\n",
    "                E_current = 0.1  # Năng lượng rất thấp\n",
    "            \n",
    "            energy_ratio = E0 / E_current\n",
    "            \n",
    "            # Tính Q - node có Q MAX sẽ được chọn\n",
    "            Q = d_tocenter ** energy_ratio\n",
    "            \n",
    "            print(f\"  Node {node_id}: d={d_tocenter:.2f}, E_cur={E_current:.1f}, \"\n",
    "                  f\"E0={E0:.1f}, ratio={energy_ratio:.2f}, Q={Q:.3f}\")\n",
    "            \n",
    "            # Chọn node có Q lớn nhất\n",
    "            if Q > max_Q:\n",
    "                max_Q = Q\n",
    "                best_cluster_head = node_id\n",
    "        else:\n",
    "            # Fallback: chọn node gần tâm nhất nếu không có thông tin energy\n",
    "            print(f\"  Node {node_id}: No energy data, using distance only\")\n",
    "            if i == 0 or dists_to_center[i] < dists_to_center[node_ids.index(best_cluster_head)]:\n",
    "                best_cluster_head = node_id\n",
    "    \n",
    "    print(f\"Chọn Node {best_cluster_head} làm Cluster Head (Q_max = {max_Q:.3f})\")\n",
    "    return best_cluster_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c684f92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 100, d_tobs = 96.71, K_optimal = 11\n",
      "Số cụm: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "  File \"c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py\", line 503, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "  File \"c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py\", line 971, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py\", line 1456, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "choose_cluster_head() missing 1 required positional argument: 'node_data_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m clusters_output \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(clusters_raw):\n\u001b[1;32m---> 29\u001b[0m     ch \u001b[38;5;241m=\u001b[39m \u001b[43mchoose_cluster_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m     clusters_output[i] \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     31\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnodes\u001b[39m\u001b[38;5;124m\"\u001b[39m: c[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnode_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     32\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcenter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtuple\u001b[39m(np\u001b[38;5;241m.\u001b[39mround(c[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcenter\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;241m2\u001b[39m)),\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster_head\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mint\u001b[39m(ch)\n\u001b[0;32m     34\u001b[0m     }\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Xuất ra file\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: choose_cluster_head() missing 1 required positional argument: 'node_data_dict'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "input_folder = \"D:\\\\Year 4\\\\tiến hóa\\\\project\\\\UWSN_greedy\\\\input_data\"\n",
    "output_folder = \"D:\\\\Year 4\\\\tiến hóa\\\\project\\\\UWSN_greedy\\\\output_data_kmeans\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "draw_folder = \"draw_output_kmeans\"\n",
    "os.makedirs(draw_folder, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.startswith(\"nodes_\") and filename.endswith(\".json\"):\n",
    "        # Lấy số lượng node từ tên file\n",
    "        number_nodes = filename.split(\"_\")[1].split(\".\")[0]\n",
    "        # Đọc dữ liệu từ file input\n",
    "        with open(os.path.join(input_folder, filename), \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        node_positions = np.array([[d[\"x\"], d[\"y\"], d[\"z\"]] for d in data])\n",
    "        node_ids = [d[\"id\"] for d in data]\n",
    "        # Phân cụm\n",
    "        k = calculate_number_clusters(node_positions, base_station=(0, 0, 0))\n",
    "        print(f\"Số cụm: {k}\")\n",
    "        clusters_raw = cluster_split(node_positions, node_ids, R=int(number_nodes)//k)\n",
    "        # Tạo output\n",
    "        clusters_output = {}\n",
    "        for i, c in enumerate(clusters_raw):\n",
    "            ch = choose_cluster_head(c)\n",
    "            clusters_output[i] = {\n",
    "                \"nodes\": c[\"node_ids\"],\n",
    "                \"center\": tuple(np.round(c[\"center\"], 2)),\n",
    "                \"cluster_head\": int(ch)\n",
    "            }\n",
    "        # Xuất ra file\n",
    "        out_path = os.path.join(output_folder, f\"nodes_{number_nodes}.json\")\n",
    "        with open(out_path, \"w\") as f:\n",
    "            json.dump(clusters_output, f, indent=4)\n",
    "        print(f\"Đã xuất file {out_path}\")\n",
    "        # Vẽ và lưu hình\n",
    "        fig = plt.figure(figsize=(10, 8))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        colors = plt.cm.get_cmap('tab10', len(clusters_output))\n",
    "        for cid, info in clusters_output.items():\n",
    "            nodes = np.array([node_positions[nid] for nid in info['nodes']])\n",
    "            ax.scatter(nodes[:, 0], nodes[:, 1], nodes[:, 2],\n",
    "                        label=f'Cụm {cid}',\n",
    "                        color=colors(cid))\n",
    "            ch_pos = node_positions[info['cluster_head']]\n",
    "            ax.scatter(ch_pos[0], ch_pos[1], ch_pos[2],\n",
    "                        color=colors(cid),\n",
    "                        marker='*', s=80, edgecolor='k')\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_zlabel('Z')\n",
    "        ax.legend()\n",
    "        plt.title(f'Phân cụm các node cảm biến ({number_nodes} node)')\n",
    "        ax.view_init(elev=30, azim=30)\n",
    "        plt.tight_layout()\n",
    "        draw_path = os.path.join(draw_folder, f\"nodes_{number_nodes}.png\")\n",
    "        plt.savefig(draw_path)\n",
    "        plt.close(fig)\n",
    "        print(f\"Đã lưu hình vẽ {draw_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
