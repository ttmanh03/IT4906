{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec5c394",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T18:27:14.078079Z",
     "iopub.status.busy": "2025-11-23T18:27:14.077669Z",
     "iopub.status.idle": "2025-11-23T18:27:14.083183Z",
     "shell.execute_reply": "2025-11-23T18:27:14.082091Z",
     "shell.execute_reply.started": "2025-11-23T18:27:14.078054Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import pdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aecbdac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T18:27:14.084807Z",
     "iopub.status.busy": "2025-11-23T18:27:14.084505Z",
     "iopub.status.idle": "2025-11-23T18:27:14.111429Z",
     "shell.execute_reply": "2025-11-23T18:27:14.110364Z",
     "shell.execute_reply.started": "2025-11-23T18:27:14.084778Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Clustering:\n",
    "    def __init__(self, space_size=400, r_sen=50, max_cluster_size=20, min_cluster_size=5):\n",
    "        self.space_size = space_size\n",
    "        self.r_sen = r_sen\n",
    "        self.max_cluster_size = max_cluster_size\n",
    "        self.min_cluster_size = min_cluster_size\n",
    "\n",
    "    def estimate_optimal_k(self, nodes, base_station=(200,200,400)):\n",
    "        \"\"\"\n",
    "        ∆Ø·ªõc t√≠nh s·ªë c·ª•m t·ªëi ∆∞u d·ª±a tr√™n c√¥ng th·ª©c WSN\n",
    "        K = sqrt(N*L / (pi*d_tobs))\n",
    "        \"\"\"\n",
    "        N = len(nodes)\n",
    "        base_pos = np.array(base_station)\n",
    "\n",
    "        # Khoang cach trung binh toi base station\n",
    "        distances = np.linalg.norm(nodes - base_pos, axis=1)\n",
    "        d_tobs = np.mean(distances)\n",
    "\n",
    "        space_size = self.space_size\n",
    "\n",
    "        k_optimal = np.sqrt(N * space_size / (np.pi * d_tobs))\n",
    "        k_optimal = max(2, int(np.round(k_optimal)))\n",
    "\n",
    "        # ƒêi·ªÅu ch·ªânh d·ª±a tr√™n max_cluster_size\n",
    "        k_min = int(np.ceil(N / self.max_cluster_size))\n",
    "        k_optimal = max(k_optimal, k_min)\n",
    "        \n",
    "        return k_optimal\n",
    "    \n",
    "    def check_cluster_validity(self, cluster_nodes):\n",
    "        \"\"\"\n",
    "        Kiem tra tinh hop le cua cum\n",
    "        \"\"\"\n",
    "        size = len(cluster_nodes)\n",
    "\n",
    "        # Ki·ªÉm tra k√≠ch th∆∞·ªõc\n",
    "        if size < self.min_cluster_size or size > self.max_cluster_size:\n",
    "            return False, 0, size\n",
    "        \n",
    "        # Ki·ªÉm tra kho·∫£ng c√°ch\n",
    "        if size > 1:\n",
    "            distances = pdist(cluster_nodes)\n",
    "            max_dist = np.max(distances)\n",
    "            \n",
    "            if max_dist > self.r_sen:\n",
    "                return False, max_dist, size\n",
    "            \n",
    "            return True, max_dist, size\n",
    "        \n",
    "        return True, 0, size\n",
    "    \n",
    "    def split_invalid_cluster(self, cluster_nodes, cluster_ids):\n",
    "        \"\"\"\n",
    "        Chia nh·ªè c·ª•m kh√¥ng h·ª£p l·ªá th√†nh c√°c c·ª•m con\n",
    "        \"\"\"\n",
    "        # N·∫øu c·ª•m ch·ªâ c√≥ 1 node, kh√¥ng th·ªÉ chia\n",
    "        if len(cluster_nodes) < 2:\n",
    "            return [(cluster_nodes, cluster_ids)]\n",
    "        \n",
    "        # S·ª≠ d·ª•ng K-Means ƒë·ªÉ chia 2\n",
    "        kmeans = KMeans(n_clusters=2, n_init=20, random_state=42)\n",
    "        labels = kmeans.fit_predict(cluster_nodes)\n",
    "        \n",
    "        sub_clusters = []\n",
    "        for i in range(2):\n",
    "            sub_nodes = cluster_nodes[labels == i]\n",
    "            sub_ids = [cluster_ids[j] for j in range(len(cluster_ids)) if labels[j] == i]\n",
    "            \n",
    "            if len(sub_nodes) > 0:\n",
    "                sub_clusters.append((sub_nodes, sub_ids))\n",
    "        \n",
    "        return sub_clusters\n",
    "    \n",
    "    def merge_small_clusters(self, clusters_data):\n",
    "        \"\"\"\n",
    "        G·ªôp c√°c c·ª•m nh·ªè v·ªõi c·ª•m l√°ng gi·ªÅng g·∫ßn nh·∫•t\n",
    "        \"\"\"\n",
    "        if len(clusters_data) <= 1:\n",
    "            return clusters_data\n",
    "        \n",
    "        merged = []\n",
    "        to_merge = []\n",
    "        \n",
    "        # T√¨m c√°c c·ª•m nh·ªè\n",
    "        for nodes, ids in clusters_data:\n",
    "            if len(nodes) < self.min_cluster_size:\n",
    "                to_merge.append((nodes, ids))\n",
    "            else:\n",
    "                merged.append((nodes, ids))\n",
    "        \n",
    "        # G·ªôp t·ª´ng c·ª•m nh·ªè v√†o c·ª•m g·∫ßn nh·∫•t\n",
    "        for small_nodes, small_ids in to_merge:\n",
    "            if len(merged) == 0:\n",
    "                merged.append((small_nodes, small_ids))\n",
    "                continue\n",
    "            \n",
    "            # T√¨m c·ª•m g·∫ßn nh·∫•t\n",
    "            small_center = np.mean(small_nodes, axis=0)\n",
    "            min_dist = float('inf')\n",
    "            best_idx = 0\n",
    "            \n",
    "            for i, (nodes, ids) in enumerate(merged):\n",
    "                center = np.mean(nodes, axis=0)\n",
    "                dist = np.linalg.norm(small_center - center)\n",
    "                \n",
    "                # Ki·ªÉm tra xem g·ªôp c√≥ v∆∞·ª£t qu√° max_size kh√¥ng\n",
    "                if dist < min_dist and len(nodes) + len(small_nodes) <= self.max_cluster_size:\n",
    "                    min_dist = dist\n",
    "                    best_idx = i\n",
    "            \n",
    "            # G·ªôp\n",
    "            merged[best_idx] = (\n",
    "                np.vstack([merged[best_idx][0], small_nodes]),\n",
    "                merged[best_idx][1] + small_ids\n",
    "            )\n",
    "        \n",
    "        return merged\n",
    "    \n",
    "    def cluster_with_constraints(self, nodes, node_ids, k=None, max_iterations=10):\n",
    "        \"\"\"\n",
    "        Ph√¢n c·ª•m v·ªõi r√†ng bu·ªôc - Thu·∫≠t to√°n ch√≠nh\n",
    "        \n",
    "        Args:\n",
    "            nodes: T·ªça ƒë·ªô 3D c·ªßa nodes\n",
    "            node_ids: ID c·ªßa nodes\n",
    "            k: S·ªë c·ª•m (n·∫øu None s·∫Ω t·ª± ƒë·ªông ∆∞·ªõc t√≠nh)\n",
    "            max_iterations: S·ªë l·∫ßn l·∫∑p t·ªëi ƒëa ƒë·ªÉ ƒëi·ªÅu ch·ªânh\n",
    "            \n",
    "        Returns:\n",
    "            List of (cluster_nodes, cluster_ids)\n",
    "        \"\"\"\n",
    "        if k is None:\n",
    "            k = self.estimate_optimal_k(nodes)\n",
    "        \n",
    "        print(f\"B·∫Øt ƒë·∫ßu ph√¢n c·ª•m v·ªõi k={k}\")\n",
    "        \n",
    "        # B∆∞·ªõc 1: K-Means ban ƒë·∫ßu\n",
    "        kmeans = KMeans(n_clusters=k, n_init=30, random_state=42)\n",
    "        labels = kmeans.fit_predict(nodes)\n",
    "        \n",
    "        # B∆∞·ªõc 2: T·∫°o c√°c c·ª•m v√† ki·ªÉm tra\n",
    "        iteration = 0\n",
    "        while iteration < max_iterations:\n",
    "            print(f\"  V√≤ng l·∫∑p {iteration + 1}/{max_iterations}\")\n",
    "            \n",
    "            valid_clusters = []\n",
    "            invalid_clusters = []\n",
    "            \n",
    "            # Ph√¢n lo·∫°i c·ª•m h·ª£p l·ªá v√† kh√¥ng h·ª£p l·ªá\n",
    "            for i in range(k):\n",
    "                cluster_nodes = nodes[labels == i]\n",
    "                cluster_ids = [node_ids[j] for j in range(len(node_ids)) if labels[j] == i]\n",
    "                \n",
    "                if len(cluster_nodes) == 0:\n",
    "                    continue\n",
    "                \n",
    "                is_valid, max_dist, size = self.check_cluster_validity(cluster_nodes)\n",
    "                \n",
    "                if is_valid:\n",
    "                    valid_clusters.append((cluster_nodes, cluster_ids))\n",
    "                    print(f\"    C·ª•m {i}: ‚úì h·ª£p l·ªá (size={size}, max_dist={max_dist:.1f}m)\")\n",
    "                else:\n",
    "                    invalid_clusters.append((cluster_nodes, cluster_ids))\n",
    "                    print(f\"    C·ª•m {i}: ‚úó kh√¥ng h·ª£p l·ªá (size={size}, max_dist={max_dist:.1f}m)\")\n",
    "            \n",
    "            # N·∫øu t·∫•t c·∫£ h·ª£p l·ªá, k·∫øt th√∫c\n",
    "            if len(invalid_clusters) == 0:\n",
    "                print(f\"  ‚Üí T·∫•t c·∫£ c·ª•m h·ª£p l·ªá!\")\n",
    "                break\n",
    "            \n",
    "            # B∆∞·ªõc 3: X·ª≠ l√Ω c√°c c·ª•m kh√¥ng h·ª£p l·ªá\n",
    "            for cluster_nodes, cluster_ids in invalid_clusters:\n",
    "                size = len(cluster_nodes)\n",
    "                \n",
    "                if size > self.max_cluster_size:\n",
    "                    # C·ª•m qu√° l·ªõn ‚Üí Chia nh·ªè\n",
    "                    print(f\"    ‚Üí Chia c·ª•m (size={size})\")\n",
    "                    sub_clusters = self.split_invalid_cluster(cluster_nodes, cluster_ids)\n",
    "                    valid_clusters.extend(sub_clusters)\n",
    "                else:\n",
    "                    # C·ª•m c√≥ kho·∫£ng c√°ch qu√° l·ªõn ‚Üí Chia nh·ªè\n",
    "                    print(f\"    ‚Üí Chia c·ª•m (kho·∫£ng c√°ch l·ªõn)\")\n",
    "                    sub_clusters = self.split_invalid_cluster(cluster_nodes, cluster_ids)\n",
    "                    valid_clusters.extend(sub_clusters)\n",
    "            \n",
    "            # C·∫≠p nh·∫≠t labels v√† k cho v√≤ng l·∫∑p ti·∫øp theo\n",
    "            k = len(valid_clusters)\n",
    "            \n",
    "            # T·∫°o l·∫°i labels t·ª´ valid_clusters\n",
    "            labels = np.zeros(len(nodes), dtype=int)\n",
    "            for cluster_idx, (_, cluster_ids) in enumerate(valid_clusters):\n",
    "                for node_id in cluster_ids:\n",
    "                    node_idx = node_ids.index(node_id)\n",
    "                    labels[node_idx] = cluster_idx\n",
    "            \n",
    "            iteration += 1\n",
    "        \n",
    "        # B∆∞·ªõc 4: G·ªôp c√°c c·ª•m qu√° nh·ªè\n",
    "        valid_clusters = self.merge_small_clusters(valid_clusters)\n",
    "        \n",
    "        print(f\"Ho√†n th√†nh: {len(valid_clusters)} c·ª•m\")\n",
    "        return valid_clusters\n",
    "    \n",
    "    def choose_cluster_head(self, cluster_nodes, cluster_ids, node_data=None):\n",
    "        \"\"\"\n",
    "        Ch·ªçn cluster head\n",
    "        - ∆Øu ti√™n: Node c√≥ nƒÉng l∆∞·ª£ng cao nh·∫•t\n",
    "        - D·ª± ph√≤ng: Node g·∫ßn t√¢m c·ª•m nh·∫•t\n",
    "        \"\"\"\n",
    "        if node_data:\n",
    "            # Ch·ªçn theo nƒÉng l∆∞·ª£ng\n",
    "            max_energy = -1\n",
    "            ch_id = cluster_ids[0]\n",
    "            \n",
    "            for nid in cluster_ids:\n",
    "                if nid in node_data and 'residual_energy' in node_data[nid]:\n",
    "                    energy = node_data[nid]['residual_energy']\n",
    "                    if energy > max_energy:\n",
    "                        max_energy = energy\n",
    "                        ch_id = nid\n",
    "            \n",
    "            return ch_id\n",
    "        else:\n",
    "            # Ch·ªçn theo kho·∫£ng c√°ch ƒë·∫øn t√¢m\n",
    "            center = np.mean(cluster_nodes, axis=0)\n",
    "            distances = np.linalg.norm(cluster_nodes - center, axis=1)\n",
    "            min_idx = np.argmin(distances)\n",
    "            return cluster_ids[min_idx]\n",
    "    \n",
    "    def calculate_metrics(self, clusters_data):\n",
    "        \"\"\"\n",
    "        T√≠nh c√°c metric ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng ph√¢n c·ª•m\n",
    "        \"\"\"\n",
    "        metrics = {\n",
    "            'num_clusters': len(clusters_data),\n",
    "            'avg_cluster_size': 0,\n",
    "            'min_cluster_size': float('inf'),\n",
    "            'max_cluster_size': 0,\n",
    "            'avg_intra_distance': 0,\n",
    "            'max_intra_distance': 0,\n",
    "            'balance_score': 0  # ƒê·ªô c√¢n b·∫±ng k√≠ch th∆∞·ªõc c·ª•m (0-1, c√†ng cao c√†ng t·ªët)\n",
    "        }\n",
    "        \n",
    "        sizes = []\n",
    "        intra_dists = []\n",
    "        \n",
    "        for nodes, ids in clusters_data:\n",
    "            size = len(nodes)\n",
    "            sizes.append(size)\n",
    "            \n",
    "            metrics['min_cluster_size'] = min(metrics['min_cluster_size'], size)\n",
    "            metrics['max_cluster_size'] = max(metrics['max_cluster_size'], size)\n",
    "            \n",
    "            if size > 1:\n",
    "                distances = pdist(nodes)\n",
    "                intra_dists.append(np.mean(distances))\n",
    "                metrics['max_intra_distance'] = max(metrics['max_intra_distance'], np.max(distances))\n",
    "        \n",
    "        metrics['avg_cluster_size'] = np.mean(sizes)\n",
    "        metrics['avg_intra_distance'] = np.mean(intra_dists) if intra_dists else 0\n",
    "        \n",
    "        # T√≠nh balance score (d·ª±a tr√™n coefficient of variation)\n",
    "        cv = np.std(sizes) / np.mean(sizes) if np.mean(sizes) > 0 else 0\n",
    "        metrics['balance_score'] = 1 / (1 + cv)  # 1 = ho√†n to√†n c√¢n b·∫±ng\n",
    "        \n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a7ebeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T18:27:14.112497Z",
     "iopub.status.busy": "2025-11-23T18:27:14.112227Z",
     "iopub.status.idle": "2025-11-23T18:27:14.130428Z",
     "shell.execute_reply": "2025-11-23T18:27:14.129599Z",
     "shell.execute_reply.started": "2025-11-23T18:27:14.112478Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_vs(p1, p2, v_f, v_AUV):\n",
    "    x1, y1, z1 = p1\n",
    "    x2, y2, z2 = p2\n",
    "    Lx, Ly, Lz = x2 - x1, y2 - y1, z2 - z1\n",
    "    L_mag = math.sqrt(Lx**2 + Ly**2 + Lz**2)\n",
    "    if L_mag == 0:\n",
    "        return v_AUV\n",
    "    cos_beta = Lz / L_mag\n",
    "    cos_beta = np.clip(cos_beta, -1, 1)\n",
    "    beta = math.acos(cos_beta)\n",
    "    inner = np.clip((v_f * cos_beta) / v_AUV, -1, 1)\n",
    "    angle = beta + math.acos(inner)\n",
    "    if abs(cos_beta) < 1e-9:\n",
    "        return v_AUV\n",
    "    return abs(math.cos(angle) * v_AUV / cos_beta)\n",
    "\n",
    "def travel_time(path, coords, v_f, v_AUV):\n",
    "    total_time = 0.0\n",
    "    if len(path) <= 1:\n",
    "        return 0.0\n",
    "    for i in range(len(path) - 1):\n",
    "        p1, p2 = coords[path[i]], coords[path[i + 1]]\n",
    "        d = np.linalg.norm(np.array(p2) - np.array(p1))\n",
    "        v_s = compute_vs(tuple(p1), tuple(p2), v_f, v_AUV)\n",
    "        total_time += d / max(v_s, 1e-9)\n",
    "    # return to start\n",
    "    p1, p2 = coords[path[-1]], coords[path[0]]\n",
    "    d = np.linalg.norm(np.array(p2) - np.array(p1))\n",
    "    v_s = compute_vs(tuple(p1), tuple(p2), v_f, v_AUV)\n",
    "    total_time += d / max(v_s, 1e-9)\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21183c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbor_path(centers, v_f, v_AUV):\n",
    "    \"\"\"Thu·∫≠t to√°n tham lam ch·ªçn c·ª•m k·∫ø ti·∫øp d·ª±a tr√™n *th·ªùi gian di chuy·ªÉn ∆∞·ªõc t√≠nh*.\n",
    "    centers: list t·ªça ƒë·ªô, index 0 l√† base station.\n",
    "    v_f: v·∫≠n t·ªëc d√≤ng ch·∫£y; v_AUV: v·∫≠n t·ªëc AUV g·ªëc.\n",
    "    Tr·∫£ v·ªÅ list index theo th·ª© t·ª± thƒÉm (ch∆∞a c·ªông ƒëo·∫°n quay v·ªÅ start).\"\"\"\n",
    "    n = len(centers)\n",
    "    if n <= 1:\n",
    "        return [0]\n",
    "    unvisited = set(range(1, n))\n",
    "    path = [0]\n",
    "    cur = 0\n",
    "    pts = np.array(centers)\n",
    "    while unvisited:\n",
    "        best_next = None\n",
    "        best_time = float('inf')\n",
    "        for cand in unvisited:\n",
    "            p_cur = tuple(pts[cur])\n",
    "            p_cand = tuple(pts[cand])\n",
    "            dist = np.linalg.norm(pts[cand] - pts[cur])\n",
    "            v_s = compute_vs(p_cur, p_cand, v_f, v_AUV)\n",
    "            t = dist / max(v_s, 1e-9)\n",
    "            if t < best_time:\n",
    "                best_time = t\n",
    "                best_next = cand\n",
    "        path.append(best_next)\n",
    "        unvisited.remove(best_next)\n",
    "        cur = best_next\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e739a74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T18:27:14.162724Z",
     "iopub.status.busy": "2025-11-23T18:27:14.162201Z",
     "iopub.status.idle": "2025-11-23T18:27:14.179942Z",
     "shell.execute_reply": "2025-11-23T18:27:14.178976Z",
     "shell.execute_reply.started": "2025-11-23T18:27:14.162697Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_energy(best_time, n_members):\n",
    "    \"\"\"\n",
    "    T√≠nh nƒÉng l∆∞·ª£ng ti√™u th·ª• cho Member Node v√† Cluster Head.\n",
    "    \n",
    "    Parameters:\n",
    "    - best_time: Th·ªùi gian ho√†n th√†nh chu k·ª≥ AUV\n",
    "    - n_members: S·ªë l∆∞·ª£ng node th√†nh vi√™n th·ª±c t·∫ø trong cluster (kh√¥ng t√≠nh cluster head)\n",
    "    \"\"\"\n",
    "    G, L = 100, 1024\n",
    "    P_t, P_r, P_idle, DR, DR_i = 1.6e-3, 0.8e-3, 0.1e-3, 4000, 1e6\n",
    "\n",
    "    # NƒÉng l∆∞·ª£ng cho Member Node\n",
    "    E_tx_MN = G * P_t * L / DR\n",
    "    E_idle_MN = (best_time - G * L / DR) * P_idle\n",
    "    E_total_MN = E_tx_MN + E_idle_MN\n",
    "\n",
    "    # NƒÉng l∆∞·ª£ng cho Cluster Head (nh·∫≠n t·ª´ n_members node, truy·ªÅn cho AUV)\n",
    "    E_rx_TN = G * P_r * L * n_members / DR\n",
    "    E_tx_TN = G * P_t * L * n_members / DR_i\n",
    "    E_idle_TN = (best_time - (G*L*n_members/DR) - (G*L*n_members/DR_i)) * P_idle\n",
    "    E_total_TN = E_rx_TN + E_tx_TN + E_idle_TN\n",
    "\n",
    "    return {\n",
    "        \"Member\": {\"E_total\": E_total_MN},\n",
    "        \"Target\": {\"E_total\": E_total_TN}\n",
    "    }\n",
    "\n",
    "def update_energy(all_nodes, clusters, best_time):\n",
    "    \"\"\"\n",
    "    C·∫≠p nh·∫≠t nƒÉng l∆∞·ª£ng cho t·∫•t c·∫£ c√°c node d·ª±a tr√™n s·ªë member th·ª±c t·∫ø c·ªßa t·ª´ng cluster.\n",
    "    \n",
    "    Parameters:\n",
    "    - all_nodes: Dictionary ch·ª©a th√¥ng tin t·∫•t c·∫£ c√°c node\n",
    "    - clusters: Dictionary ch·ª©a th√¥ng tin c√°c cluster\n",
    "    - best_time: Th·ªùi gian ho√†n th√†nh chu k·ª≥ AUV\n",
    "    \"\"\"\n",
    "    for cid, cinfo in clusters.items():\n",
    "        ch = cinfo.get('cluster_head')\n",
    "        nodes = cinfo.get('nodes', [])\n",
    "        \n",
    "        # T√≠nh s·ªë member nodes (kh√¥ng t√≠nh cluster head)\n",
    "        n_members = len([n for n in nodes if n != ch])\n",
    "        \n",
    "        # T√≠nh nƒÉng l∆∞·ª£ng cho cluster n√†y v·ªõi s·ªë member th·ª±c t·∫ø\n",
    "        energy_report = compute_energy(best_time, n_members)\n",
    "        \n",
    "        for nid in nodes:\n",
    "            if nid not in all_nodes: continue\n",
    "            if nid == ch:\n",
    "                all_nodes[nid]['residual_energy'] -= energy_report['Target']['E_total']\n",
    "            else:\n",
    "                all_nodes[nid]['residual_energy'] -= energy_report['Member']['E_total']\n",
    "            all_nodes[nid]['residual_energy'] = max(all_nodes[nid]['residual_energy'], 0.0)\n",
    "\n",
    "def remove_dead_nodes(all_nodes, clusters):\n",
    "    \"\"\"\n",
    "    Lo·∫°i b·ªè c√°c node ƒë√£ h·∫øt nƒÉng l∆∞·ª£ng v√† c·∫≠p nh·∫≠t l·∫°i clusters.\n",
    "    \n",
    "    Returns:\n",
    "    - new_clusters: Dictionary c√°c cluster c√≤n node s·ªëng\n",
    "    - dead: List c√°c node_id ƒë√£ ch·∫øt\n",
    "    \"\"\"\n",
    "    dead = [nid for nid, info in list(all_nodes.items()) if info['residual_energy'] <= 0]\n",
    "    for nid in dead:\n",
    "        del all_nodes[nid]\n",
    "\n",
    "    new_clusters = {}\n",
    "    for cid, cinfo in clusters.items():\n",
    "        alive_nodes = [nid for nid in cinfo.get('nodes', []) if nid in all_nodes]\n",
    "        if alive_nodes:\n",
    "            new_c = dict(cinfo)\n",
    "            new_c['nodes'] = alive_nodes\n",
    "            new_clusters[cid] = new_c\n",
    "\n",
    "    return new_clusters, dead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6b93f0-bb87-4303-a031-ef3c71222f02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T18:27:14.200339Z",
     "iopub.status.busy": "2025-11-23T18:27:14.199982Z",
     "iopub.status.idle": "2025-11-23T18:27:14.217069Z",
     "shell.execute_reply": "2025-11-23T18:27:14.216159Z",
     "shell.execute_reply.started": "2025-11-23T18:27:14.200310Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def reselect_cluster_heads(clusters, all_nodes):\n",
    "    \"\"\"\n",
    "    Ch·ªâ ch·ªçn l·∫°i cluster head cho c√°c c·ª•m hi·ªán t·∫°i d·ª±a tr√™n nƒÉng l∆∞·ª£ng.\n",
    "    Kh√¥ng ph√¢n c·ª•m l·∫°i.\n",
    "    \"\"\"\n",
    "    for cid, cinfo in clusters.items():\n",
    "        cluster_ids = cinfo['nodes']\n",
    "        # T√¨m node c√≥ nƒÉng l∆∞·ª£ng cao nh·∫•t\n",
    "        max_energy = -1\n",
    "        new_ch = cluster_ids[0]\n",
    "        for nid in cluster_ids:\n",
    "            if nid in all_nodes and 'residual_energy' in all_nodes[nid]:\n",
    "                energy = all_nodes[nid]['residual_energy']\n",
    "                if energy > max_energy:\n",
    "                    max_energy = energy\n",
    "                    new_ch = nid\n",
    "        clusters[cid]['cluster_head'] = new_ch\n",
    "    return clusters\n",
    "\n",
    "print(\"‚úì Helper function loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1e08e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T18:27:14.218377Z",
     "iopub.status.busy": "2025-11-23T18:27:14.218067Z",
     "iopub.status.idle": "2025-11-23T18:27:14.246263Z",
     "shell.execute_reply": "2025-11-23T18:27:14.245286Z",
     "shell.execute_reply.started": "2025-11-23T18:27:14.218350Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    M√¥ ph·ªèng v·ªõi logic:\n",
    "    - M·ªói v√≤ng l·∫∑p: Ch·ªâ ch·ªçn l·∫°i cluster head\n",
    "    - Khi c√≥ node ch·∫øt: Ph√¢n c·ª•m l·∫°i v√† t√≠nh ƒë∆∞·ªùng ƒëi m·ªõi\n",
    "    - ƒê∆∞·ªùng ƒëi tham lam d·ª±a tr√™n *th·ªùi gian di chuy·ªÉn ∆∞·ªõc t√≠nh* (velocity + distance)\n",
    "    \"\"\"\n",
    "    # ƒêI·ªÄU CH·ªàNH ƒê∆Ø·ªúNG D·∫™N\n",
    "    input_folder = \"/kaggle/input/nodes-data\"  # ‚Üê s·ª≠a theo dataset th·ª±c t·∫ø\n",
    "    output_folder = \"/kaggle/working/output_data_greedy\"\n",
    "    \n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    if not os.path.exists(input_folder):\n",
    "        print(f\"‚ùå L·ªói: Th∆∞ m·ª•c {input_folder} kh√¥ng t·ªìn t·∫°i!\")\n",
    "        return\n",
    "\n",
    "    files = [f for f in os.listdir(input_folder) if f.endswith('.json')]\n",
    "    if len(files) == 0:\n",
    "        print(f\"‚ùå Kh√¥ng t√¨m th·∫•y file d·ªØ li·ªáu n√†o trong {input_folder}\")\n",
    "        return\n",
    "\n",
    "    # Tham s·ªë\n",
    "    INITIAL_ENERGY = 100.0\n",
    "    v_f = 1.2\n",
    "    v_AUV = 3.0\n",
    "    R_SEN = 60\n",
    "    MAX_SIZE = 20\n",
    "    MIN_SIZE = 5\n",
    "    \n",
    "    results_summary = []\n",
    "    clustering = Clustering(space_size=400, r_sen=R_SEN, max_cluster_size=MAX_SIZE, min_cluster_size=MIN_SIZE)\n",
    "\n",
    "    for filename in files:\n",
    "        input_path = os.path.join(input_folder, filename)\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"=== ƒêang x·ª≠ l√Ω file: {filename} ===\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        try:\n",
    "            with open(input_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå L·ªói ƒë·ªçc file {filename}: {e}\")\n",
    "            continue\n",
    "\n",
    "        node_positions = {}\n",
    "        all_nodes = {}\n",
    "        \n",
    "        if isinstance(data, list):\n",
    "            for node in data:\n",
    "                nid = node['id']\n",
    "                all_nodes[nid] = {\n",
    "                    'initial_energy': node.get('initial_energy', INITIAL_ENERGY),\n",
    "                    'residual_energy': node.get('residual_energy', INITIAL_ENERGY)\n",
    "                }\n",
    "                node_positions[nid] = (node['x'], node['y'], node['z'])\n",
    "        else:\n",
    "            print(f\"‚ùå C·∫•u tr√∫c file {filename} kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£\")\n",
    "            continue\n",
    "\n",
    "        total_nodes = len(all_nodes)\n",
    "        print(f\"T·ªïng s·ªë node ban ƒë·∫ßu: {total_nodes}\")\n",
    "        print(f\"Tham s·ªë: r_sen={R_SEN}m, max_size={MAX_SIZE}, min_size={MIN_SIZE}\")\n",
    "        print(\"Ph∆∞∆°ng ph√°p ƒë·ªãnh tuy·∫øn: Tham lam theo th·ªùi gian (Nearest-Time)\")\n",
    "\n",
    "        # Ph√¢n c·ª•m l·∫ßn ƒë·∫ßu\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"PH√ÇN C·ª§M L·∫¶N ƒê·∫¶U TI√äN\")\n",
    "        print(f\"{'='*60}\")\n",
    "        clusters = recluster(all_nodes, node_positions, clustering, R_SEN, MAX_SIZE, MIN_SIZE)\n",
    "        \n",
    "        # T√≠nh ƒë∆∞·ªùng ƒëi l·∫ßn ƒë·∫ßu b·∫±ng tham lam theo th·ªùi gian\n",
    "        centers = [(0,0,0)] + [tuple(clusters[k]['center']) for k in sorted(clusters.keys())]\n",
    "        print(f\"\\nüîç T√≠nh ƒë∆∞·ªùng ƒëi tham lam (th·ªùi gian) ban ƒë·∫ßu...\")\n",
    "        current_path = nearest_neighbor_path(centers, v_f, v_AUV)\n",
    "        current_time = travel_time(current_path, centers, v_f, v_AUV)\n",
    "        print(f\"‚úÖ ƒê∆∞·ªùng ƒëi ban ƒë·∫ßu: {current_time:.2f}s | S·ªë c·ª•m: {len(clusters)}\")\n",
    "        \n",
    "        cycle = 0\n",
    "        alive_log = []\n",
    "        energy_log = []\n",
    "        cluster_count_log = []\n",
    "        reclustering_cycles = []  # L∆∞u c√°c cycle c√≥ ph√¢n c·ª•m l·∫°i\n",
    "\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"üöÄ B·∫ÆT ƒê·∫¶U M√î PH·ªéNG\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        while True:\n",
    "            cycle += 1\n",
    "            alive_log.append(len(all_nodes))\n",
    "            total_energy = sum(all_nodes[n]['residual_energy'] for n in all_nodes)\n",
    "            energy_log.append(total_energy)\n",
    "            cluster_count_log.append(len(clusters))\n",
    "\n",
    "            alive_ratio = len(all_nodes)/total_nodes if total_nodes > 0 else 0\n",
    "            \n",
    "            if alive_ratio < 0.9:\n",
    "                print(f\"\\nüõë D·ª´ng m√¥ ph·ªèng ·ªü cycle {cycle}: < 90% node c√≤n s·ªëng ({alive_ratio*100:.2f}%)\")\n",
    "                break\n",
    "\n",
    "            print(f\"\\n--- Cycle {cycle} --- | Alive: {alive_ratio*100:.2f}% ({len(all_nodes)}/{total_nodes}) | Energy: {total_energy:.2f}J | Clusters: {len(clusters)}\")\n",
    "\n",
    "            # Ch·ªâ ch·ªçn l·∫°i cluster head (KH√îNG ph√¢n c·ª•m l·∫°i)\n",
    "            print(f\"   üîÑ Ch·ªçn l·∫°i cluster head d·ª±a tr√™n nƒÉng l∆∞·ª£ng...\")\n",
    "            clusters = reselect_cluster_heads(clusters, all_nodes)\n",
    "            \n",
    "            # C·∫≠p nh·∫≠t nƒÉng l∆∞·ª£ng v·ªõi ƒë∆∞·ªùng ƒëi hi·ªán t·∫°i\n",
    "            update_energy(all_nodes, clusters, current_time)\n",
    "            \n",
    "            # Ki·ªÉm tra node ch·∫øt\n",
    "            clusters, dead_nodes = remove_dead_nodes(all_nodes, clusters)\n",
    "            \n",
    "            if dead_nodes:\n",
    "                print(f\"   ‚ö° {len(dead_nodes)} node(s) ƒë√£ h·∫øt nƒÉng l∆∞·ª£ng\")\n",
    "                \n",
    "                # C√ì NODE CH·∫æT ‚Üí PH√ÇN C·ª§M L·∫†I V√Ä T√çNH ƒê∆Ø·ªúNG ƒêI M·ªöI (tham lam theo th·ªùi gian)\n",
    "                if len(all_nodes) > 0:\n",
    "                    print(f\"   üîß PH√ÇN C·ª§M L·∫†I do c√≥ node ch·∫øt...\")\n",
    "                    reclustering_cycles.append(cycle)\n",
    "                    clusters = recluster(all_nodes, node_positions, clustering, R_SEN, MAX_SIZE, MIN_SIZE)\n",
    "                    if len(clusters) > 0:\n",
    "                        centers = [(0,0,0)] + [tuple(clusters[k]['center']) for k in sorted(clusters.keys())]\n",
    "                        print(f\"   üîç T√≠nh ƒë∆∞·ªùng ƒëi m·ªõi (tham lam theo th·ªùi gian)...\")\n",
    "                        current_path = nearest_neighbor_path(centers, v_f, v_AUV)\n",
    "                        current_time = travel_time(current_path, centers, v_f, v_AUV)\n",
    "                        print(f\"   ‚úÖ ƒê∆∞·ªùng ƒëi m·ªõi: {current_time:.2f}s | S·ªë c·ª•m m·ªõi: {len(clusters)}\")\n",
    "                    else:\n",
    "                        print(\"   ‚ö†Ô∏è Kh√¥ng c√≤n c·ª•m h·ª£p l·ªá\")\n",
    "                        break\n",
    "                else:\n",
    "                    print(\"   ‚ö†Ô∏è Kh√¥ng c√≤n node s·ªëng\")\n",
    "                    break\n",
    "\n",
    "        # L∆∞u k·∫øt qu·∫£\n",
    "        meta = {\n",
    "            'input_file': filename,\n",
    "            'initial_total_nodes': total_nodes,\n",
    "            'cycles_completed': cycle - 1,\n",
    "            'final_alive_nodes': len(all_nodes),\n",
    "            'final_alive_ratio': len(all_nodes)/total_nodes if total_nodes > 0 else 0,\n",
    "            'reclustering_count': len(reclustering_cycles),\n",
    "            'reclustering_at_cycles': reclustering_cycles,\n",
    "            'method': 'Time-based Greedy Nearest Neighbor with Selective Reclustering',\n",
    "            'strategy': 'Reselect CH every cycle, Recluster only when node dies',\n",
    "            'parameters': {\n",
    "                'r_sen': R_SEN,\n",
    "                'max_cluster_size': MAX_SIZE,\n",
    "                'min_cluster_size': MIN_SIZE,\n",
    "                'v_flow': v_f,\n",
    "                'v_AUV': v_AUV\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        output_json = os.path.join(output_folder, f\"result_{filename}\")\n",
    "        with open(output_json, \"w\") as f:\n",
    "            json.dump(meta, f, indent=4)\n",
    "\n",
    "        results_summary.append((filename, cycle - 1, len(reclustering_cycles)))\n",
    "        print(f\"\\n‚úÖ File {filename}: {cycle - 1} cycles ho√†n th√†nh, {len(reclustering_cycles)} l·∫ßn ph√¢n c·ª•m l·∫°i\")\n",
    "\n",
    "        # Plot k·∫øt qu·∫£\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # Subplot 1: Alive nodes\n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.plot(range(len(alive_log)), alive_log, marker='o', linewidth=2, color='steelblue')\n",
    "        for rc in reclustering_cycles:\n",
    "            plt.axvline(x=rc, color='red', linestyle='--', alpha=0.5)\n",
    "        plt.title(f\"S·ªë node s·ªëng - {filename}\", fontweight='bold')\n",
    "        plt.xlabel(\"Chu k·ª≥\")\n",
    "        plt.ylabel(\"Nodes alive\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.axhline(y=total_nodes*0.9, color='red', linestyle='--', linewidth=2, label='Ng∆∞·ª°ng 90%')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Subplot 2: Energy\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.plot(range(len(energy_log)), energy_log, marker='s', linewidth=2, color='orange')\n",
    "        for rc in reclustering_cycles:\n",
    "            plt.axvline(x=rc, color='red', linestyle='--', alpha=0.5)\n",
    "        plt.title(f\"NƒÉng l∆∞·ª£ng to√†n m·∫°ng - {filename}\", fontweight='bold')\n",
    "        plt.xlabel(\"Chu k·ª≥\")\n",
    "        plt.ylabel(\"Total energy (J)\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Subplot 3: Clusters\n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.plot(range(1, len(cluster_count_log)+1), cluster_count_log, marker='^', linewidth=2, color='green')\n",
    "        for rc in reclustering_cycles:\n",
    "            plt.axvline(x=rc, color='red', linestyle='--', alpha=0.5, label='Ph√¢n c·ª•m l·∫°i' if rc == reclustering_cycles[0] else '')\n",
    "        plt.title(f\"S·ªë c·ª•m - {filename}\", fontweight='bold')\n",
    "        plt.xlabel(\"Chu k·ª≥\")\n",
    "        plt.ylabel(\"S·ªë c·ª•m\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        if reclustering_cycles:\n",
    "            plt.legend()\n",
    "        \n",
    "        # Subplot 4: Info\n",
    "        plt.subplot(2, 2, 4)\n",
    "        plt.axis('off')\n",
    "        alive_ratio = len(all_nodes)/total_nodes if total_nodes>0 else 0\n",
    "        info_text = f\"\"\"\n",
    "        TH·ªêNG K√ä:\n",
    "        ‚Ä¢ T·ªïng cycles: {cycle - 1}\n",
    "        ‚Ä¢ S·ªë l·∫ßn ph√¢n c·ª•m l·∫°i: {len(reclustering_cycles)}\n",
    "        ‚Ä¢ Cycles ph√¢n c·ª•m l·∫°i: {reclustering_cycles[:5]}{'...' if len(reclustering_cycles) > 5 else ''}\n",
    "        ‚Ä¢ Node c√≤n s·ªëng: {len(all_nodes)}/{total_nodes}\n",
    "        ‚Ä¢ T·ªâ l·ªá s·ªëng: {alive_ratio*100:.1f}%\n",
    "        \n",
    "        CHI·∫æN L∆Ø·ª¢C:\n",
    "        ‚Ä¢ M·ªói cycle: Ch·ªçn l·∫°i CH\n",
    "        ‚Ä¢ Khi node ch·∫øt: Ph√¢n c·ª•m + Greedy theo th·ªùi gian\n",
    "        \"\"\"\n",
    "        plt.text(0.1, 0.5, info_text, fontsize=10, verticalalignment='center', family='monospace')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_folder, f\"summary_{filename}.png\"), dpi=150)\n",
    "        plt.close()\n",
    "\n",
    "    # T·ªïng k·∫øt\n",
    "    if results_summary:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"üìä T·ªîNG K·∫æT\")\n",
    "        print(f\"{'='*60}\")\n",
    "        for fname, cycles, recount in results_summary:\n",
    "            print(f\"  {fname}: {cycles} cycles, {recount} l·∫ßn ph√¢n c·ª•m l·∫°i\")\n",
    "        print(f\"\\n‚úÖ Ho√†n th√†nh! K·∫øt qu·∫£ ƒë√£ l∆∞u t·∫°i: {output_folder}\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå Kh√¥ng c√≥ k·∫øt qu·∫£ n√†o ƒë∆∞·ª£c t·∫°o ra\")\n",
    "\n",
    "print(\"‚úì Main function (time-based greedy) loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec634f8-0d7a-403b-80bf-cfdfe71bad34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T18:27:14.247359Z",
     "iopub.status.busy": "2025-11-23T18:27:14.247083Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8816109,
     "sourceId": 13841806,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
