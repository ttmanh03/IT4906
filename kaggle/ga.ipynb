{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec5c394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import pdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aecbdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Clustering:\n",
    "    def __init__(self, space_size=400, r_sen=50, max_cluster_size=20, min_cluster_size=5):\n",
    "        self.space_size = space_size\n",
    "        self.r_sen = r_sen\n",
    "        self.max_cluster_size = max_cluster_size\n",
    "        self.min_cluster_size = min_cluster_size\n",
    "\n",
    "    def estimate_optimal_k(self, nodes, base_station=(200,200,400)):\n",
    "        \"\"\"\n",
    "        ∆Ø·ªõc t√≠nh s·ªë c·ª•m t·ªëi ∆∞u d·ª±a tr√™n c√¥ng th·ª©c WSN\n",
    "        K = sqrt(N*L / (pi*d_tobs))\n",
    "        \"\"\"\n",
    "        N = len(nodes)\n",
    "        base_pos = np.array(base_station)\n",
    "\n",
    "        # Khoang cach trung binh toi base station\n",
    "        distances = np.linalg.norm(nodes - base_pos, axis=1)\n",
    "        d_tobs = np.mean(distances)\n",
    "\n",
    "        space_size = self.space_size\n",
    "\n",
    "        k_optimal = np.sqrt(N * space_size / (np.pi * d_tobs))\n",
    "        k_optimal = max(2, int(np.round(k_optimal)))\n",
    "\n",
    "        # ƒêi·ªÅu ch·ªânh d·ª±a tr√™n max_cluster_size\n",
    "        k_min = int(np.ceil(N / self.max_cluster_size))\n",
    "        k_optimal = max(k_optimal, k_min)\n",
    "        \n",
    "        return k_optimal\n",
    "    \n",
    "    def check_cluster_validity(self, cluster_nodes):\n",
    "        \"\"\"\n",
    "        Kiem tra tinh hop le cua cum\n",
    "        \"\"\"\n",
    "        size = len(cluster_nodes)\n",
    "\n",
    "        # Ki·ªÉm tra k√≠ch th∆∞·ªõc\n",
    "        if size < self.min_cluster_size or size > self.max_cluster_size:\n",
    "            return False, 0, size\n",
    "        \n",
    "        # Ki·ªÉm tra kho·∫£ng c√°ch\n",
    "        if size > 1:\n",
    "            distances = pdist(cluster_nodes)\n",
    "            max_dist = np.max(distances)\n",
    "            \n",
    "            if max_dist > self.r_sen:\n",
    "                return False, max_dist, size\n",
    "            \n",
    "            return True, max_dist, size\n",
    "        \n",
    "        return True, 0, size\n",
    "    \n",
    "    def split_invalid_cluster(self, cluster_nodes, cluster_ids):\n",
    "        \"\"\"\n",
    "        Chia nh·ªè c·ª•m kh√¥ng h·ª£p l·ªá th√†nh c√°c c·ª•m con\n",
    "        \"\"\"\n",
    "        # N·∫øu c·ª•m ch·ªâ c√≥ 1 node, kh√¥ng th·ªÉ chia\n",
    "        if len(cluster_nodes) < 2:\n",
    "            return [(cluster_nodes, cluster_ids)]\n",
    "        \n",
    "        # S·ª≠ d·ª•ng K-Means ƒë·ªÉ chia 2\n",
    "        kmeans = KMeans(n_clusters=2, n_init=20, random_state=42)\n",
    "        labels = kmeans.fit_predict(cluster_nodes)\n",
    "        \n",
    "        sub_clusters = []\n",
    "        for i in range(2):\n",
    "            sub_nodes = cluster_nodes[labels == i]\n",
    "            sub_ids = [cluster_ids[j] for j in range(len(cluster_ids)) if labels[j] == i]\n",
    "            \n",
    "            if len(sub_nodes) > 0:\n",
    "                sub_clusters.append((sub_nodes, sub_ids))\n",
    "        \n",
    "        return sub_clusters\n",
    "    \n",
    "    def merge_small_clusters(self, clusters_data):\n",
    "        \"\"\"\n",
    "        G·ªôp c√°c c·ª•m nh·ªè v·ªõi c·ª•m l√°ng gi·ªÅng g·∫ßn nh·∫•t\n",
    "        \"\"\"\n",
    "        if len(clusters_data) <= 1:\n",
    "            return clusters_data\n",
    "        \n",
    "        merged = []\n",
    "        to_merge = []\n",
    "        \n",
    "        # T√¨m c√°c c·ª•m nh·ªè\n",
    "        for nodes, ids in clusters_data:\n",
    "            if len(nodes) < self.min_cluster_size:\n",
    "                to_merge.append((nodes, ids))\n",
    "            else:\n",
    "                merged.append((nodes, ids))\n",
    "        \n",
    "        # G·ªôp t·ª´ng c·ª•m nh·ªè v√†o c·ª•m g·∫ßn nh·∫•t\n",
    "        for small_nodes, small_ids in to_merge:\n",
    "            if len(merged) == 0:\n",
    "                merged.append((small_nodes, small_ids))\n",
    "                continue\n",
    "            \n",
    "            # T√¨m c·ª•m g·∫ßn nh·∫•t\n",
    "            small_center = np.mean(small_nodes, axis=0)\n",
    "            min_dist = float('inf')\n",
    "            best_idx = 0\n",
    "            \n",
    "            for i, (nodes, ids) in enumerate(merged):\n",
    "                center = np.mean(nodes, axis=0)\n",
    "                dist = np.linalg.norm(small_center - center)\n",
    "                \n",
    "                # Ki·ªÉm tra xem g·ªôp c√≥ v∆∞·ª£t qu√° max_size kh√¥ng\n",
    "                if dist < min_dist and len(nodes) + len(small_nodes) <= self.max_cluster_size:\n",
    "                    min_dist = dist\n",
    "                    best_idx = i\n",
    "            \n",
    "            # G·ªôp\n",
    "            merged[best_idx] = (\n",
    "                np.vstack([merged[best_idx][0], small_nodes]),\n",
    "                merged[best_idx][1] + small_ids\n",
    "            )\n",
    "        \n",
    "        return merged\n",
    "    \n",
    "    def cluster_with_constraints(self, nodes, node_ids, k=None, max_iterations=10):\n",
    "        \"\"\"\n",
    "        Ph√¢n c·ª•m v·ªõi r√†ng bu·ªôc - Thu·∫≠t to√°n ch√≠nh\n",
    "        \n",
    "        Args:\n",
    "            nodes: T·ªça ƒë·ªô 3D c·ªßa nodes\n",
    "            node_ids: ID c·ªßa nodes\n",
    "            k: S·ªë c·ª•m (n·∫øu None s·∫Ω t·ª± ƒë·ªông ∆∞·ªõc t√≠nh)\n",
    "            max_iterations: S·ªë l·∫ßn l·∫∑p t·ªëi ƒëa ƒë·ªÉ ƒëi·ªÅu ch·ªânh\n",
    "            \n",
    "        Returns:\n",
    "            List of (cluster_nodes, cluster_ids)\n",
    "        \"\"\"\n",
    "        if k is None:\n",
    "            k = self.estimate_optimal_k(nodes)\n",
    "        \n",
    "        print(f\"B·∫Øt ƒë·∫ßu ph√¢n c·ª•m v·ªõi k={k}\")\n",
    "        \n",
    "        # B∆∞·ªõc 1: K-Means ban ƒë·∫ßu\n",
    "        kmeans = KMeans(n_clusters=k, n_init=30, random_state=42)\n",
    "        labels = kmeans.fit_predict(nodes)\n",
    "        \n",
    "        # B∆∞·ªõc 2: T·∫°o c√°c c·ª•m v√† ki·ªÉm tra\n",
    "        iteration = 0\n",
    "        while iteration < max_iterations:\n",
    "            print(f\"  V√≤ng l·∫∑p {iteration + 1}/{max_iterations}\")\n",
    "            \n",
    "            valid_clusters = []\n",
    "            invalid_clusters = []\n",
    "            \n",
    "            # Ph√¢n lo·∫°i c·ª•m h·ª£p l·ªá v√† kh√¥ng h·ª£p l·ªá\n",
    "            for i in range(k):\n",
    "                cluster_nodes = nodes[labels == i]\n",
    "                cluster_ids = [node_ids[j] for j in range(len(node_ids)) if labels[j] == i]\n",
    "                \n",
    "                if len(cluster_nodes) == 0:\n",
    "                    continue\n",
    "                \n",
    "                is_valid, max_dist, size = self.check_cluster_validity(cluster_nodes)\n",
    "                \n",
    "                if is_valid:\n",
    "                    valid_clusters.append((cluster_nodes, cluster_ids))\n",
    "                    print(f\"    C·ª•m {i}: ‚úì h·ª£p l·ªá (size={size}, max_dist={max_dist:.1f}m)\")\n",
    "                else:\n",
    "                    invalid_clusters.append((cluster_nodes, cluster_ids))\n",
    "                    print(f\"    C·ª•m {i}: ‚úó kh√¥ng h·ª£p l·ªá (size={size}, max_dist={max_dist:.1f}m)\")\n",
    "            \n",
    "            # N·∫øu t·∫•t c·∫£ h·ª£p l·ªá, k·∫øt th√∫c\n",
    "            if len(invalid_clusters) == 0:\n",
    "                print(f\"  ‚Üí T·∫•t c·∫£ c·ª•m h·ª£p l·ªá!\")\n",
    "                break\n",
    "            \n",
    "            # B∆∞·ªõc 3: X·ª≠ l√Ω c√°c c·ª•m kh√¥ng h·ª£p l·ªá\n",
    "            for cluster_nodes, cluster_ids in invalid_clusters:\n",
    "                size = len(cluster_nodes)\n",
    "                \n",
    "                if size > self.max_cluster_size:\n",
    "                    # C·ª•m qu√° l·ªõn ‚Üí Chia nh·ªè\n",
    "                    print(f\"    ‚Üí Chia c·ª•m (size={size})\")\n",
    "                    sub_clusters = self.split_invalid_cluster(cluster_nodes, cluster_ids)\n",
    "                    valid_clusters.extend(sub_clusters)\n",
    "                else:\n",
    "                    # C·ª•m c√≥ kho·∫£ng c√°ch qu√° l·ªõn ‚Üí Chia nh·ªè\n",
    "                    print(f\"    ‚Üí Chia c·ª•m (kho·∫£ng c√°ch l·ªõn)\")\n",
    "                    sub_clusters = self.split_invalid_cluster(cluster_nodes, cluster_ids)\n",
    "                    valid_clusters.extend(sub_clusters)\n",
    "            \n",
    "            # C·∫≠p nh·∫≠t labels v√† k cho v√≤ng l·∫∑p ti·∫øp theo\n",
    "            k = len(valid_clusters)\n",
    "            \n",
    "            # T·∫°o l·∫°i labels t·ª´ valid_clusters\n",
    "            labels = np.zeros(len(nodes), dtype=int)\n",
    "            for cluster_idx, (_, cluster_ids) in enumerate(valid_clusters):\n",
    "                for node_id in cluster_ids:\n",
    "                    node_idx = node_ids.index(node_id)\n",
    "                    labels[node_idx] = cluster_idx\n",
    "            \n",
    "            iteration += 1\n",
    "        \n",
    "        # B∆∞·ªõc 4: G·ªôp c√°c c·ª•m qu√° nh·ªè\n",
    "        valid_clusters = self.merge_small_clusters(valid_clusters)\n",
    "        \n",
    "        print(f\"Ho√†n th√†nh: {len(valid_clusters)} c·ª•m\")\n",
    "        return valid_clusters\n",
    "    \n",
    "    def choose_cluster_head(self, cluster_nodes, cluster_ids, node_data=None):\n",
    "        \"\"\"\n",
    "        Ch·ªçn cluster head\n",
    "        - ∆Øu ti√™n: Node c√≥ nƒÉng l∆∞·ª£ng cao nh·∫•t\n",
    "        - D·ª± ph√≤ng: Node g·∫ßn t√¢m c·ª•m nh·∫•t\n",
    "        \"\"\"\n",
    "        if node_data:\n",
    "            # Ch·ªçn theo nƒÉng l∆∞·ª£ng\n",
    "            max_energy = -1\n",
    "            ch_id = cluster_ids[0]\n",
    "            \n",
    "            for nid in cluster_ids:\n",
    "                if nid in node_data and 'residual_energy' in node_data[nid]:\n",
    "                    energy = node_data[nid]['residual_energy']\n",
    "                    if energy > max_energy:\n",
    "                        max_energy = energy\n",
    "                        ch_id = nid\n",
    "            \n",
    "            return ch_id\n",
    "        else:\n",
    "            # Ch·ªçn theo kho·∫£ng c√°ch ƒë·∫øn t√¢m\n",
    "            center = np.mean(cluster_nodes, axis=0)\n",
    "            distances = np.linalg.norm(cluster_nodes - center, axis=1)\n",
    "            min_idx = np.argmin(distances)\n",
    "            return cluster_ids[min_idx]\n",
    "    \n",
    "    def calculate_metrics(self, clusters_data):\n",
    "        \"\"\"\n",
    "        T√≠nh c√°c metric ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng ph√¢n c·ª•m\n",
    "        \"\"\"\n",
    "        metrics = {\n",
    "            'num_clusters': len(clusters_data),\n",
    "            'avg_cluster_size': 0,\n",
    "            'min_cluster_size': float('inf'),\n",
    "            'max_cluster_size': 0,\n",
    "            'avg_intra_distance': 0,\n",
    "            'max_intra_distance': 0,\n",
    "            'balance_score': 0  # ƒê·ªô c√¢n b·∫±ng k√≠ch th∆∞·ªõc c·ª•m (0-1, c√†ng cao c√†ng t·ªët)\n",
    "        }\n",
    "        \n",
    "        sizes = []\n",
    "        intra_dists = []\n",
    "        \n",
    "        for nodes, ids in clusters_data:\n",
    "            size = len(nodes)\n",
    "            sizes.append(size)\n",
    "            \n",
    "            metrics['min_cluster_size'] = min(metrics['min_cluster_size'], size)\n",
    "            metrics['max_cluster_size'] = max(metrics['max_cluster_size'], size)\n",
    "            \n",
    "            if size > 1:\n",
    "                distances = pdist(nodes)\n",
    "                intra_dists.append(np.mean(distances))\n",
    "                metrics['max_intra_distance'] = max(metrics['max_intra_distance'], np.max(distances))\n",
    "        \n",
    "        metrics['avg_cluster_size'] = np.mean(sizes)\n",
    "        metrics['avg_intra_distance'] = np.mean(intra_dists) if intra_dists else 0\n",
    "        \n",
    "        # T√≠nh balance score (d·ª±a tr√™n coefficient of variation)\n",
    "        cv = np.std(sizes) / np.mean(sizes) if np.mean(sizes) > 0 else 0\n",
    "        metrics['balance_score'] = 1 / (1 + cv)  # 1 = ho√†n to√†n c√¢n b·∫±ng\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "def process_data(input_file, output_folder, draw_folder, \n",
    "                    r_sen=50, max_size=20, min_size=5):\n",
    "    with open(input_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    nodes = np.array([[d['x'], d['y'], d['z']] for d in data])\n",
    "    node_ids = [d['id'] for d in data]\n",
    "    \n",
    "    # T·∫°o node_data v·ªõi th√¥ng tin nƒÉng l∆∞·ª£ng\n",
    "    node_data = {}\n",
    "    for d in data:\n",
    "        if 'residual_energy' in d:\n",
    "            node_data[d['id']] = {\n",
    "                'residual_energy': d['residual_energy'],\n",
    "                'initial_energy': d.get('initial_energy', 100.0)\n",
    "            }\n",
    "    \n",
    "    # Kh·ªüi t·∫°o clustering\n",
    "    clustering = Clustering(\n",
    "        r_sen=r_sen,\n",
    "        max_cluster_size=max_size,\n",
    "        min_cluster_size=min_size\n",
    "    )\n",
    "    \n",
    "    # Ph√¢n c·ª•m\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"X·ª≠ l√Ω: {os.path.basename(input_file)}\")\n",
    "    print(f\"S·ªë nodes: {len(nodes)}\")\n",
    "    print(f\"Tham s·ªë: r_sen={r_sen}m, max_size={max_size}, min_size={min_size}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    clusters_data = clustering.cluster_with_constraints(nodes, node_ids)\n",
    "    \n",
    "    # T√≠nh metrics\n",
    "    metrics = clustering.calculate_metrics(clusters_data)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"K·∫æT QU·∫¢:\")\n",
    "    print(f\"  S·ªë c·ª•m: {metrics['num_clusters']}\")\n",
    "    print(f\"  K√≠ch th∆∞·ªõc trung b√¨nh: {metrics['avg_cluster_size']:.1f}\")\n",
    "    print(f\"  K√≠ch th∆∞·ªõc: [{metrics['min_cluster_size']} - {metrics['max_cluster_size']}]\")\n",
    "    print(f\"  Kho·∫£ng c√°ch trung b√¨nh trong c·ª•m: {metrics['avg_intra_distance']:.1f}m\")\n",
    "    print(f\"  Kho·∫£ng c√°ch max trong c·ª•m: {metrics['max_intra_distance']:.1f}m\")\n",
    "    print(f\"  ƒê·ªô c√¢n b·∫±ng: {metrics['balance_score']:.2%}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # T·∫°o output\n",
    "    output_data = {}\n",
    "    for i, (cluster_nodes, cluster_ids) in enumerate(clusters_data):\n",
    "        ch = clustering.choose_cluster_head(cluster_nodes, cluster_ids, node_data)\n",
    "        center = np.mean(cluster_nodes, axis=0)\n",
    "        \n",
    "        output_data[i] = {\n",
    "            'nodes': cluster_ids,\n",
    "            'center': [float(x) for x in np.round(center, 2)],\n",
    "            'cluster_head': int(ch),\n",
    "            'size': len(cluster_ids)\n",
    "        }\n",
    "    \n",
    "    # L∆∞u output\n",
    "    output_file = os.path.join(output_folder, os.path.basename(input_file))\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(output_data, f, indent=4)\n",
    "    print(f\"‚úì ƒê√£ l∆∞u: {output_file}\")\n",
    "    \n",
    "    # V·∫Ω bi·ªÉu ƒë·ªì\n",
    "    draw_file = os.path.join(draw_folder, \n",
    "                            os.path.basename(input_file).replace('.json', '.png'))\n",
    "    visualize_clusters(nodes, clusters_data, output_data, draw_file)\n",
    "    print(f\"‚úì ƒê√£ v·∫Ω: {draw_file}\")\n",
    "    \n",
    "    return output_data, metrics\n",
    "\n",
    "def visualize_clusters(nodes, clusters_data, output_data, save_path):\n",
    "    \"\"\"\n",
    "    V·∫Ω bi·ªÉu ƒë·ªì 3D c√°c c·ª•m\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(12, 9))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    num_clusters = len(clusters_data)\n",
    "    cmap = plt.colormaps.get_cmap('tab20' if num_clusters > 10 else 'tab10')\n",
    "    \n",
    "    for i, (cluster_nodes, cluster_ids) in enumerate(clusters_data):\n",
    "        color = cmap(i % 20)\n",
    "        \n",
    "        # V·∫Ω nodes\n",
    "        ax.scatter(cluster_nodes[:, 0], cluster_nodes[:, 1], cluster_nodes[:, 2],\n",
    "                  label=f'C·ª•m {i} ({len(cluster_ids)})',\n",
    "                  color=color, alpha=0.6, s=50)\n",
    "        \n",
    "        # V·∫Ω cluster head\n",
    "        ch_id = output_data[i]['cluster_head']\n",
    "        ch_idx = cluster_ids.index(ch_id)\n",
    "        ch_pos = cluster_nodes[ch_idx]\n",
    "        ax.scatter(ch_pos[0], ch_pos[1], ch_pos[2],\n",
    "                  color=color, marker='*', s=400, \n",
    "                  edgecolor='black', linewidth=1.5, zorder=100)\n",
    "        \n",
    "        # V·∫Ω t√¢m c·ª•m\n",
    "        center = output_data[i]['center']\n",
    "        ax.scatter(center[0], center[1], center[2],\n",
    "                  color=color, marker='x', s=100, linewidth=2, zorder=90)\n",
    "    \n",
    "    # V·∫Ω base station\n",
    "    ax.scatter(0, 0, 0, color='red', marker='^', s=500,\n",
    "              label='Base Station', edgecolor='black', linewidth=2, zorder=110)\n",
    "    \n",
    "    ax.set_xlabel('X (m)', fontsize=11)\n",
    "    ax.set_ylabel('Y (m)', fontsize=11)\n",
    "    ax.set_zlabel('Z (m)', fontsize=11)\n",
    "    ax.set_title(f'WSN Clustering - {len(nodes)} nodes, {num_clusters} c·ª•m',\n",
    "                fontsize=13, fontweight='bold')\n",
    "    \n",
    "    if num_clusters <= 15:\n",
    "        ax.legend(loc='upper left', bbox_to_anchor=(1.02, 1), fontsize=9)\n",
    "    \n",
    "    ax.view_init(elev=25, azim=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=100, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "# ===== MAIN EXECUTION =====\n",
    "if __name__ == \"__main__\":\n",
    "    # T·∫°o th∆∞ m·ª•c output\n",
    "    input_folder = \"IT4906/input_data\"\n",
    "    output_folder = \"output_data_optimized\"\n",
    "    draw_folder = \"draw_output_optimized\"\n",
    "    \n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    os.makedirs(draw_folder, exist_ok=True)\n",
    "    \n",
    "    # Tham s·ªë\n",
    "    R_SEN = 60 # B√°n k√≠nh truy·ªÅn t·∫£i (m)\n",
    "    MAX_SIZE = 20  # K√≠ch th∆∞·ªõc c·ª•m t·ªëi ƒëa\n",
    "    MIN_SIZE = 5  # K√≠ch th∆∞·ªõc c·ª•m t·ªëi thi·ªÉu\n",
    "    \n",
    "    # X·ª≠ l√Ω t·ª´ng file\n",
    "    all_metrics = {}\n",
    "    \n",
    "    for filename in sorted(os.listdir(input_folder)):\n",
    "        if filename.startswith(\"nodes_\") and filename.endswith(\".json\"):\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            \n",
    "            try:\n",
    "                output_data, metrics = process_data(\n",
    "                    input_path, output_folder, draw_folder,\n",
    "                    r_sen=R_SEN, max_size=MAX_SIZE, min_size=MIN_SIZE\n",
    "                )\n",
    "                all_metrics[filename] = metrics\n",
    "            except Exception as e:\n",
    "                print(f\"‚úó L·ªói x·ª≠ l√Ω {filename}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    # T·ªïng k·∫øt\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"T·ªîNG K·∫æT TO√ÄN B·ªò\")\n",
    "    print(\"=\"*60)\n",
    "    for filename, metrics in all_metrics.items():\n",
    "        print(f\"\\n{filename}:\")\n",
    "        print(f\"  C·ª•m: {metrics['num_clusters']}, \"\n",
    "              f\"Size: {metrics['avg_cluster_size']:.1f} ¬± \"\n",
    "              f\"{metrics['max_cluster_size']-metrics['min_cluster_size']}, \"\n",
    "              f\"Balance: {metrics['balance_score']:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a7ebeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_vs(p1, p2, v_f, v_AUV):\n",
    "    x1, y1, z1 = p1\n",
    "    x2, y2, z2 = p2\n",
    "    Lx, Ly, Lz = x2 - x1, y2 - y1, z2 - z1\n",
    "    L_mag = math.sqrt(Lx**2 + Ly**2 + Lz**2)\n",
    "    if L_mag == 0:\n",
    "        return v_AUV\n",
    "    cos_beta = Lz / L_mag\n",
    "    cos_beta = np.clip(cos_beta, -1, 1)\n",
    "    beta = math.acos(cos_beta)\n",
    "    inner = np.clip((v_f * cos_beta) / v_AUV, -1, 1)\n",
    "    angle = beta + math.acos(inner)\n",
    "    if abs(cos_beta) < 1e-9:\n",
    "        return v_AUV\n",
    "    return abs(math.cos(angle) * v_AUV / cos_beta)\n",
    "\n",
    "def travel_time(path, coords, v_f, v_AUV):\n",
    "    total_time = 0.0\n",
    "    if len(path) <= 1:\n",
    "        return 0.0\n",
    "    for i in range(len(path) - 1):\n",
    "        p1, p2 = coords[path[i]], coords[path[i + 1]]\n",
    "        d = np.linalg.norm(np.array(p2) - np.array(p1))\n",
    "        v_s = compute_vs(tuple(p1), tuple(p2), v_f, v_AUV)\n",
    "        total_time += d / max(v_s, 1e-9)\n",
    "    # return to start\n",
    "    p1, p2 = coords[path[-1]], coords[path[0]]\n",
    "    d = np.linalg.norm(np.array(p2) - np.array(p1))\n",
    "    v_s = compute_vs(tuple(p1), tuple(p2), v_f, v_AUV)\n",
    "    total_time += d / max(v_s, 1e-9)\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333849b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusterTSP_GA:\n",
    "    \"\"\"GA t·ªëi ∆∞u h√≥a tour qua c√°c cluster centers, s·ª≠ d·ª•ng travel_time/compute_vs ƒë·ªÉ t√≠nh m·ª•c ti√™u (th·ªùi gian).\"\"\"\n",
    "    def __init__(self, clusters, ga_params=None):\n",
    "        # clusters: dict mapping cluster_id -> {\"center\": (x,y,z), ...}\n",
    "        self.clusters = clusters\n",
    "        # t·∫°o list centers v·ªõi ƒëi·ªÉm b·∫Øt ƒë·∫ßu ·ªü index 0\n",
    "        self.cluster_centers = [(0.0, 0.0, 0.0)] + [clusters[k][\"center\"] for k in sorted(clusters.keys())]\n",
    "        self.n = len(self.cluster_centers)\n",
    "\n",
    "        # default params\n",
    "        defaults = {\n",
    "            'pop_size': 50,\n",
    "            'generations': 200,\n",
    "            'crossover_rate': 0.8,\n",
    "            'mutation_rate': 0.2,\n",
    "            'elitism_k': 3,\n",
    "            'tournament_size': 3,\n",
    "            'crossover_type': 'OX',\n",
    "            'mutation_type': 'inversion',\n",
    "            'local_search': True,\n",
    "            'v_f': 0.3,\n",
    "            'v_AUV': 1.0,\n",
    "            'verbose': False\n",
    "        }\n",
    "        if ga_params:\n",
    "            defaults.update(ga_params)\n",
    "        self.params = defaults\n",
    "\n",
    "        self.best_fitness_history = []\n",
    "        self.avg_fitness_history = []\n",
    "\n",
    "    def create_individual(self):\n",
    "        seq = list(range(1, self.n))\n",
    "        random.shuffle(seq)\n",
    "        return [0] + seq\n",
    "\n",
    "    def create_population(self):\n",
    "        pop = []\n",
    "        # add a nearest neighbor as seed\n",
    "        pop.append(self.nearest_neighbor(0))\n",
    "        while len(pop) < self.params['pop_size']:\n",
    "            pop.append(self.create_individual())\n",
    "        return pop\n",
    "\n",
    "    def nearest_neighbor(self, start=0):\n",
    "        unvisited = set(range(1, self.n))\n",
    "        tour = [start]\n",
    "        cur = start\n",
    "        while unvisited:\n",
    "            nxt = min(unvisited, key=lambda x: np.linalg.norm(np.array(self.cluster_centers[cur]) - np.array(self.cluster_centers[x])))\n",
    "            tour.append(nxt)\n",
    "            unvisited.remove(nxt)\n",
    "            cur = nxt\n",
    "        return tour\n",
    "\n",
    "    def fitness(self, individual):\n",
    "        # fitness = 1 / total_time\n",
    "        total_time = travel_time(individual, self.cluster_centers, self.params['v_f'], self.params['v_AUV'])\n",
    "        return 1.0 / (total_time + 1e-9)\n",
    "\n",
    "    def tournament_selection(self, population):\n",
    "        candidates = random.sample(population, self.params['tournament_size'])\n",
    "        return max(candidates, key=self.fitness)\n",
    "\n",
    "    def order_crossover(self, p1, p2):\n",
    "        # OX on subarray excluding index 0\n",
    "        sub1 = p1[1:]\n",
    "        sub2 = p2[1:]\n",
    "        m = len(sub1)\n",
    "        if m < 2:\n",
    "            return p1.copy(), p2.copy()\n",
    "        a, b = sorted(random.sample(range(m), 2))\n",
    "        c1 = [-1]*m\n",
    "        c2 = [-1]*m\n",
    "        c1[a:b] = sub1[a:b]\n",
    "        ptr = b\n",
    "        for x in sub2[b:]+sub2[:b]:\n",
    "            if x not in c1:\n",
    "                c1[ptr % m] = x\n",
    "                ptr += 1\n",
    "        c2[a:b] = sub2[a:b]\n",
    "        ptr = b\n",
    "        for x in sub1[b:]+sub1[:b]:\n",
    "            if x not in c2:\n",
    "                c2[ptr % m] = x\n",
    "                ptr += 1\n",
    "        return [0]+c1, [0]+c2\n",
    "\n",
    "    def pmx_crossover(self, p1, p2):\n",
    "        sub1 = p1[1:]\n",
    "        sub2 = p2[1:]\n",
    "        m = len(sub1)\n",
    "        if m < 2:\n",
    "            return p1.copy(), p2.copy()\n",
    "        a, b = sorted(random.sample(range(m), 2))\n",
    "        c1 = [-1]*m\n",
    "        c2 = [-1]*m\n",
    "        c1[a:b] = sub1[a:b]\n",
    "        c2[a:b] = sub2[a:b]\n",
    "        mapping1 = {sub1[i]: sub2[i] for i in range(a,b)}\n",
    "        mapping2 = {sub2[i]: sub1[i] for i in range(a,b)}\n",
    "        for i in list(range(0,a)) + list(range(b,m)):\n",
    "            val = sub2[i]\n",
    "            while val in mapping1:\n",
    "                val = mapping1[val]\n",
    "            c1[i] = val\n",
    "            val = sub1[i]\n",
    "            while val in mapping2:\n",
    "                val = mapping2[val]\n",
    "            c2[i] = val\n",
    "        return [0]+c1, [0]+c2\n",
    "\n",
    "    def swap_mutation(self, ind):\n",
    "        ind = ind.copy()\n",
    "        if len(ind) > 2:\n",
    "            i, j = random.sample(range(1, len(ind)), 2)\n",
    "            ind[i], ind[j] = ind[j], ind[i]\n",
    "        return ind\n",
    "\n",
    "    def inversion_mutation(self, ind):\n",
    "        ind = ind.copy()\n",
    "        if len(ind) > 2:\n",
    "            i, j = sorted(random.sample(range(1, len(ind)), 2))\n",
    "            ind[i:j+1] = list(reversed(ind[i:j+1]))\n",
    "        return ind\n",
    "\n",
    "    def two_opt(self, tour):\n",
    "        improved = True\n",
    "        best = tour.copy()\n",
    "        best_time = travel_time(best, self.cluster_centers, self.params['v_f'], self.params['v_AUV'])\n",
    "        while improved:\n",
    "            improved = False\n",
    "            for i in range(1, len(best)-2):\n",
    "                for j in range(i+1, len(best)-1):\n",
    "                    cand = best.copy()\n",
    "                    cand[i:j+1] = list(reversed(cand[i:j+1]))\n",
    "                    t = travel_time(cand, self.cluster_centers, self.params['v_f'], self.params['v_AUV'])\n",
    "                    if t < best_time:\n",
    "                        best = cand\n",
    "                        best_time = t\n",
    "                        improved = True\n",
    "                        break\n",
    "                if improved:\n",
    "                    break\n",
    "        return best\n",
    "\n",
    "    def evolve(self):\n",
    "        pop = self.create_population()\n",
    "        best = max(pop, key=self.fitness)\n",
    "        best_time = travel_time(best, self.cluster_centers, self.params['v_f'], self.params['v_AUV'])\n",
    "        for gen in range(self.params['generations']):\n",
    "            fitnesses = [self.fitness(ind) for ind in pop]\n",
    "            self.best_fitness_history.append(max(fitnesses))\n",
    "            self.avg_fitness_history.append(float(np.mean(fitnesses)))\n",
    "            gen_best = pop[np.argmax(fitnesses)]\n",
    "            gen_best_time = travel_time(gen_best, self.cluster_centers, self.params['v_f'], self.params['v_AUV'])\n",
    "            if gen_best_time < best_time:\n",
    "                best = gen_best.copy()\n",
    "                best_time = gen_best_time\n",
    "                if self.params['verbose'] and gen % 50 == 0:\n",
    "                    print(f\"   Gen {gen}: new best time = {best_time:.4f} s\")\n",
    "\n",
    "            # elite\n",
    "            elite_idx = np.argsort(fitnesses)[-self.params['elitism_k']:]\n",
    "            new_pop = [pop[i].copy() for i in elite_idx]\n",
    "            while len(new_pop) < self.params['pop_size']:\n",
    "                p1 = self.tournament_selection(pop)\n",
    "                p2 = self.tournament_selection(pop)\n",
    "                if random.random() < self.params['crossover_rate']:\n",
    "                    if self.params['crossover_type'] == 'OX':\n",
    "                        c1, c2 = self.order_crossover(p1, p2)\n",
    "                    else:\n",
    "                        c1, c2 = self.pmx_crossover(p1, p2)\n",
    "                else:\n",
    "                    c1, c2 = p1.copy(), p2.copy()\n",
    "\n",
    "                if random.random() < self.params['mutation_rate']:\n",
    "                    if self.params['mutation_type'] == 'swap':\n",
    "                        c1 = self.swap_mutation(c1)\n",
    "                    else:\n",
    "                        c1 = self.inversion_mutation(c1)\n",
    "                if random.random() < self.params['mutation_rate']:\n",
    "                    if self.params['mutation_type'] == 'swap':\n",
    "                        c2 = self.swap_mutation(c2)\n",
    "                    else:\n",
    "                        c2 = self.inversion_mutation(c2)\n",
    "\n",
    "                if self.params['local_search'] and random.random() < 0.1:\n",
    "                    c1 = self.two_opt(c1)\n",
    "                    c2 = self.two_opt(c2)\n",
    "\n",
    "                new_pop.extend([c1, c2])\n",
    "\n",
    "            pop = new_pop[:self.params['pop_size']]\n",
    "\n",
    "        return best, best_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e739a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_energy(best_time, n_members):\n",
    "    \"\"\"\n",
    "    T√≠nh nƒÉng l∆∞·ª£ng ti√™u th·ª• cho Member Node v√† Cluster Head.\n",
    "    \n",
    "    Parameters:\n",
    "    - best_time: Th·ªùi gian ho√†n th√†nh chu k·ª≥ AUV\n",
    "    - n_members: S·ªë l∆∞·ª£ng node th√†nh vi√™n th·ª±c t·∫ø trong cluster (kh√¥ng t√≠nh cluster head)\n",
    "    \"\"\"\n",
    "    G, L = 100, 1024\n",
    "    P_t, P_r, P_idle, DR, DR_i = 1.6e-3, 0.8e-3, 0.1e-3, 4000, 1e6\n",
    "\n",
    "    # NƒÉng l∆∞·ª£ng cho Member Node\n",
    "    E_tx_MN = G * P_t * L / DR\n",
    "    E_idle_MN = (best_time - G * L / DR) * P_idle\n",
    "    E_total_MN = E_tx_MN + E_idle_MN\n",
    "\n",
    "    # NƒÉng l∆∞·ª£ng cho Cluster Head (nh·∫≠n t·ª´ n_members node, truy·ªÅn cho AUV)\n",
    "    E_rx_TN = G * P_r * L * n_members / DR\n",
    "    E_tx_TN = G * P_t * L * n_members / DR_i\n",
    "    E_idle_TN = (best_time - (G*L*n_members/DR) - (G*L*n_members/DR_i)) * P_idle\n",
    "    E_total_TN = E_rx_TN + E_tx_TN + E_idle_TN\n",
    "\n",
    "    return {\n",
    "        \"Member\": {\"E_total\": E_total_MN},\n",
    "        \"Target\": {\"E_total\": E_total_TN}\n",
    "    }\n",
    "\n",
    "def update_energy(all_nodes, clusters, best_time):\n",
    "    \"\"\"\n",
    "    C·∫≠p nh·∫≠t nƒÉng l∆∞·ª£ng cho t·∫•t c·∫£ c√°c node d·ª±a tr√™n s·ªë member th·ª±c t·∫ø c·ªßa t·ª´ng cluster.\n",
    "    \n",
    "    Parameters:\n",
    "    - all_nodes: Dictionary ch·ª©a th√¥ng tin t·∫•t c·∫£ c√°c node\n",
    "    - clusters: Dictionary ch·ª©a th√¥ng tin c√°c cluster\n",
    "    - best_time: Th·ªùi gian ho√†n th√†nh chu k·ª≥ AUV\n",
    "    \"\"\"\n",
    "    for cid, cinfo in clusters.items():\n",
    "        ch = cinfo.get('cluster_head')\n",
    "        nodes = cinfo.get('nodes', [])\n",
    "        \n",
    "        # T√≠nh s·ªë member nodes (kh√¥ng t√≠nh cluster head)\n",
    "        n_members = len([n for n in nodes if n != ch])\n",
    "        \n",
    "        # T√≠nh nƒÉng l∆∞·ª£ng cho cluster n√†y v·ªõi s·ªë member th·ª±c t·∫ø\n",
    "        energy_report = compute_energy(best_time, n_members)\n",
    "        \n",
    "        for nid in nodes:\n",
    "            if nid not in all_nodes: continue\n",
    "            if nid == ch:\n",
    "                all_nodes[nid]['residual_energy'] -= energy_report['Target']['E_total']\n",
    "            else:\n",
    "                all_nodes[nid]['residual_energy'] -= energy_report['Member']['E_total']\n",
    "            all_nodes[nid]['residual_energy'] = max(all_nodes[nid]['residual_energy'], 0.0)\n",
    "\n",
    "def remove_dead_nodes(all_nodes, clusters):\n",
    "    \"\"\"\n",
    "    Lo·∫°i b·ªè c√°c node ƒë√£ h·∫øt nƒÉng l∆∞·ª£ng v√† c·∫≠p nh·∫≠t l·∫°i clusters.\n",
    "    \n",
    "    Returns:\n",
    "    - new_clusters: Dictionary c√°c cluster c√≤n node s·ªëng\n",
    "    - dead: List c√°c node_id ƒë√£ ch·∫øt\n",
    "    \"\"\"\n",
    "    dead = [nid for nid, info in list(all_nodes.items()) if info['residual_energy'] <= 0]\n",
    "    for nid in dead:\n",
    "        del all_nodes[nid]\n",
    "\n",
    "    new_clusters = {}\n",
    "    for cid, cinfo in clusters.items():\n",
    "        alive_nodes = [nid for nid in cinfo.get('nodes', []) if nid in all_nodes]\n",
    "        if alive_nodes:\n",
    "            new_c = dict(cinfo)\n",
    "            new_c['nodes'] = alive_nodes\n",
    "            new_clusters[cid] = new_c\n",
    "\n",
    "    return new_clusters, dead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4012ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ga_path_optimization(clusters, v_f, v_AUV, verbose=False):\n",
    "    \"\"\"\n",
    "    S·ª≠ d·ª•ng Genetic Algorithm ƒë·ªÉ t√¨m ƒë∆∞·ªùng ƒëi t·ªëi ∆∞u qua c√°c cluster.\n",
    "    \n",
    "    Parameters:\n",
    "    - clusters: Dictionary c√°c cluster v·ªõi center\n",
    "    - v_f: V·∫≠n t·ªëc d√≤ng ch·∫£y\n",
    "    - v_AUV: V·∫≠n t·ªëc AUV\n",
    "    - verbose: In th√¥ng tin ti·∫øn tr√¨nh GA\n",
    "    \n",
    "    Returns:\n",
    "    - path_indices: List c√°c index theo th·ª© t·ª± thƒÉm\n",
    "    - best_time: Th·ªùi gian t·ªëi ∆∞u\n",
    "    \"\"\"\n",
    "    if len(clusters) == 0:\n",
    "        return [0], 0.0\n",
    "    \n",
    "    ga_params = {\n",
    "        'pop_size': 40,\n",
    "        'generations': 150,\n",
    "        'crossover_rate': 0.8,\n",
    "        'mutation_rate': 0.2,\n",
    "        'elitism_k': 3,\n",
    "        'local_search': True,\n",
    "        'v_f': v_f,\n",
    "        'v_AUV': v_AUV,\n",
    "        'verbose': verbose\n",
    "    }\n",
    "    \n",
    "    ga = ClusterTSP_GA(clusters, ga_params)\n",
    "    best_path, best_time = ga.evolve()\n",
    "    \n",
    "    return best_path, best_time\n",
    "\n",
    "def recluster(all_nodes, node_positions, clustering_instance, r_sen=60, max_size=20, min_size=5):\n",
    "    \"\"\"\n",
    "    Ph√¢n c·ª•m l·∫°i to√†n b·ªô c√°c node c√≤n s·ªëng s·ª≠ d·ª•ng thu·∫≠t to√°n t·ª´ cluster.py.\n",
    "    \n",
    "    Parameters:\n",
    "    - all_nodes: Dictionary c√°c node c√≤n s·ªëng\n",
    "    - node_positions: Dictionary v·ªã tr√≠ c·ªßa c√°c node\n",
    "    - clustering_instance: Instance c·ªßa class Clustering\n",
    "    - r_sen: Ng∆∞·ª°ng kho·∫£ng c√°ch t·ªëi ƒëa trong c·ª•m\n",
    "    - max_size: S·ªë l∆∞·ª£ng node t·ªëi ƒëa trong 1 c·ª•m\n",
    "    - min_size: S·ªë l∆∞·ª£ng node t·ªëi thi·ªÉu trong 1 c·ª•m\n",
    "    \n",
    "    Returns:\n",
    "    - clusters: Dictionary c√°c c·ª•m m·ªõi\n",
    "    \"\"\"\n",
    "    ids = sorted(list(all_nodes.keys()))\n",
    "    if len(ids) == 0:\n",
    "        return {}\n",
    "\n",
    "    # T·∫°o m·∫£ng t·ªça ƒë·ªô nodes\n",
    "    coords = np.array([node_positions[nid] for nid in ids])\n",
    "    \n",
    "    # C·∫≠p nh·∫≠t tham s·ªë cho clustering instance\n",
    "    clustering_instance.r_sen = r_sen\n",
    "    clustering_instance.max_cluster_size = max_size\n",
    "    clustering_instance.min_cluster_size = min_size\n",
    "    \n",
    "    # Ph√¢n c·ª•m v·ªõi r√†ng bu·ªôc\n",
    "    clusters_data = clustering_instance.cluster_with_constraints(coords, ids)\n",
    "    \n",
    "    # Chuy·ªÉn ƒë·ªïi sang format c·∫ßn thi·∫øt\n",
    "    clusters = {}\n",
    "    for i, (cluster_nodes, cluster_ids) in enumerate(clusters_data):\n",
    "        center = np.mean(cluster_nodes, axis=0).tolist()\n",
    "        \n",
    "        # Ch·ªçn cluster head\n",
    "        ch = clustering_instance.choose_cluster_head(cluster_nodes, cluster_ids, all_nodes)\n",
    "        \n",
    "        clusters[i] = {\n",
    "            'nodes': cluster_ids,\n",
    "            'center': center,\n",
    "            'cluster_head': ch\n",
    "        }\n",
    "    \n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1e08e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    H√†m ch√≠nh m√¥ ph·ªèng m·∫°ng c·∫£m bi·∫øn d∆∞·ªõi n∆∞·ªõc v·ªõi AUV thu th·∫≠p d·ªØ li·ªáu.\n",
    "    S·ª≠ d·ª•ng Genetic Algorithm ƒë·ªÉ t·ªëi ∆∞u ƒë∆∞·ªùng ƒëi.\n",
    "    \"\"\"\n",
    "    input_dir = \"input_data\"\n",
    "    output_dir = \"result_ga_ch_most_energy\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    if not os.path.exists(input_dir):\n",
    "        print(f\"‚ùå L·ªói: Th∆∞ m·ª•c {input_dir} kh√¥ng t·ªìn t·∫°i!\")\n",
    "        return\n",
    "\n",
    "    files = [f for f in os.listdir(input_dir) if f.endswith('.json')]\n",
    "    \n",
    "    if len(files) == 0:\n",
    "        print(f\"‚ùå Kh√¥ng t√¨m th·∫•y file d·ªØ li·ªáu n√†o trong {input_dir}\")\n",
    "        return\n",
    "\n",
    "    # Tham s·ªë\n",
    "    INITIAL_ENERGY = 100.0\n",
    "    v_f = 1.2\n",
    "    v_AUV = 3.0\n",
    "    R_SEN = 60      # B√°n k√≠nh truy·ªÅn t·∫£i (m)\n",
    "    MAX_SIZE = 20   # K√≠ch th∆∞·ªõc c·ª•m t·ªëi ƒëa\n",
    "    MIN_SIZE = 5    # K√≠ch th∆∞·ªõc c·ª•m t·ªëi thi·ªÉu\n",
    "    \n",
    "    results_summary = []\n",
    "    \n",
    "    # Kh·ªüi t·∫°o Clustering instance\n",
    "    clustering = Clustering(\n",
    "        space_size=400,\n",
    "        r_sen=R_SEN,\n",
    "        max_cluster_size=MAX_SIZE,\n",
    "        min_cluster_size=MIN_SIZE\n",
    "    )\n",
    "\n",
    "    for filename in files:\n",
    "        input_path = os.path.join(input_dir, filename)\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"=== ƒêang x·ª≠ l√Ω file: {filename} ===\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        try:\n",
    "            with open(input_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå L·ªói ƒë·ªçc file {filename}: {e}\")\n",
    "            continue\n",
    "\n",
    "        node_positions = {}\n",
    "        all_nodes = {}\n",
    "        \n",
    "        # X·ª≠ l√Ω file JSON - danh s√°ch nodes: [{\"id\": 0, \"x\": ..., \"y\": ..., \"z\": ...}, ...]\n",
    "        if isinstance(data, list):\n",
    "            print(\"ƒê·ªãnh d·∫°ng: Danh s√°ch nodes\")\n",
    "            for node in data:\n",
    "                nid = node['id']\n",
    "                all_nodes[nid] = {\n",
    "                    'initial_energy': node.get('initial_energy', INITIAL_ENERGY),\n",
    "                    'residual_energy': node.get('residual_energy', INITIAL_ENERGY)\n",
    "                }\n",
    "                node_positions[nid] = (node['x'], node['y'], node['z'])\n",
    "        else:\n",
    "            print(f\"‚ùå C·∫•u tr√∫c file {filename} kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£ (c·∫ßn list of nodes)\")\n",
    "            continue\n",
    "\n",
    "        total_nodes = len(all_nodes)\n",
    "        print(f\"T·ªïng s·ªë node ban ƒë·∫ßu: {total_nodes}\")\n",
    "        print(f\"Tham s·ªë: r_sen={R_SEN}m, max_size={MAX_SIZE}, min_size={MIN_SIZE}\")\n",
    "        print(f\"Ph∆∞∆°ng ph√°p: Genetic Algorithm (GA)\")\n",
    "\n",
    "        # Ph√¢n c·ª•m l·∫ßn ƒë·∫ßu ti√™n\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"PH√ÇN C·ª§M L·∫¶N ƒê·∫¶U TI√äN\")\n",
    "        print(f\"{'='*60}\")\n",
    "        initial_clusters = recluster(all_nodes, node_positions, clustering, R_SEN, MAX_SIZE, MIN_SIZE)\n",
    "        \n",
    "        # T√≠nh metrics cho ph√¢n c·ª•m ban ƒë·∫ßu\n",
    "        clusters_data_for_metrics = []\n",
    "        for cid, cinfo in initial_clusters.items():\n",
    "            cluster_nodes = np.array([node_positions[nid] for nid in cinfo['nodes']])\n",
    "            clusters_data_for_metrics.append((cluster_nodes, cinfo['nodes']))\n",
    "        \n",
    "        metrics = clustering.calculate_metrics(clusters_data_for_metrics)\n",
    "        \n",
    "        print(f\"\\n METRICS PH√ÇN C·ª§M:\")\n",
    "        print(f\"  - S·ªë c·ª•m: {metrics['num_clusters']}\")\n",
    "        print(f\"  - K√≠ch th∆∞·ªõc TB: {metrics['avg_cluster_size']:.1f}\")\n",
    "        print(f\"  - K√≠ch th∆∞·ªõc: [{metrics['min_cluster_size']} - {metrics['max_cluster_size']}]\")\n",
    "        print(f\"  - Kho·∫£ng c√°ch TB trong c·ª•m: {metrics['avg_intra_distance']:.1f}m\")\n",
    "        print(f\"  - Kho·∫£ng c√°ch max trong c·ª•m: {metrics['max_intra_distance']:.1f}m\")\n",
    "        print(f\"  - ƒê·ªô c√¢n b·∫±ng: {metrics['balance_score']:.2%}\")\n",
    "        \n",
    "        # L∆∞u k·∫øt qu·∫£ ph√¢n c·ª•m l·∫ßn ƒë·∫ßu\n",
    "        clusters_output = {}\n",
    "        for cid, cinfo in initial_clusters.items():\n",
    "            clusters_output[cid] = {\n",
    "                'cluster_id': cid,\n",
    "                'nodes': cinfo['nodes'],\n",
    "                'center': cinfo['center'],\n",
    "                'cluster_head': cinfo['cluster_head'],\n",
    "                'num_nodes': len(cinfo['nodes'])\n",
    "            }\n",
    "        \n",
    "        initial_cluster_file = os.path.join(output_dir, f\"initial_clusters_{filename}\")\n",
    "        with open(initial_cluster_file, \"w\", encoding='utf-8') as f:\n",
    "            json.dump(clusters_output, f, indent=4, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"\\n ƒê√£ l∆∞u ph√¢n c·ª•m ban ƒë·∫ßu: {initial_cluster_file}\")\n",
    "\n",
    "        cycle = 0\n",
    "        alive_log = []\n",
    "        energy_log = []\n",
    "        cluster_count_log = []\n",
    "\n",
    "        # V√≤ng l·∫∑p m√¥ ph·ªèng\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\" B·∫ÆT ƒê·∫¶U M√î PH·ªéNG (s·ª≠ d·ª•ng GA)\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        while True:\n",
    "            cycle += 1\n",
    "            alive_log.append(len(all_nodes))\n",
    "            total_energy = sum(all_nodes[n]['residual_energy'] for n in all_nodes)\n",
    "            energy_log.append(total_energy)\n",
    "\n",
    "            alive_ratio = len(all_nodes)/total_nodes if total_nodes > 0 else 0\n",
    "            \n",
    "            if alive_ratio < 0.9:\n",
    "                print(f\"\\nüõë D·ª´ng m√¥ ph·ªèng ·ªü cycle {cycle}: < 90% node c√≤n s·ªëng ({alive_ratio*100:.2f}%)\")\n",
    "                break\n",
    "\n",
    "            # Ph√¢n c·ª•m l·∫°i\n",
    "            clusters = recluster(all_nodes, node_positions, clustering, R_SEN, MAX_SIZE, MIN_SIZE)\n",
    "            cluster_count_log.append(len(clusters))\n",
    "            \n",
    "            if len(clusters) == 0:\n",
    "                print(f\"\\n D·ª´ng m√¥ ph·ªèng ·ªü cycle {cycle}: Kh√¥ng c√≤n node\")\n",
    "                break\n",
    "\n",
    "            print(f\"\\n--- Cycle {cycle} --- | Alive: {alive_ratio*100:.2f}% ({len(all_nodes)}/{total_nodes}) | Energy: {total_energy:.2f}J | Clusters: {len(clusters)}\")\n",
    "\n",
    "            # T·∫°o ƒë∆∞·ªùng ƒëi cho AUV b·∫±ng GA (thay v√¨ Greedy)\n",
    "            print(f\"   üß¨ Ch·∫°y GA ƒë·ªÉ t·ªëi ∆∞u ƒë∆∞·ªùng ƒëi...\")\n",
    "            path_indices, best_time = ga_path_optimization(clusters, v_f, v_AUV, verbose=False)\n",
    "            print(f\"   ‚úÖ GA ho√†n th√†nh: Best time = {best_time:.2f}s\")\n",
    "            \n",
    "            # C·∫≠p nh·∫≠t nƒÉng l∆∞·ª£ng\n",
    "            update_energy(all_nodes, clusters, best_time)\n",
    "            clusters, dead_nodes = remove_dead_nodes(all_nodes, clusters)\n",
    "            \n",
    "            if dead_nodes:\n",
    "                print(f\"   ‚ö° {len(dead_nodes)} node(s) ƒë√£ h·∫øt nƒÉng l∆∞·ª£ng\")\n",
    "\n",
    "        # L∆∞u k·∫øt qu·∫£ JSON\n",
    "        meta = {\n",
    "            'input_file': filename,\n",
    "            'initial_total_nodes': total_nodes,\n",
    "            'cycles_completed': cycle - 1,\n",
    "            'final_alive_nodes': len(all_nodes),\n",
    "            'final_alive_ratio': len(all_nodes)/total_nodes if total_nodes > 0 else 0,\n",
    "            'method': 'Genetic Algorithm (GA)',\n",
    "            'parameters': {\n",
    "                'r_sen': R_SEN,\n",
    "                'max_cluster_size': MAX_SIZE,\n",
    "                'min_cluster_size': MIN_SIZE,\n",
    "                'v_flow': v_f,\n",
    "                'v_AUV': v_AUV,\n",
    "                'ga_pop_size': 40,\n",
    "                'ga_generations': 150\n",
    "            },\n",
    "            'initial_clustering_metrics': {\n",
    "                'num_clusters': metrics['num_clusters'],\n",
    "                'avg_cluster_size': float(metrics['avg_cluster_size']),\n",
    "                'balance_score': float(metrics['balance_score'])\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        output_json = os.path.join(output_dir, f\"result_{filename}\")\n",
    "        with open(output_json, \"w\") as f:\n",
    "            json.dump(meta, f, indent=4)\n",
    "\n",
    "        results_summary.append((filename, cycle - 1))\n",
    "        print(f\"\\n File {filename}: {cycle - 1} cycles ho√†n th√†nh\")\n",
    "\n",
    "        # Plot 1: Alive nodes per cycle\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(range(len(alive_log)), alive_log, marker='o', linewidth=2, color='steelblue')\n",
    "        plt.title(f\"S·ªë node s·ªëng theo chu k·ª≥ - {filename} (GA)\", fontsize=14, fontweight='bold')\n",
    "        plt.xlabel(\"Chu k·ª≥\", fontsize=12)\n",
    "        plt.ylabel(\"Nodes alive\", fontsize=12)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.axhline(y=total_nodes*0.9, color='red', linestyle='--', linewidth=2, label='Ng∆∞·ª°ng 90%')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, f\"alive_nodes_{filename}.png\"), dpi=150)\n",
    "        plt.close()\n",
    "\n",
    "        # Plot 2: Total energy per cycle\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(range(len(energy_log)), energy_log, marker='s', linewidth=2, color='orange')\n",
    "        plt.title(f\"NƒÉng l∆∞·ª£ng to√†n m·∫°ng theo chu k·ª≥ - {filename} (GA)\", fontsize=14, fontweight='bold')\n",
    "        plt.xlabel(\"Chu k·ª≥\", fontsize=12)\n",
    "        plt.ylabel(\"Total energy (J)\", fontsize=12)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, f\"energy_{filename}.png\"), dpi=150)\n",
    "        plt.close()\n",
    "        \n",
    "        # Plot 3: Number of clusters per cycle\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(range(1, len(cluster_count_log)+1), cluster_count_log, marker='^', linewidth=2, color='green')\n",
    "        plt.title(f\"S·ªë c·ª•m theo chu k·ª≥ - {filename} (GA)\", fontsize=14, fontweight='bold')\n",
    "        plt.xlabel(\"Chu k·ª≥\", fontsize=12)\n",
    "        plt.ylabel(\"S·ªë c·ª•m\", fontsize=12)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, f\"clusters_{filename}.png\"), dpi=150)\n",
    "        plt.close()\n",
    "\n",
    "    # Summary plot\n",
    "    if results_summary:\n",
    "        labels = [x[0] for x in results_summary]\n",
    "        values = [x[1] for x in results_summary]\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(labels, values, marker='o', linewidth=2, markersize=8)\n",
    "        plt.title(\"AUV cycles completed per dataset (GA)\", fontsize=14, fontweight='bold')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.ylabel(\"Cycles\", fontsize=12)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, \"summary_cycles.png\"), dpi=150)\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"‚úÖ Ho√†n th√†nh! K·∫øt qu·∫£ ƒë√£ l∆∞u t·∫°i: {output_dir}\")\n",
    "        print(f\"{'='*60}\")\n",
    "    else:\n",
    "        print(\"\\n  Kh√¥ng c√≥ k·∫øt qu·∫£ n√†o ƒë∆∞·ª£c t·∫°o ra\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
