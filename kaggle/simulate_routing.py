import sys
import os
import json
import numpy as np

import matplotlib.pyplot as plt
from scipy.spatial.distance import pdist
from numba import njit
import itertools

sys.path.append(os.path.dirname(os.path.dirname(__file__)))
from compute import Computing
from clustering import Clustering
from algorthms.greedy import Greedy
from algorthms.ga import ClusterTSP_GA
from algorthms.pso import Pso_routing
from algorthms.pso_adaptive_noise import Pso_adaptive_noise
from algorthms.pso_levy_flight import Pso_levy_flight


def main():
    """
    M√¥ ph·ªèng v·ªõi 3 thu·∫≠t to√°n: Greedy, GA, PSO
    T·∫°o folder t·ªïng h·ª£p v√† folder chi ti·∫øt cho t·ª´ng b·ªô d·ªØ li·ªáu
    """
    # ƒêI·ªÄU CH·ªàNH ƒê∆Ø·ªúNG D·∫™N
    input_folder = "/kaggle/input/input652/input_data"
    output_main_folder = "/kaggle/working/results_history"
    
    os.makedirs(output_main_folder, exist_ok=True)

    if not os.path.exists(input_folder):
        print(f"‚ùå L·ªói: Th∆∞ m·ª•c {input_folder} kh√¥ng t·ªìn t·∫°i!")
        return

    files = [f for f in os.listdir(input_folder) if f.endswith('.json')]
    if len(files) == 0:
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y file d·ªØ li·ªáu n√†o trong {input_folder}")
        return

    # Tham s·ªë
    INITIAL_ENERGY = 100.0
    v_f = 1.2
    v_AUV = 3.0
    R_SEN = 60
    MAX_SIZE = 25
    MIN_SIZE = 10
    
    # L∆∞u k·∫øt qu·∫£ cho 3 thu·∫≠t to√°n (d√πng cho bi·ªÉu ƒë·ªì t·ªïng h·ª£p)
    algorithms = [ 'PSO', 'Greedy', 'GA']
    global_results = {alg: {} for alg in algorithms}
    
    clustering = Clustering(space_size=400, r_sen=R_SEN, max_cluster_size=MAX_SIZE, min_cluster_size=MIN_SIZE)

    # Ch·∫°y t·ª´ng file d·ªØ li·ªáu
    for filename in sorted(files):
        input_path = os.path.join(input_folder, filename)
        
        # T·∫°o folder cho file n√†y
        base_name = filename.replace('.json', '')
        file_output_folder = os.path.join(output_main_folder, f"folder_{base_name}")
        os.makedirs(file_output_folder, exist_ok=True)
        
        print(f"\n{'='*80}")
        print(f"=== ƒêang x·ª≠ l√Ω file: {filename} ===")
        print(f"{'='*80}")
        
        try:
            with open(input_path, 'r') as f:
                data = json.load(f)
        except Exception as e:
            print(f"‚ùå L·ªói ƒë·ªçc file {filename}: {e}")
            continue

        # Parse d·ªØ li·ªáu node
        node_positions = {}
        initial_nodes = {}
        
        if isinstance(data, list):
            for node in data:
                nid = node['id']
                initial_nodes[nid] = {
                    'initial_energy': node.get('initial_energy', INITIAL_ENERGY),
                    'residual_energy': node.get('residual_energy', INITIAL_ENERGY)
                }
                node_positions[nid] = (node['x'], node['y'], node['z'])
        else:
            print(f"‚ùå C·∫•u tr√∫c file {filename} kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£")
            continue

        total_nodes = len(initial_nodes)
        print(f"T·ªïng s·ªë node: {total_nodes}")

        # Ph√¢n c·ª•m ban ƒë·∫ßu (d√πng chung cho c·∫£ 3 thu·∫≠t to√°n)
        ids = sorted(list(initial_nodes.keys()))
        coords = np.array([node_positions[nid] for nid in ids])
        clusters_data = clustering.cluster_with_constraints(coords, ids)
        
        initial_clusters = {}
        for i, (cluster_nodes, cluster_ids) in enumerate(clusters_data):
            center = np.mean(cluster_nodes, axis=0).tolist()
            ch = clustering.choose_cluster_head(cluster_nodes, cluster_ids, initial_nodes)
            initial_clusters[i] = {'nodes': cluster_ids, 'center': center, 'cluster_head': ch}

        # T·∫°o t·ªça ƒë·ªô cho routing
        sorted_keys = sorted(initial_clusters.keys())
        centers = [(200, 200, 400)]  # BS
        for k in sorted_keys:
            ch = initial_clusters[k]['cluster_head']
            centers.append(tuple(node_positions[ch]))
        center_coords = np.array(centers)

        # L∆∞u k·∫øt qu·∫£ t·ª´ng thu·∫≠t to√°n cho file n√†y
        file_results = {}

        # ======== CH·∫†Y 3 THU·∫¨T TO√ÅN ========
        for algorithm in algorithms:
            print(f"\n{'='*60}")
            print(f"üî• Ch·∫°y thu·∫≠t to√°n: {algorithm}")
            print(f"{'='*60}")
            
            # Deep copy d·ªØ li·ªáu cho m·ªói thu·∫≠t to√°n
            all_nodes = {k: v.copy() for k, v in initial_nodes.items()}
            clusters = {k: v.copy() for k, v in initial_clusters.items()}
            
            # T√≠nh ƒë∆∞·ªùng ƒëi ban ƒë·∫ßu
            if algorithm == 'Greedy':
                current_path, current_time = Greedy.greedy_tsp(center_coords, v_f, v_AUV)
            elif algorithm == 'GA':
                ga_solver = ClusterTSP_GA(clusters, ga_params={
                    'pop_size': 50,
                    'generations': 150,
                    'v_f': v_f,
                    'v_AUV': v_AUV,
                    'verbose': False
                })
                current_path, _, current_time = ga_solver.evolve()
            else:  # PSO
                current_path, current_time = Pso_routing.multi_pso_tsp(
                    center_coords, v_f, v_AUV,
                    n_outer=3, n_particles=50, max_iter=50, verbose=False
                )
            
            print(f"   ƒê∆∞·ªùng ƒëi ban ƒë·∫ßu: {current_time:.4f}s")
            
            # M√¥ ph·ªèng t·ª´ng chu k·ª≥
            cycle = 0
            alive_log = []
            total_energy_consumed = 0
            
            while True:
                cycle += 1
                alive_log.append(len(all_nodes))
                alive_ratio = len(all_nodes) / total_nodes
                
                if alive_ratio < 0.1:
                    print(f"üõë D·ª´ng ·ªü cycle {cycle}: {alive_ratio*100:.2f}% node c√≤n s·ªëng")
                    break
                
                if cycle % 50 == 0:
                    print(f"   Cycle {cycle}: {len(all_nodes)}/{total_nodes} nodes alive")
                
                # C·∫≠p nh·∫≠t nƒÉng l∆∞·ª£ng
                energy_before = sum(all_nodes[n]['residual_energy'] for n in all_nodes)
                Computing.update_energy(all_nodes, clusters, current_time)
                energy_after = sum(all_nodes[n]['residual_energy'] for n in all_nodes)
                total_energy_consumed += (energy_before - energy_after)
                
                # Ch·ªçn l·∫°i cluster head
                clusters = Clustering.reselect_cluster_heads(clusters, all_nodes)
                
                # T√≠nh l·∫°i ƒë∆∞·ªùng ƒëi v·ªõi CH m·ªõi
                sorted_keys = sorted(clusters.keys())
                centers = [(200, 200, 400)]
                for k in sorted_keys:
                    ch = clusters[k]['cluster_head']
                    centers.append(tuple(node_positions[ch]))
                center_coords = np.array(centers)
                
                if algorithm == 'Greedy':
                    current_path, current_time = Greedy.greedy_tsp(center_coords, v_f, v_AUV)
                elif algorithm == 'GA':
                    ga_solver = ClusterTSP_GA(clusters, ga_params={
                        'pop_size': 50, 'generations': 150,
                        'v_f': v_f, 'v_AUV': v_AUV, 'verbose': False
                    })
                    current_path, _, current_time = ga_solver.evolve()
                else:  # PSO
                    current_path, current_time = Pso_routing.multi_pso_tsp(
                        center_coords, v_f, v_AUV,
                        n_outer=3, n_particles=30, max_iter=80, verbose=False
                    )
                
                # Ki·ªÉm tra node ch·∫øt
                clusters, dead_nodes = Clustering.remove_dead_nodes(all_nodes, clusters)
                
                if dead_nodes:
                    if len(all_nodes) > 0:
                        clusters = Clustering.recluster(all_nodes, node_positions, clustering, R_SEN, MAX_SIZE, MIN_SIZE)
                        if len(clusters) == 0:
                            break
                        
                        sorted_keys = sorted(clusters.keys())
                        centers = [(200, 200, 400)]
                        for k in sorted_keys:
                            ch = clusters[k]['cluster_head']
                            centers.append(tuple(node_positions[ch]))
                        center_coords = np.array(centers)
                        
                        if algorithm == 'Greedy':
                            current_path, current_time = Greedy.greedy_tsp(center_coords, v_f, v_AUV)
                        elif algorithm == 'GA':
                            ga_solver = ClusterTSP_GA(clusters, ga_params={
                                'pop_size': 50, 'generations': 150,
                                'v_f': v_f, 'v_AUV': v_AUV, 'verbose': False
                            })
                            current_path, _, current_time = ga_solver.evolve()
                        else:  # PSO
                            current_path, current_time = Pso_routing.multi_pso_tsp(
                                center_coords, v_f, v_AUV,
                                n_outer=3, n_particles=30, max_iter=80, verbose=False
                            )
                    else:
                        break
            
            # L∆∞u k·∫øt qu·∫£ thu·∫≠t to√°n n√†y
            final_alive = len(all_nodes)
            final_alive_ratio = final_alive / total_nodes
            
            result_data = {
                'filename': filename,
                'algorithm': algorithm,
                'initial_nodes': total_nodes,
                'cycles_completed': cycle - 1,
                'final_alive_nodes': final_alive,
                'final_alive_ratio': round(final_alive_ratio, 4),
                'total_energy_consumed': round(total_energy_consumed, 4),
                'alive_log': alive_log
            }
            
            file_results[algorithm] = result_data
            
            # L∆∞u file JSON ri√™ng cho thu·∫≠t to√°n n√†y
            alg_file = os.path.join(file_output_folder, f"{algorithm}_result.json")
            with open(alg_file, 'w') as f:
                json.dump(result_data, f, indent=4)
            
            # L∆∞u v√†o global results
            global_results[algorithm][filename] = result_data
            
            print(f"‚úÖ {algorithm} ho√†n th√†nh: {cycle-1} cycles, {total_energy_consumed:.2f}J, {final_alive}/{total_nodes} nodes s·ªëng")

        # ======== V·∫º BI·ªÇU ƒê·ªí CHO FILE N√ÄY ========
        print(f"\nüìä V·∫Ω bi·ªÉu ƒë·ªì so s√°nh cho {filename}")
        
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        
        # Bi·ªÉu ƒë·ªì 1: Network Lifetime (cycles)
        ax = axes[0, 0]
        cycles_data = [file_results[alg]['cycles_completed'] for alg in algorithms]
        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']
        bars = ax.bar(algorithms, cycles_data, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)
        ax.set_ylabel('S·ªë chu k·ª≥ (cycles)', fontweight='bold', fontsize=12)
        ax.set_title(f'Th·ªùi gian s·ªëng m·∫°ng - {filename}', fontweight='bold', fontsize=14)
        ax.grid(True, alpha=0.3, axis='y')
        
        # Th√™m gi√° tr·ªã l√™n ƒë·∫ßu c·ªôt
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{int(height)}',
                   ha='center', va='bottom', fontweight='bold', fontsize=11)
        
        # Bi·ªÉu ƒë·ªì 2: Total Energy Consumed
        ax = axes[0, 1]
        energy_data = [file_results[alg]['total_energy_consumed'] for alg in algorithms]
        bars = ax.bar(algorithms, energy_data, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)
        ax.set_ylabel('NƒÉng l∆∞·ª£ng ti√™u th·ª• (J)', fontweight='bold', fontsize=12)
        ax.set_title(f'T·ªïng nƒÉng l∆∞·ª£ng ti√™u th·ª• - {filename}', fontweight='bold', fontsize=14)
        ax.grid(True, alpha=0.3, axis='y')
        
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{height:.1f}',
                   ha='center', va='bottom', fontweight='bold', fontsize=11)
        
        # Bi·ªÉu ƒë·ªì 3: S·ªë node s·ªëng theo chu k·ª≥
        ax = axes[1, 0]
        for alg, color in zip(algorithms, colors):
            alive_log = file_results[alg]['alive_log']
            ax.plot(range(len(alive_log)), alive_log, marker='o', label=alg, 
                   linewidth=2.5, markersize=4, color=color)
        
        ax.set_xlabel('S·ªë chu k·ª≥', fontweight='bold', fontsize=12)
        ax.set_ylabel('S·ªë node s·ªëng', fontweight='bold', fontsize=12)
        ax.set_title(f'S·ªë node s·ªëng theo chu k·ª≥ - {filename}', fontweight='bold', fontsize=14)
        ax.legend(fontsize=11, loc='best')
        ax.grid(True, alpha=0.3)
        ax.axhline(y=total_nodes*0.1, color='red', linestyle='--', linewidth=2, alpha=0.5, label='Ng∆∞·ª°ng 10%')
        
        # Bi·ªÉu ƒë·ªì 4: T·ª∑ l·ªá node s·ªëng cu·ªëi c√πng
        ax = axes[1, 1]
        ratio_data = [file_results[alg]['final_alive_ratio'] * 100 for alg in algorithms]
        bars = ax.bar(algorithms, ratio_data, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)
        ax.set_ylabel('T·ª∑ l·ªá node s·ªëng (%)', fontweight='bold', fontsize=12)
        ax.set_title(f'T·ª∑ l·ªá node s·ªëng cu·ªëi c√πng - {filename}', fontweight='bold', fontsize=14)
        ax.grid(True, alpha=0.3, axis='y')
        ax.set_ylim([0, 100])
        
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{height:.1f}%',
                   ha='center', va='bottom', fontweight='bold', fontsize=11)
        
        plt.tight_layout()
        chart_file = os.path.join(file_output_folder, f"comparison_{base_name}.png")
        plt.savefig(chart_file, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"‚úÖ Bi·ªÉu ƒë·ªì ƒë√£ l∆∞u: {chart_file}")

    # ======== V·∫º BI·ªÇU ƒê·ªí T·ªîNG H·ª¢P T·∫§T C·∫¢ C√ÅC FILE ========
    print(f"\n{'='*80}")
    print("üìä V·∫º BI·ªÇU ƒê·ªí T·ªîNG H·ª¢P")
    print(f"{'='*80}")
    
    # Chu·∫©n b·ªã d·ªØ li·ªáu
    node_counts = []
    lifetimes = {alg: [] for alg in algorithms}
    energies = {alg: [] for alg in algorithms}
    alive_logs_550 = {alg: [] for alg in algorithms}
    
    for filename in sorted(files):
        # Tr√≠ch xu·∫•t s·ªë node t·ª´ t√™n file
        try:
            num_nodes = int(filename.split('_')[1].split('.')[0])
            node_counts.append(num_nodes)
        except:
            node_counts.append(0)
        
        for alg in algorithms:
            if filename in global_results[alg]:
                lifetimes[alg].append(global_results[alg][filename]['cycles_completed'])
                energies[alg].append(global_results[alg][filename]['total_energy_consumed'])
                
                # L∆∞u alive_log cho file 550 nodes
                if '550' in filename:
                    alive_logs_550[alg] = global_results[alg][filename]['alive_log']
            else:
                lifetimes[alg].append(0)
                energies[alg].append(0)
    
    # V·∫Ω 4 bi·ªÉu ƒë·ªì t·ªïng h·ª£p
    fig, axes = plt.subplots(2, 2, figsize=(18, 14))
    
    x = np.arange(len(node_counts))
    width = 0.25
    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']
    
    # Bi·ªÉu ƒë·ªì 1: Th·ªùi gian s·ªëng to√†n m·∫°ng
    ax = axes[0, 0]
    for i, alg in enumerate(algorithms):
        bars = ax.bar(x + i*width, lifetimes[alg], width, label=alg, 
                     color=colors[i], alpha=0.8, edgecolor='black', linewidth=1)
    ax.set_xlabel('S·ªë l∆∞·ª£ng node', fontweight='bold', fontsize=13)
    ax.set_ylabel('Th·ªùi gian s·ªëng (cycles)', fontweight='bold', fontsize=13)
    ax.set_title('Th·ªùi gian s·ªëng to√†n m·∫°ng theo s·ªë node', fontweight='bold', fontsize=15)
    ax.set_xticks(x + width)
    ax.set_xticklabels(node_counts, fontsize=11)
    ax.legend(fontsize=12)
    ax.grid(True, alpha=0.3, axis='y')
    
    # Bi·ªÉu ƒë·ªì 2: NƒÉng l∆∞·ª£ng ti√™u th·ª•
    ax = axes[0, 1]
    for i, alg in enumerate(algorithms):
        bars = ax.bar(x + i*width, energies[alg], width, label=alg, 
                     color=colors[i], alpha=0.8, edgecolor='black', linewidth=1)
    ax.set_xlabel('S·ªë l∆∞·ª£ng node', fontweight='bold', fontsize=13)
    ax.set_ylabel('NƒÉng l∆∞·ª£ng ti√™u th·ª• (J)', fontweight='bold', fontsize=13)
    ax.set_title('T·ªïng nƒÉng l∆∞·ª£ng ti√™u th·ª• theo s·ªë node', fontweight='bold', fontsize=15)
    ax.set_xticks(x + width)
    ax.set_xticklabels(node_counts, fontsize=11)
    ax.legend(fontsize=12)
    ax.grid(True, alpha=0.3, axis='y')
    
    # Bi·ªÉu ƒë·ªì 3: S·ªë node s·ªëng theo chu k·ª≥ (550 nodes)
    ax = axes[1, 0]
    for alg, color in zip(algorithms, colors):
        if alive_logs_550[alg]:
            ax.plot(range(len(alive_logs_550[alg])), alive_logs_550[alg], 
                   marker='o', label=alg, linewidth=2.5, markersize=5, color=color)
    
    ax.set_xlabel('S·ªë chu k·ª≥', fontweight='bold', fontsize=13)
    ax.set_ylabel('S·ªë node s·ªëng', fontweight='bold', fontsize=13)
    ax.set_title('S·ªë node s·ªëng theo chu k·ª≥ (550 nodes)', fontweight='bold', fontsize=15)
    ax.legend(fontsize=12)
    ax.grid(True, alpha=0.3)
    
    # Bi·ªÉu ƒë·ªì 4: S·ªë chu k·ª≥ theo s·ªë l∆∞·ª£ng nodes
    ax = axes[1, 1]
    for i, alg in enumerate(algorithms):
        ax.plot(node_counts, lifetimes[alg], marker='o', label=alg, 
               linewidth=2.5, markersize=8, color=colors[i])
    
    ax.set_xlabel('S·ªë l∆∞·ª£ng node', fontweight='bold', fontsize=13)
    ax.set_ylabel('S·ªë chu k·ª≥', fontweight='bold', fontsize=13)
    ax.set_title('S·ªë chu k·ª≥ m·∫°ng theo s·ªë l∆∞·ª£ng node', fontweight='bold', fontsize=15)
    ax.legend(fontsize=12)
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    summary_chart = os.path.join(output_main_folder, 'summary_all_datasets.png')
    plt.savefig(summary_chart, dpi=150, bbox_inches='tight')
    plt.close()
    
    print(f"‚úÖ Bi·ªÉu ƒë·ªì t·ªïng h·ª£p ƒë√£ l∆∞u: {summary_chart}")
    
    # L∆∞u k·∫øt qu·∫£ t·ªïng h·ª£p
    summary_data = {
        'node_counts': node_counts,
        'algorithms': algorithms,
        'network_lifetime': lifetimes,
        'total_energy_consumed': energies,
        'detailed_results': global_results
    }
    
    summary_json = os.path.join(output_main_folder, 'summary_all_results.json')
    with open(summary_json, 'w') as f:
        json.dump(summary_data, f, indent=4)
    
    print(f"‚úÖ K·∫øt qu·∫£ t·ªïng h·ª£p ƒë√£ l∆∞u: {summary_json}")
    
    # In b·∫£ng k·∫øt qu·∫£
    print(f"\n{'='*100}")
    print("B·∫¢NG K·∫æT QU·∫¢ SO S√ÅNH CHI TI·∫æT")
    print(f"{'='*100}")
    print(f"{'Nodes':<10} {'Greedy':<30} {'GA':<30} {'PSO':<30}")
    print(f"{'':<10} {'Cycles':<10} {'Energy(J)':<10} {'Alive%':<10} {'Cycles':<10} {'Energy(J)':<10} {'Alive%':<10} {'Cycles':<10} {'Energy(J)':<10} {'Alive%':<10}")
    print("-" * 100)
    
    for i, nc in enumerate(node_counts):
        row = f"{nc:<10}"
        fname = sorted(files)[i]
        for alg in algorithms:
            if fname in global_results[alg]:
                cycles = global_results[alg][fname]['cycles_completed']
                energy = global_results[alg][fname]['total_energy_consumed']
                alive_ratio = global_results[alg][fname]['final_alive_ratio'] * 100
                row += f"{cycles:<10} {energy:<10.2f} {alive_ratio:<10.1f}"
            else:
                row += f"{'N/A':<10} {'N/A':<10} {'N/A':<10}"
        print(row)
    
    print(f"\n{'='*100}")
    print(f"‚úÖ HO√ÄN TH√ÄNH! T·∫•t c·∫£ k·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {output_main_folder}")
    print(f"{'='*100}")

print("‚úì Complete main comparison function with detailed folders loaded")
if __name__ == '__main__':
    main()