import sys
import os
import json
import numpy as np

import matplotlib.pyplot as plt
from scipy.spatial.distance import pdist
from numba import njit

sys.path.append(os.path.dirname(os.path.dirname(__file__)))
from compute import Computing
from clustering import Clustering
from algorthms.greedy import Greedy
from algorthms.ga import ClusterTSP_GA
from algorthms.pso import Pso_routing
from algorthms.pso_adaptive_noise import Pso_adaptive_noise
from algorthms.pso_levy_flight import Pso_levy_flight

def compare_routing_boxplot():
    """
    So s√°nh 4 thu·∫≠t to√°n (GA, PSO, PSOver2, PSOver3) tr√™n 10 file d·ªØ li·ªáu
    M·ªói thu·∫≠t to√°n ch·∫°y 5 l·∫ßn l·∫∑p l·∫°i tr√™n m·ªói file
    V·∫Ω box plot: Ox = t√™n file, Oy = travel time, m·ªói file c√≥ 4 box (4 thu·∫≠t to√°n)
    T·∫°o 9 bi·ªÉu ƒë·ªì cho 9 th∆∞ m·ª•c (nodes_150, nodes_200, ..., nodes_550)
    """
    # ƒê∆Ø·ªúNG D·∫™N
    base_input_dir = "/kaggle/input/input-10-files-2/input_data_evenly_distributed"
    base_output_dir = "D:/Year 4/ti·∫øn h√≥a/project/results/routing_boxplot"
    
    os.makedirs(base_output_dir, exist_ok=True)
    
    print(f"\n{'='*80}")
    print("SO S√ÅNH ƒê·ªò H·ªòI T·ª§ K·∫æT QU·∫¢ ƒê·ªäNH TUY·∫æN C·ª¶A C√ÅC THU·∫¨T TO√ÅN")
    print(f"{'='*80}\n")
    
    # Tham s·ªë
    INITIAL_ENERGY = 100.0
    v_f = 1.2
    v_AUV = 3.0
    R_SEN = 60
    MAX_SIZE = 25
    MIN_SIZE = 10
    
    # Tham s·ªë thu·∫≠t to√°n
    MAX_ITER = 200  # Cho PSO
    MAX_GEN = 200   # Cho GA
    N_PARTICLES = 50
    POP_SIZE = 50
    N_RUNS = 5  # S·ªë l·∫ßn ch·∫°y l·∫∑p l·∫°i
    
    # Danh s√°ch s·ªë nodes
    node_counts = [150, 200, 250, 300, 350, 400, 450, 500, 550]
    
    # Duy·ªát qua t·ª´ng th∆∞ m·ª•c
    for N in node_counts:
        folder_name = f"nodes_{N}"
        input_folder = os.path.join(base_input_dir, folder_name)
        output_folder = os.path.join(base_output_dir, folder_name)
        os.makedirs(output_folder, exist_ok=True)
        
        print(f"\n{'='*80}")
        print(f"X·ª¨ L√ù TH∆Ø M·ª§C: {folder_name}")
        print(f"{'='*80}\n")
        
        if not os.path.exists(input_folder):
            print(f"‚ùå L·ªói: Th∆∞ m·ª•c {input_folder} kh√¥ng t·ªìn t·∫°i!")
            continue
        
        # Dictionary l∆∞u k·∫øt qu·∫£: {file_name: {algorithm: [run1, run2, ..., run5]}}
        results_data = {}
        
        # Duy·ªát qua 10 file
        for file_idx in range(1, 11):
            filename = f"nodes_{N}_{file_idx}.json"
            filepath = os.path.join(input_folder, filename)
            
            if not os.path.exists(filepath):
                print(f"‚ö†Ô∏è B·ªè qua: {filename} kh√¥ng t·ªìn t·∫°i")
                continue
            
            print(f"\n{'‚îÄ'*60}")
            print(f"üìÇ File: {filename}")
            print(f"{'‚îÄ'*60}")
            
            # ƒê·ªçc d·ªØ li·ªáu
            try:
                with open(filepath, 'r') as f:
                    data = json.load(f)
            except Exception as e:
                print(f"‚ùå L·ªói ƒë·ªçc file: {e}")
                continue
            
            # Parse nodes
            node_positions = {}
            initial_nodes = {}
            
            for node in data:
                nid = node['id']
                initial_nodes[nid] = {
                    'initial_energy': node.get('energy_node', INITIAL_ENERGY),
                    'residual_energy': node.get('energy_residual', INITIAL_ENERGY)
                }
                node_positions[nid] = (node['x'], node['y'], node['z'])
            
            # Ph√¢n c·ª•m
            clustering = Clustering(space_size=400, r_sen=R_SEN, 
                                   max_cluster_size=MAX_SIZE, min_cluster_size=MIN_SIZE)
            ids = sorted(list(initial_nodes.keys()))
            coords = np.array([node_positions[nid] for nid in ids])
            clusters_data = clustering.cluster_with_constraints(coords, ids)
            
            clusters = {}
            for i, (cluster_nodes, cluster_ids) in enumerate(clusters_data):
                center = np.mean(cluster_nodes, axis=0).tolist()
                ch = clustering.choose_cluster_head(cluster_nodes, cluster_ids, initial_nodes)
                clusters[i] = {'nodes': cluster_ids, 'center': center, 'cluster_head': ch}
            
            # T·∫°o t·ªça ƒë·ªô routing (BS + Cluster Heads)
            sorted_keys = sorted(clusters.keys())
            centers = [(200, 200, 400)]  # Base Station
            for k in sorted_keys:
                ch = clusters[k]['cluster_head']
                centers.append(tuple(node_positions[ch]))
            center_coords = np.array(centers)
            
            print(f"  üìä Nodes: {len(initial_nodes)}, Clusters: {len(clusters)}, Routing points: {len(center_coords)}")
            
            # Kh·ªüi t·∫°o dictionary cho file n√†y
            results_data[filename] = {
                'GA': [],
                'PSO': [],
                'PSOver2': [],
                'PSOver3': []
            }
            
            # ============================================
            # CH·∫†Y 5 L·∫¶N CHO M·ªñI THU·∫¨T TO√ÅN
            # ============================================
            
            # 1. GA
            print(f"  üîÑ Ch·∫°y GA (5 l·∫ßn)...", end=' ')
            for run in range(N_RUNS):
                ga_solver = ClusterTSP_GA(clusters, ga_params={
                    'pop_size': POP_SIZE,
                    'generations': MAX_GEN,
                    'v_f': v_f,
                    'v_AUV': v_AUV,
                    'verbose': False
                })
                _, _, cost_ga, _ = ga_solver.evolve()
                results_data[filename]['GA'].append(cost_ga)
            print(f"‚úì (avg: {np.mean(results_data[filename]['GA']):.2f}s)")
            
            # 2. PSO
            print(f"  üîÑ Ch·∫°y PSO (5 l·∫ßn)...", end=' ')
            for run in range(N_RUNS):
                path_pso, cost_pso = Pso_routing.multi_pso_tsp(center_coords, v_f=v_f, v_AUV=v_AUV, n_outer=5,  # S·ªë l·∫ßn ch·∫°y outer loop
                verbose=False,
                n_particles=N_PARTICLES,  
                max_iter=MAX_ITER  
                )
                results_data[filename]['PSO'].append(cost_pso)
            print(f"‚úì (avg: {np.mean(results_data[filename]['PSO']):.2f}s)")
            
            # 3. PSOver2
            print(f"  üîÑ Ch·∫°y PSOver2 (5 l·∫ßn)...", end=' ')
            for run in range(N_RUNS):
                path_pso2, cost_pso2 = Pso_adaptive_noise.multi_pso_tsp(
                    center_coords, 
                    v_f=v_f, 
                    v_AUV=v_AUV, 
                    n_outer=5,  # S·ªë l·∫ßn ch·∫°y outer loop
                    verbose=False,
                    n_particles=N_PARTICLES,  # Truy·ªÅn v√†o kwargs
                    max_iter=MAX_ITER  # Truy·ªÅn v√†o kwargs
                    )
                results_data[filename]['PSOver2'].append(cost_pso2)
            print(f"‚úì (avg: {np.mean(results_data[filename]['PSOver2']):.2f}s)")
            
            # 4. PSOver3
            print(f"  üîÑ Ch·∫°y PSOver3 (5 l·∫ßn)...", end=' ')
            for run in range(N_RUNS):
                path_pso3, cost_pso3 = Pso_levy_flight.multi_pso_tsp(
                    center_coords, 
                    v_f=v_f, 
                    v_AUV=v_AUV, 
                    n_outer=5,  # S·ªë l·∫ßn ch·∫°y outer loop
                    verbose=False,
                    n_particles=N_PARTICLES,  # Truy·ªÅn v√†o kwargs
                    max_iter=MAX_ITER  # Truy·ªÅn v√†o kwargs
                    )
                results_data[filename]['PSOver3'].append(cost_pso3)
            print(f"‚úì (avg: {np.mean(results_data[filename]['PSOver3']):.2f}s)")
        
        # ============================================
        # V·∫º BOX PLOT
        # ============================================
        print(f"\n{'='*60}")
        print("üìä V·∫º BOX PLOT")
        print(f"{'='*60}\n")
        
        fig, ax = plt.subplots(figsize=(20, 8))
        
        # T√™n c√°c file (tr·ª•c X)
        file_names = [f"nodes_{N}_{i}" for i in range(1, 11)]
        x_positions = np.arange(len(file_names))
        
        # C·∫•u h√¨nh cho 4 thu·∫≠t to√°n
        algorithms = ['GA', 'PSO', 'PSOver2', 'PSOver3']
        colors = ['#FF6B6B', '#4ECDC4', '#FFD93D', '#95E1D3']
        markers = ['o', 's', '^', 'D']  # H√¨nh d·∫°ng marker kh√°c nhau
        linestyles = ['-', '--', '-.', ':']  # Ki·ªÉu ƒë∆∞·ªùng th·∫≥ng kh√°c nhau
        
        # ƒê·ªô r·ªông offset cho m·ªói thu·∫≠t to√°n
        offset_width = 0.15
        offsets = [-1.5 * offset_width, -0.5 * offset_width, 
                   0.5 * offset_width, 1.5 * offset_width]
        
        # V·∫Ω cho m·ªói thu·∫≠t to√°n
        for alg_idx, (alg, color, marker, linestyle, offset) in enumerate(
            zip(algorithms, colors, markers, linestyles, offsets)
        ):
            for file_idx, filename in enumerate(file_names):
                full_filename = f"{filename}.json"
                
                if full_filename not in results_data:
                    continue
                
                values = results_data[full_filename][alg]
                
                if len(values) == 0:
                    continue
                
                x_pos = x_positions[file_idx] + offset
                
                # V·∫Ω ƒë∆∞·ªùng th·∫≥ng d·ªçc t·ª´ min ƒë·∫øn max
                min_val = min(values)
                max_val = max(values)
                ax.plot([x_pos, x_pos], [min_val, max_val], 
                       color=color, linestyle=linestyle, linewidth=2, alpha=0.7)
                
                # V·∫Ω c√°c ƒëi·ªÉm d·ªØ li·ªáu
                ax.scatter([x_pos] * len(values), values, 
                          color=color, marker=marker, s=80, 
                          edgecolors='black', linewidths=1, 
                          alpha=0.8, zorder=3)
                
                # V·∫Ω median (ƒë∆∞·ªùng ngang)
                median_val = np.median(values)
                ax.plot([x_pos - 0.03, x_pos + 0.03], [median_val, median_val], 
                       color='black', linewidth=3, zorder=4)
        
        # T·∫°o legend
        legend_elements = [
            plt.Line2D([0], [0], color=color, marker=marker, linestyle=linestyle,
                      markersize=8, linewidth=2, label=alg)
            for alg, color, marker, linestyle in zip(algorithms, colors, markers, linestyles)
        ]
        ax.legend(handles=legend_elements, loc='upper left', fontsize=12, 
                 framealpha=0.9, edgecolor='black')
        
        # C·∫•u h√¨nh tr·ª•c
        ax.set_xticks(x_positions)
        ax.set_xticklabels(file_names, rotation=45, ha='right', fontsize=11)
        ax.set_xlabel('Dataset Files', fontweight='bold', fontsize=14)
        ax.set_ylabel('Travel Time (s)', fontweight='bold', fontsize=14)
        ax.set_title(f'Routing Algorithm Comparison - {folder_name} (5 runs per algorithm)', 
                    fontweight='bold', fontsize=16)
        ax.grid(True, alpha=0.3, axis='y')
        
        plt.tight_layout()
        chart_file = os.path.join(output_folder, f'boxplot_{folder_name}.png')
        plt.savefig(chart_file, dpi=200, bbox_inches='tight')
        plt.close()
        
        print(f"‚úÖ Bi·ªÉu ƒë·ªì ƒë√£ l∆∞u: {chart_file}\n")
        
        # ============================================
        # L∆ØU K·∫æT QU·∫¢ JSON
        # ============================================
        summary = {
            'folder': folder_name,
            'num_nodes': N,
            'num_files': len(results_data),
            'num_runs_per_algorithm': N_RUNS,
            'results': {}
        }
        
        for filename in file_names:
            full_filename = f"{filename}.json"
            if full_filename in results_data:
                summary['results'][filename] = {}
                for alg in algorithms:
                    values = results_data[full_filename][alg]
                    if len(values) > 0:
                        summary['results'][filename][alg] = {
                            'values': [float(v) for v in values],
                            'mean': float(np.mean(values)),
                            'median': float(np.median(values)),
                            'std': float(np.std(values)),
                            'min': float(min(values)),
                            'max': float(max(values))
                        }
        
        results_file = os.path.join(output_folder, f'results_{folder_name}.json')
        with open(results_file, 'w') as f:
            json.dump(summary, f, indent=4)
        
        print(f"‚úÖ K·∫øt qu·∫£ JSON ƒë√£ l∆∞u: {results_file}\n")
        
        # ============================================
        # IN B·∫¢NG TH·ªêNG K√ä
        # ============================================
        print(f"{'='*90}")
        print(f"B·∫¢NG TH·ªêNG K√ä - {folder_name}")
        print(f"{'='*90}")
        print(f"{'File':<15} {'Algorithm':<10} {'Mean':<10} {'Median':<10} {'Std':<10} {'Min':<10} {'Max':<10}")
        print("-" * 90)
        
        for filename in file_names:
            full_filename = f"{filename}.json"
            if full_filename in results_data:
                for alg in algorithms:
                    values = results_data[full_filename][alg]
                    if len(values) > 0:
                        print(f"{filename:<15} {alg:<10} {np.mean(values):<10.2f} "
                              f"{np.median(values):<10.2f} {np.std(values):<10.2f} "
                              f"{min(values):<10.2f} {max(values):<10.2f}")
                print("-" * 90)
        
        print(f"\n‚úÖ Ho√†n th√†nh th∆∞ m·ª•c {folder_name}!\n")
    
    print(f"\n{'='*80}")
    print(f"‚úÖ HO√ÄN TH√ÄNH T·∫§T C·∫¢! K·∫øt qu·∫£ t·∫°i: {base_output_dir}")
    print(f"{'='*80}\n")
print("‚úì Box plot comparison code loaded")

compare_routing_boxplot()