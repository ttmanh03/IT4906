{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fbdcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# ==========================\n",
    "# HÀM PHỤ TÍNH TOÁN\n",
    "# ==========================\n",
    "\n",
    "def compute_vs(p1, p2, v_f, v_AUV):\n",
    "    x1, y1, z1 = p1\n",
    "    x2, y2, z2 = p2\n",
    "    Lx, Ly, Lz = x2 - x1, y2 - y1, z2 - z1\n",
    "    L_mag = math.sqrt(Lx**2 + Ly**2 + Lz**2)\n",
    "    if L_mag == 0:\n",
    "        return v_AUV\n",
    "    cos_beta = Lz / L_mag\n",
    "    cos_beta = np.clip(cos_beta, -1, 1)\n",
    "    beta = math.acos(cos_beta)\n",
    "    inner = np.clip((v_f * cos_beta) / v_AUV, -1, 1)\n",
    "    angle = beta + math.acos(inner)\n",
    "    v_s = abs(math.cos(angle) * v_AUV / cos_beta)\n",
    "    return v_s\n",
    "\n",
    "\n",
    "def travel_time(path, coords, v_f, v_AUV):\n",
    "    total_time = 0.0\n",
    "    for i in range(len(path) - 1):\n",
    "        p1, p2 = coords[path[i]], coords[path[i + 1]]\n",
    "        d = np.linalg.norm(np.array(p2) - np.array(p1))\n",
    "        v_s = compute_vs(tuple(p1), tuple(p2), v_f, v_AUV)\n",
    "        total_time += d / max(v_s, 1e-9)\n",
    "    # quay lại điểm đầu\n",
    "    p1, p2 = coords[path[-1]], coords[path[0]]\n",
    "    d = np.linalg.norm(np.array(p2) - np.array(p1))\n",
    "    v_s = compute_vs(tuple(p1), tuple(p2), v_f, v_AUV)\n",
    "    total_time += d / max(v_s, 1e-9)\n",
    "    return total_time\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# LỚP CHÍNH GA\n",
    "# ==========================\n",
    "\n",
    "class ClusterTSP_GA:\n",
    "    def __init__(self, clusters, ga_params=None):\n",
    "        self.clusters = clusters\n",
    "        self.cluster_centers = [(0.0, 0.0, 0.0)] + [clusters[k][\"center\"] for k in sorted(clusters.keys())]\n",
    "        self.n = len(self.cluster_centers)\n",
    "\n",
    "        defaults = {\n",
    "            'pop_size': 50,\n",
    "            'generations': 200,\n",
    "            'crossover_rate': 0.8,\n",
    "            'mutation_rate': 0.2,\n",
    "            'elitism_k': 3,\n",
    "            'tournament_size': 3,\n",
    "            'crossover_type': 'OX',\n",
    "            'mutation_type': 'inversion',\n",
    "            'local_search': True,\n",
    "            'v_f': 0.3,\n",
    "            'v_AUV': 1.0,\n",
    "            'verbose': False\n",
    "        }\n",
    "        if ga_params:\n",
    "            defaults.update(ga_params)\n",
    "        self.params = defaults\n",
    "        self.best_fitness_history = []\n",
    "\n",
    "    def create_individual(self):\n",
    "        seq = list(range(1, self.n))\n",
    "        random.shuffle(seq)\n",
    "        return [0] + seq\n",
    "\n",
    "    def create_population(self):\n",
    "        return [self.create_individual() for _ in range(self.params['pop_size'])]\n",
    "\n",
    "    def fitness(self, ind):\n",
    "        total_time = travel_time(ind, self.cluster_centers, self.params['v_f'], self.params['v_AUV'])\n",
    "        return 1.0 / (total_time + 1e-9)\n",
    "\n",
    "    def tournament_selection(self, population):\n",
    "        return max(random.sample(population, self.params['tournament_size']), key=self.fitness)\n",
    "\n",
    "    def order_crossover(self, p1, p2):\n",
    "        sub1, sub2 = p1[1:], p2[1:]\n",
    "        a, b = sorted(random.sample(range(len(sub1)), 2))\n",
    "        c1, c2 = [-1]*len(sub1), [-1]*len(sub1)\n",
    "        c1[a:b], c2[a:b] = sub1[a:b], sub2[a:b]\n",
    "        ptr = b\n",
    "        for x in sub2[b:]+sub2[:b]:\n",
    "            if x not in c1:\n",
    "                c1[ptr % len(sub1)] = x\n",
    "                ptr += 1\n",
    "        ptr = b\n",
    "        for x in sub1[b:]+sub1[:b]:\n",
    "            if x not in c2:\n",
    "                c2[ptr % len(sub2)] = x\n",
    "                ptr += 1\n",
    "        return [0]+c1, [0]+c2\n",
    "\n",
    "    def inversion_mutation(self, ind):\n",
    "        i, j = sorted(random.sample(range(1, len(ind)), 2))\n",
    "        ind[i:j+1] = list(reversed(ind[i:j+1]))\n",
    "        return ind\n",
    "\n",
    "    def evolve(self):\n",
    "        pop = self.create_population()\n",
    "        best = max(pop, key=self.fitness)\n",
    "        best_time = travel_time(best, self.cluster_centers, self.params['v_f'], self.params['v_AUV'])\n",
    "        for _ in range(self.params['generations']):\n",
    "            fitnesses = [self.fitness(ind) for ind in pop]\n",
    "            best_gen = pop[np.argmax(fitnesses)]\n",
    "            gen_best_time = travel_time(best_gen, self.cluster_centers, self.params['v_f'], self.params['v_AUV'])\n",
    "            if gen_best_time < best_time:\n",
    "                best, best_time = best_gen.copy(), gen_best_time\n",
    "            elite_idx = np.argsort(fitnesses)[-self.params['elitism_k']:]\n",
    "            new_pop = [pop[i].copy() for i in elite_idx]\n",
    "            while len(new_pop) < self.params['pop_size']:\n",
    "                p1, p2 = self.tournament_selection(pop), self.tournament_selection(pop)\n",
    "                c1, c2 = self.order_crossover(p1, p2) if random.random() < self.params['crossover_rate'] else (p1.copy(), p2.copy())\n",
    "                if random.random() < self.params['mutation_rate']:\n",
    "                    c1 = self.inversion_mutation(c1)\n",
    "                if random.random() < self.params['mutation_rate']:\n",
    "                    c2 = self.inversion_mutation(c2)\n",
    "                new_pop += [c1, c2]\n",
    "            pop = new_pop[:self.params['pop_size']]\n",
    "        return best, best_time\n",
    "\n",
    "\n",
    "def compute_energy(best_time):\n",
    "    G, L, n = 100, 1024, 4\n",
    "    P_t, P_r, P_idle, DR, DR_i = 1.6e-3, 0.8e-3, 0.1e-3, 4000, 1e6\n",
    "    E_tx_MN = G * P_t * L / DR\n",
    "    E_idle_MN = (best_time - G * L / DR) * P_idle\n",
    "    E_total_MN = E_tx_MN + E_idle_MN\n",
    "    E_rx_TN = G * P_r * L * n / DR\n",
    "    E_tx_TN = G * P_t * L * n / DR_i\n",
    "    E_idle_TN = (best_time - (G * L * n / DR) - (G * L * n / DR_i)) * P_idle\n",
    "    E_total_TN = E_rx_TN + E_tx_TN + E_idle_TN\n",
    "    return {\n",
    "        \"Member\": {\"E_tx\": E_tx_MN, \"E_idle\": E_idle_MN, \"E_total\": E_total_MN},\n",
    "        \"Target\": {\"E_rx\": E_rx_TN, \"E_tx\": E_tx_TN, \"E_idle\": E_idle_TN, \"E_total\": E_total_TN}\n",
    "    }\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# CHẠY TOÀN BỘ CÁC FILE JSON TRONG THƯ MỤC\n",
    "# ==========================\n",
    "\n",
    "def main():\n",
    "    input_dir = \"D:/Year 4/tiến hóa/project/UWSN_greedy/output_data_kmeans\"\n",
    "    output_dir = \"D:/Year 4/tiến hóa/project/UWSN_greedy/output_path/output_ga/\"\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    files = [f for f in os.listdir(input_dir) if f.endswith(\".json\")]\n",
    "\n",
    "    ga_params = {\n",
    "        'pop_size': 40,\n",
    "        'generations': 200,\n",
    "        'crossover_rate': 0.8,\n",
    "        'mutation_rate': 0.2,\n",
    "        'elitism_k': 3,\n",
    "        'local_search': True,\n",
    "        'v_f': 1.2,\n",
    "        'v_AUV': 3.0,\n",
    "        'verbose': False\n",
    "    }\n",
    "\n",
    "    for filename in files:\n",
    "        input_path = os.path.join(input_dir, filename)\n",
    "        print(f\"\\n=== Đang xử lý file: {filename} ===\")\n",
    "\n",
    "        with open(input_path, 'r') as f:\n",
    "            clusters = json.load(f)\n",
    "\n",
    "        ga = ClusterTSP_GA(clusters, ga_params)\n",
    "        best, best_time = ga.evolve()\n",
    "        energy = compute_energy(best_time)\n",
    "\n",
    "        result = {\n",
    "            \"input_file\": filename,\n",
    "            \"best_path\": best,\n",
    "            \"best_time\": best_time,\n",
    "            \"energy\": energy,\n",
    "            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"result_{os.path.splitext(filename)[0]}.json\")\n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(result, f, indent=4)\n",
    "\n",
    "        print(f\"Đã lưu kết quả: {output_path}\")\n",
    "        print(f\"   -> Best time: {best_time:.4f}s\\n\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f352b0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# ==========================\n",
    "# HÀM TÍNH TOÁN TỐC ĐỘ & THỜI GIAN\n",
    "# ==========================\n",
    "\n",
    "def compute_vs(p1, p2, v_f, v_AUV):\n",
    "    x1, y1, z1 = p1\n",
    "    x2, y2, z2 = p2\n",
    "    Lx, Ly, Lz = x2 - x1, y2 - y1, z2 - z1\n",
    "    L_mag = math.sqrt(Lx**2 + Ly**2 + Lz**2)\n",
    "    if L_mag == 0:\n",
    "        return v_AUV\n",
    "    cos_beta = Lz / L_mag\n",
    "    cos_beta = np.clip(cos_beta, -1, 1)\n",
    "    beta = math.acos(cos_beta)\n",
    "    inner = np.clip((v_f * cos_beta) / v_AUV, -1, 1)\n",
    "    angle = beta + math.acos(inner)\n",
    "    v_s = abs(math.cos(angle) * v_AUV / cos_beta)\n",
    "    return v_s\n",
    "\n",
    "\n",
    "def travel_time(path, coords, v_f, v_AUV):\n",
    "    total_time = 0.0\n",
    "    for i in range(len(path) - 1):\n",
    "        p1, p2 = coords[path[i]], coords[path[i + 1]]\n",
    "        d = np.linalg.norm(np.array(p2) - np.array(p1))\n",
    "        v_s = compute_vs(tuple(p1), tuple(p2), v_f, v_AUV)\n",
    "        total_time += d / max(v_s, 1e-9)\n",
    "    # quay lại điểm đầu\n",
    "    p1, p2 = coords[path[-1]], coords[path[0]]\n",
    "    d = np.linalg.norm(np.array(p2) - np.array(p1))\n",
    "    v_s = compute_vs(tuple(p1), tuple(p2), v_f, v_AUV)\n",
    "    total_time += d / max(v_s, 1e-9)\n",
    "    return total_time\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# LỚP GA (đã chỉnh để map index -> cluster_head id)\n",
    "# ==========================\n",
    "\n",
    "class ClusterTSP_GA:\n",
    "    def __init__(self, clusters, ga_params=None):\n",
    "        # clusters: dict {cid: {\"nodes\": [...], \"center\": [x,y,z], \"cluster_head\": nid}}\n",
    "        self.clusters = clusters\n",
    "        # build ordered list of centers and mapping index->cluster_head id\n",
    "        sorted_keys = sorted(clusters.keys(), key=lambda x: int(x))\n",
    "        self.index_to_ch = [None]  # index 0 is AUV base (O)\n",
    "        self.cluster_centers = [(0.0, 0.0, 0.0)]\n",
    "        for k in sorted_keys:\n",
    "            c = clusters[k]['center']\n",
    "            self.cluster_centers.append(tuple(c))\n",
    "            self.index_to_ch.append(clusters[k].get('cluster_head', None))\n",
    "\n",
    "        self.n = len(self.cluster_centers)\n",
    "\n",
    "        defaults = {\n",
    "            'pop_size': 50,\n",
    "            'generations': 200,\n",
    "            'crossover_rate': 0.8,\n",
    "            'mutation_rate': 0.2,\n",
    "            'elitism_k': 3,\n",
    "            'tournament_size': 3,\n",
    "            'crossover_type': 'OX',\n",
    "            'mutation_type': 'inversion',\n",
    "            'local_search': True,\n",
    "            'v_f': 0.3,\n",
    "            'v_AUV': 1.0,\n",
    "            'verbose': False\n",
    "        }\n",
    "        if ga_params:\n",
    "            defaults.update(ga_params)\n",
    "        self.params = defaults\n",
    "        self.best_fitness_history = []\n",
    "\n",
    "    def create_individual(self):\n",
    "        seq = list(range(1, self.n))\n",
    "        random.shuffle(seq)\n",
    "        return [0] + seq\n",
    "\n",
    "    def create_population(self):\n",
    "        return [self.create_individual() for _ in range(self.params['pop_size'])]\n",
    "\n",
    "    def fitness(self, ind):\n",
    "        total_time = travel_time(ind, self.cluster_centers, self.params['v_f'], self.params['v_AUV'])\n",
    "        return 1.0 / (total_time + 1e-9)\n",
    "\n",
    "    def tournament_selection(self, population):\n",
    "        return max(random.sample(population, self.params['tournament_size']), key=self.fitness)\n",
    "\n",
    "    def order_crossover(self, p1, p2):\n",
    "        sub1, sub2 = p1[1:], p2[1:]\n",
    "        a, b = sorted(random.sample(range(len(sub1)), 2))\n",
    "        c1, c2 = [-1]*len(sub1), [-1]*len(sub1)\n",
    "        c1[a:b], c2[a:b] = sub1[a:b], sub2[a:b]\n",
    "        ptr = b\n",
    "        for x in sub2[b:]+sub2[:b]:\n",
    "            if x not in c1:\n",
    "                c1[ptr % len(sub1)] = x\n",
    "                ptr += 1\n",
    "        ptr = b\n",
    "        for x in sub1[b:]+sub1[:b]:\n",
    "            if x not in c2:\n",
    "                c2[ptr % len(sub2)] = x\n",
    "                ptr += 1\n",
    "        return [0]+c1, [0]+c2\n",
    "\n",
    "    def inversion_mutation(self, ind):\n",
    "        i, j = sorted(random.sample(range(1, len(ind)), 2))\n",
    "        ind[i:j+1] = list(reversed(ind[i:j+1]))\n",
    "        return ind\n",
    "\n",
    "    def evolve(self):\n",
    "        pop = self.create_population()\n",
    "        best = max(pop, key=self.fitness)\n",
    "        best_time = travel_time(best, self.cluster_centers, self.params['v_f'], self.params['v_AUV'])\n",
    "        for _ in range(self.params['generations']):\n",
    "            fitnesses = [self.fitness(ind) for ind in pop]\n",
    "            best_gen = pop[np.argmax(fitnesses)]\n",
    "            gen_best_time = travel_time(best_gen, self.cluster_centers, self.params['v_f'], self.params['v_AUV'])\n",
    "            if gen_best_time < best_time:\n",
    "                best, best_time = best_gen.copy(), gen_best_time\n",
    "            elite_idx = np.argsort(fitnesses)[-self.params['elitism_k']:]\n",
    "            new_pop = [pop[i].copy() for i in elite_idx]\n",
    "            while len(new_pop) < self.params['pop_size']:\n",
    "                p1, p2 = self.tournament_selection(pop), self.tournament_selection(pop)\n",
    "                c1, c2 = self.order_crossover(p1, p2) if random.random() < self.params['crossover_rate'] else (p1.copy(), p2.copy())\n",
    "                if random.random() < self.params['mutation_rate']:\n",
    "                    c1 = self.inversion_mutation(c1)\n",
    "                if random.random() < self.params['mutation_rate']:\n",
    "                    c2 = self.inversion_mutation(c2)\n",
    "                new_pop += [c1, c2]\n",
    "            pop = new_pop[:self.params['pop_size']]\n",
    "        # convert best (indices) to cluster head node ids sequence (map 0->'O')\n",
    "        mapped_path = ['O' if idx == 0 else self.index_to_ch[idx] for idx in best]\n",
    "        return best, mapped_path, best_time\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# HÀM NĂNG LƯỢNG (giữ nguyên công thức bạn cung cấp)\n",
    "# ==========================\n",
    "\n",
    "def compute_energy(best_time):\n",
    "    G, L, n = 100, 1024, 4\n",
    "    P_t, P_r, P_idle, DR, DR_i = 1.6e-3, 0.8e-3, 0.1e-3, 4000, 1e6\n",
    "    E_tx_MN = G * P_t * L / DR\n",
    "    E_idle_MN = (best_time - G * L / DR) * P_idle\n",
    "    E_total_MN = E_tx_MN + E_idle_MN\n",
    "    E_rx_TN = G * P_r * L * n / DR\n",
    "    E_tx_TN = G * P_t * L * n / DR_i\n",
    "    E_idle_TN = (best_time - (G * L * n / DR) - (G * L * n / DR_i)) * P_idle\n",
    "    E_total_TN = E_rx_TN + E_tx_TN + E_idle_TN\n",
    "    return {\n",
    "        \"Member\": {\"E_tx\": E_tx_MN, \"E_idle\": E_idle_MN, \"E_total\": E_total_MN},\n",
    "        \"Target\": {\"E_rx\": E_rx_TN, \"E_tx\": E_tx_TN, \"E_idle\": E_idle_TN, \"E_total\": E_total_TN}\n",
    "    }\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# HÀM PHÂN CỤM VÀ CHỌN CLUSTER HEAD (sử dụng code bạn cung cấp)\n",
    "# ==========================\n",
    "\n",
    "def cluster_split(nodes, node_ids, node_data=None, r_sen=50, R=20, max_depth=10, depth=0):\n",
    "    center = np.mean(nodes, axis=0)\n",
    "    dists = np.linalg.norm(nodes - center, axis=1)\n",
    "    if (len(nodes) <= R and np.all(dists <= r_sen)) or depth >= max_depth:\n",
    "        return [{\n",
    "            \"node_ids\": node_ids,\n",
    "            \"nodes\": nodes,\n",
    "            \"center\": center,\n",
    "            \"node_data\": node_data if node_data else {}\n",
    "        }]\n",
    "\n",
    "    # Kmeans với k=2 để chia cụm\n",
    "    kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(nodes)\n",
    "\n",
    "    clusters = []\n",
    "    for i in range(2):\n",
    "        sub_nodes = nodes[labels == i]\n",
    "        sub_ids = [node_ids[j] for j in range(len(node_ids)) if labels[j] == i]\n",
    "        sub_node_data = {}\n",
    "        if node_data:\n",
    "            for node_id in sub_ids:\n",
    "                if node_id in node_data:\n",
    "                    sub_node_data[node_id] = node_data[node_id]\n",
    "        clusters += cluster_split(sub_nodes, sub_ids, sub_node_data, r_sen, R, max_depth, depth + 1)\n",
    "\n",
    "    return clusters\n",
    "\n",
    "\n",
    "def choose_cluster_head(cluster, node_data_dict):\n",
    "    nodes = cluster[\"nodes\"]\n",
    "    center = cluster[\"center\"]\n",
    "    node_ids = cluster[\"node_ids\"]\n",
    "\n",
    "    dists_to_center = np.linalg.norm(nodes - center, axis=1)\n",
    "    max_Q = -1\n",
    "    best_cluster_head = node_ids[0]\n",
    "\n",
    "    for i, node_id in enumerate(node_ids):\n",
    "        if node_id in node_data_dict:\n",
    "            node_info = node_data_dict[node_id]\n",
    "            E_current = node_info.get('residual_energy', 100.0)\n",
    "            E0 = node_info.get('initial_energy', 100.0)\n",
    "            if E_current <= 0:\n",
    "                E_current = 0.1\n",
    "            energy_ratio = E0 / E_current\n",
    "            d_tocenter = dists_to_center[i]\n",
    "            Q = d_tocenter ** energy_ratio\n",
    "            if Q > max_Q:\n",
    "                max_Q = Q\n",
    "                best_cluster_head = node_id\n",
    "        else:\n",
    "            # fallback: choose nearest to center\n",
    "            if i == 0 or dists_to_center[i] < dists_to_center[node_ids.index(best_cluster_head)]:\n",
    "                best_cluster_head = node_id\n",
    "    return best_cluster_head\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# HÀM QUẢN LÝ NĂNG LƯỢNG VÀ NODE CHẾT\n",
    "# ==========================\n",
    "\n",
    "def update_energy(all_nodes, clusters, energy_report):\n",
    "    # energy_report has 'Member' and 'Target' E_total\n",
    "    for cid, cinfo in clusters.items():\n",
    "        ch = cinfo.get('cluster_head')\n",
    "        nodes = cinfo.get('nodes', [])\n",
    "        for nid in nodes:\n",
    "            if nid not in all_nodes:\n",
    "                continue\n",
    "            if nid == ch:\n",
    "                all_nodes[nid]['residual_energy'] -= energy_report['Target']['E_total']\n",
    "            else:\n",
    "                all_nodes[nid]['residual_energy'] -= energy_report['Member']['E_total']\n",
    "            # clamp\n",
    "            if all_nodes[nid]['residual_energy'] < 0:\n",
    "                all_nodes[nid]['residual_energy'] = 0.0\n",
    "\n",
    "\n",
    "def remove_dead_nodes(all_nodes, clusters):\n",
    "    dead = [nid for nid, info in list(all_nodes.items()) if info['residual_energy'] <= 0]\n",
    "    for nid in dead:\n",
    "        del all_nodes[nid]\n",
    "    # remove from node_positions will be handled by caller\n",
    "    # clean clusters: remove clusters that have no nodes left\n",
    "    new_clusters = {}\n",
    "    for cid, cinfo in clusters.items():\n",
    "        alive_nodes = [nid for nid in cinfo.get('nodes', []) if nid in all_nodes]\n",
    "        if alive_nodes:\n",
    "            new_c = dict(cinfo)\n",
    "            new_c['nodes'] = alive_nodes\n",
    "            # if cluster head died, will select new CH during recluster\n",
    "            new_clusters[cid] = new_c\n",
    "    return new_clusters, dead\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# HÀM PHÂN CỤM LẠI TỪ node_positions\n",
    "# ==========================\n",
    "\n",
    "def recluster(all_nodes, node_positions, r_sen=50, R=20):\n",
    "    ids = sorted(list(all_nodes.keys()))\n",
    "    if len(ids) == 0:\n",
    "        return {}\n",
    "    coords = np.array([node_positions[nid] for nid in ids])\n",
    "    raw_clusters = cluster_split(coords, ids, all_nodes, r_sen=r_sen, R=R)\n",
    "    clusters = {}\n",
    "    for i, c in enumerate(raw_clusters):\n",
    "        center = c['center'].tolist()\n",
    "        node_ids = c['node_ids']\n",
    "        ch = choose_cluster_head(c, all_nodes)\n",
    "        clusters[i] = {'nodes': node_ids, 'center': center, 'cluster_head': ch}\n",
    "    return clusters\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# MAIN: vòng lặp nhiều chu kỳ\n",
    "# ==========================\n",
    "\n",
    "def main():\n",
    "    input_dir = \"D:/Year 4/tiến hóa/project/data/output_data_kmeans\"\n",
    "    output_dir = \"D:/Year 4/tiến hóa/project/data/output_path/output_ga_multicycle\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    files = [f for f in os.listdir(input_dir) if f.endswith('.json')]\n",
    "\n",
    "    ga_params = {\n",
    "        'pop_size': 40,\n",
    "        'generations': 200,\n",
    "        'crossover_rate': 0.8,\n",
    "        'mutation_rate': 0.2,\n",
    "        'elitism_k': 3,\n",
    "        'local_search': True,\n",
    "        'v_f': 1.2,\n",
    "        'v_AUV': 3.0,\n",
    "        'verbose': False\n",
    "    }\n",
    "\n",
    "    INITIAL_ENERGY = 100.0\n",
    "\n",
    "    for filename in files:\n",
    "        input_path = os.path.join(input_dir, filename)\n",
    "        print(f\"\\n=== Đang xử lý file: {filename} ===\")\n",
    "        with open(input_path, 'r') as f:\n",
    "            clusters_in = json.load(f)\n",
    "\n",
    "        # Build initial node list and try to find node positions\n",
    "        # If there's a separate nodes_positions.json in same folder, use it.\n",
    "        # Else, approximate member node positions by using cluster centers + small noise.\n",
    "        node_positions = {}\n",
    "        all_nodes = {}\n",
    "\n",
    "        # collect all node ids from clusters_in\n",
    "        all_node_ids = set()\n",
    "        for k, v in clusters_in.items():\n",
    "            for nid in v.get('nodes', []):\n",
    "                all_node_ids.add(nid)\n",
    "            # cluster_head too (may duplicate)\n",
    "            ch = v.get('cluster_head')\n",
    "            if ch is not None:\n",
    "                all_node_ids.add(ch)\n",
    "\n",
    "        # attempt to load node positions file (optional)\n",
    "        nodes_pos_file = os.path.join(input_dir, 'nodes_positions.json')\n",
    "        if os.path.exists(nodes_pos_file):\n",
    "            try:\n",
    "                with open(nodes_pos_file, 'r') as f:\n",
    "                    node_positions = json.load(f)\n",
    "                # ensure numeric keys\n",
    "                node_positions = {int(k): tuple(v) for k, v in node_positions.items()}\n",
    "                print(\"Đã nạp node_positions từ nodes_positions.json\")\n",
    "            except Exception as e:\n",
    "                print(\"Không thể đọc nodes_positions.json, sẽ tạo vị trí gần center. Error:\", e)\n",
    "\n",
    "        # if no node_positions available, approximate\n",
    "        if not node_positions:\n",
    "            for k, v in clusters_in.items():\n",
    "                center = tuple(v.get('center', (0.0, 0.0, 0.0)))\n",
    "                for nid in v.get('nodes', []):\n",
    "                    # small random offset\n",
    "                    offset = np.random.normal(scale=5.0, size=3)\n",
    "                    node_positions[nid] = tuple(np.array(center) + offset)\n",
    "                # ensure cluster head has a position (if listed separately)\n",
    "                ch = v.get('cluster_head')\n",
    "                if ch is not None and ch not in node_positions:\n",
    "                    node_positions[ch] = center\n",
    "            print(\"Tạo giả lập node_positions bằng center + noise (vì không tìm thấy file vị trí)\")\n",
    "\n",
    "        # initialize energy\n",
    "        for nid in list(all_node_ids):\n",
    "            all_nodes[nid] = {'initial_energy': INITIAL_ENERGY, 'residual_energy': INITIAL_ENERGY}\n",
    "\n",
    "        total_nodes = len(all_nodes)\n",
    "        print(f\"Tổng số node ban đầu: {total_nodes}\")\n",
    "\n",
    "        # Start with clusters_in (possibly reformat keys to ints)\n",
    "        clusters = {}\n",
    "        for k, v in clusters_in.items():\n",
    "            clusters[int(k)] = {'nodes': v.get('nodes', []), 'center': v.get('center', []), 'cluster_head': v.get('cluster_head')}\n",
    "\n",
    "        cycle = 0\n",
    "        outputs = []\n",
    "\n",
    "        while True:\n",
    "            cycle += 1\n",
    "            print(f\"\\n--- Cycle {cycle} ---\")\n",
    "\n",
    "            alive_ratio = len(all_nodes) / total_nodes if total_nodes > 0 else 0\n",
    "            print(f\"Tỉ lệ node sống: {alive_ratio*100:.2f}% ({len(all_nodes)}/{total_nodes})\")\n",
    "            if alive_ratio < 0.9:\n",
    "                print(\"Dừng mô phỏng: tỉ lệ node sống < 90%\")\n",
    "                break\n",
    "\n",
    "            if len(clusters) == 0:\n",
    "                print(\"Không còn cụm nào (không còn node). Dừng.\")\n",
    "                break\n",
    "\n",
    "            # run GA on current clusters\n",
    "            ga = ClusterTSP_GA(clusters, ga_params)\n",
    "            best_indices, best_mapped_path, best_time = ga.evolve()\n",
    "\n",
    "            energy_report = compute_energy(best_time)\n",
    "\n",
    "            # update energies\n",
    "            update_energy(all_nodes, clusters, energy_report)\n",
    "\n",
    "            # remove dead nodes\n",
    "            clusters, dead_nodes = remove_dead_nodes(all_nodes, clusters)\n",
    "            # also remove from node_positions\n",
    "            for d in dead_nodes:\n",
    "                if d in node_positions:\n",
    "                    del node_positions[d]\n",
    "\n",
    "            # log output for this cycle\n",
    "            outputs.append({\n",
    "                'cycle': cycle,\n",
    "                'num_clusters': len(clusters),\n",
    "                'best_path_indices': best_indices,\n",
    "                'best_path_node_ids': best_mapped_path,\n",
    "                'best_time': best_time,\n",
    "                'dead_nodes': dead_nodes,\n",
    "                'alive_nodes': len(all_nodes)\n",
    "            })\n",
    "\n",
    "            print(f\"Số cụm hiện tại: {len(clusters)}\")\n",
    "            print(f\"Đường đi (index trong GA): {best_indices}\")\n",
    "            print(f\"Đường đi (node ids, 'O' = base): {best_mapped_path}\")\n",
    "            if dead_nodes:\n",
    "                print(\"Nodes bị loại (chết) trong chu kỳ này:\", dead_nodes)\n",
    "            else:\n",
    "                print(\"Không có node chết ở chu kỳ này.\")\n",
    "\n",
    "            # if still nodes left, recluster and choose CH for next cycle\n",
    "            if len(all_nodes) > 0:\n",
    "                clusters = recluster(all_nodes, node_positions)\n",
    "                # if recluster produced clusters, ensure centers are lists\n",
    "                for k, v in clusters.items():\n",
    "                    clusters[k]['center'] = [float(x) for x in v['center']]\n",
    "\n",
    "        # save outputs to file\n",
    "        out_filename = os.path.join(output_dir, f\"multicycle_result_{os.path.splitext(filename)[0]}.json\")\n",
    "        meta = {\n",
    "            'input_file': filename,\n",
    "            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'initial_total_nodes': total_nodes,\n",
    "            'cycles': cycle - 1,\n",
    "            'outputs': outputs\n",
    "        }\n",
    "        with open(out_filename, 'w') as f:\n",
    "            json.dump(meta, f, indent=4)\n",
    "\n",
    "        print(f\"Kết quả đã lưu: {out_filename}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586f175d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# ==========================\n",
    "# MỤC TIÊU: Phiên bản NHANH (KHÔNG GA)\n",
    "# - Mỗi chu kỳ: phân cụm lại (cluster_split), chọn CH (choose_cluster_head)\n",
    "# - Tính đường đi ước lượng bằng heuristic nearest-neighbor tới các tâm cụm\n",
    "# - Dùng compute_energy(best_time) (bạn đã có) để tính năng lượng tiêu thụ\n",
    "# - Cập nhật năng lượng nodes, loại node chết\n",
    "# - Lặp đến khi tỉ lệ node sống < 0.9\n",
    "# ==========================\n",
    "\n",
    "# ==========================\n",
    "# HÀM TỐC ĐỘ VÀ THỜI GIAN (giữ nguyên từ mã gốc)\n",
    "# ==========================\n",
    "\n",
    "def compute_vs(p1, p2, v_f, v_AUV):\n",
    "    x1, y1, z1 = p1\n",
    "    x2, y2, z2 = p2\n",
    "    Lx, Ly, Lz = x2 - x1, y2 - y1, z2 - z1\n",
    "    L_mag = math.sqrt(Lx**2 + Ly**2 + Lz**2)\n",
    "    if L_mag == 0:\n",
    "        return v_AUV\n",
    "    cos_beta = Lz / L_mag\n",
    "    cos_beta = np.clip(cos_beta, -1, 1)\n",
    "    beta = math.acos(cos_beta)\n",
    "    inner = np.clip((v_f * cos_beta) / v_AUV, -1, 1)\n",
    "    angle = beta + math.acos(inner)\n",
    "    v_s = abs(math.cos(angle) * v_AUV / cos_beta)\n",
    "    return v_s\n",
    "\n",
    "\n",
    "def travel_time(path, coords, v_f, v_AUV):\n",
    "    total_time = 0.0\n",
    "    if len(path) <= 1:\n",
    "        return 0.0\n",
    "    for i in range(len(path) - 1):\n",
    "        p1, p2 = coords[path[i]], coords[path[i + 1]]\n",
    "        d = np.linalg.norm(np.array(p2) - np.array(p1))\n",
    "        v_s = compute_vs(tuple(p1), tuple(p2), v_f, v_AUV)\n",
    "        total_time += d / max(v_s, 1e-9)\n",
    "    # quay lại điểm đầu\n",
    "    p1, p2 = coords[path[-1]], coords[path[0]]\n",
    "    d = np.linalg.norm(np.array(p2) - np.array(p1))\n",
    "    v_s = compute_vs(tuple(p1), tuple(p2), v_f, v_AUV)\n",
    "    total_time += d / max(v_s, 1e-9)\n",
    "    return total_time\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# HÀM CLUSTER (giữ nguyên logic của bạn)\n",
    "# ==========================\n",
    "\n",
    "def cluster_split(nodes, node_ids, node_data=None, r_sen=50, R=20, max_depth=10, depth=0):\n",
    "    center = np.mean(nodes, axis=0)\n",
    "    dists = np.linalg.norm(nodes - center, axis=1)\n",
    "    if (len(nodes) <= R and np.all(dists <= r_sen)) or depth >= max_depth:\n",
    "        return [{\n",
    "            \"node_ids\": node_ids,\n",
    "            \"nodes\": nodes,\n",
    "            \"center\": center,\n",
    "            \"node_data\": node_data if node_data else {}\n",
    "        }]\n",
    "\n",
    "    kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(nodes)\n",
    "\n",
    "    clusters = []\n",
    "    for i in range(2):\n",
    "        sub_nodes = nodes[labels == i]\n",
    "        sub_ids = [node_ids[j] for j in range(len(node_ids)) if labels[j] == i]\n",
    "        sub_node_data = {}\n",
    "        if node_data:\n",
    "            for node_id in sub_ids:\n",
    "                if node_id in node_data:\n",
    "                    sub_node_data[node_id] = node_data[node_id]\n",
    "        clusters += cluster_split(sub_nodes, sub_ids, sub_node_data, r_sen, R, max_depth, depth + 1)\n",
    "\n",
    "    return clusters\n",
    "\n",
    "\n",
    "def choose_cluster_head(cluster, node_data_dict):\n",
    "    nodes = cluster[\"nodes\"]\n",
    "    center = cluster[\"center\"]\n",
    "    node_ids = cluster[\"node_ids\"]\n",
    "\n",
    "    dists_to_center = np.linalg.norm(nodes - center, axis=1)\n",
    "    max_Q = -1\n",
    "    best_cluster_head = node_ids[0]\n",
    "\n",
    "    for i, node_id in enumerate(node_ids):\n",
    "        if node_id in node_data_dict:\n",
    "            node_info = node_data_dict[node_id]\n",
    "            E_current = node_info.get('residual_energy', 100.0)\n",
    "            E0 = node_info.get('initial_energy', 100.0)\n",
    "            if E_current <= 0:\n",
    "                E_current = 0.1\n",
    "            energy_ratio = E0 / E_current\n",
    "            d_tocenter = dists_to_center[i]\n",
    "            Q = d_tocenter ** energy_ratio\n",
    "            if Q > max_Q:\n",
    "                max_Q = Q\n",
    "                best_cluster_head = node_id\n",
    "        else:\n",
    "            # fallback: choose nearest to center\n",
    "            if i == 0 or dists_to_center[i] < dists_to_center[node_ids.index(best_cluster_head)]:\n",
    "                best_cluster_head = node_id\n",
    "    return best_cluster_head\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# HÀM NĂNG LƯỢNG (giữ nguyên compute_energy)\n",
    "# ==========================\n",
    "\n",
    "def compute_energy(best_time):\n",
    "    G, L, n = 100, 1024, 4\n",
    "    P_t, P_r, P_idle, DR, DR_i = 1.6e-3, 0.8e-3, 0.1e-3, 4000, 1e6\n",
    "    E_tx_MN = G * P_t * L / DR\n",
    "    E_idle_MN = (best_time - G * L / DR) * P_idle\n",
    "    E_total_MN = E_tx_MN + E_idle_MN\n",
    "    E_rx_TN = G * P_r * L * n / DR\n",
    "    E_tx_TN = G * P_t * L * n / DR_i\n",
    "    E_idle_TN = (best_time - (G * L * n / DR) - (G * L * n / DR_i)) * P_idle\n",
    "    E_total_TN = E_rx_TN + E_tx_TN + E_idle_TN\n",
    "    return {\n",
    "        \"Member\": {\"E_tx\": E_tx_MN, \"E_idle\": E_idle_MN, \"E_total\": E_total_MN},\n",
    "        \"Target\": {\"E_rx\": E_rx_TN, \"E_tx\": E_tx_TN, \"E_idle\": E_idle_TN, \"E_total\": E_total_TN}\n",
    "    }\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# HÀM CẬP NHẬT NĂNG LƯỢNG VÀ XOÁ NODE CHẾT\n",
    "# ==========================\n",
    "\n",
    "def update_energy(all_nodes, clusters, energy_report):\n",
    "    for cid, cinfo in clusters.items():\n",
    "        ch = cinfo.get('cluster_head')\n",
    "        nodes = cinfo.get('nodes', [])\n",
    "        for nid in nodes:\n",
    "            if nid not in all_nodes:\n",
    "                continue\n",
    "            if nid == ch:\n",
    "                all_nodes[nid]['residual_energy'] -= energy_report['Target']['E_total']\n",
    "            else:\n",
    "                all_nodes[nid]['residual_energy'] -= energy_report['Member']['E_total']\n",
    "            all_nodes[nid]['residual_energy'] = max(all_nodes[nid]['residual_energy'], 0.0)\n",
    "\n",
    "\n",
    "def remove_dead_nodes(all_nodes, clusters):\n",
    "    dead = [nid for nid, info in list(all_nodes.items()) if info['residual_energy'] <= 0]\n",
    "    for nid in dead:\n",
    "        del all_nodes[nid]\n",
    "    new_clusters = {}\n",
    "    for cid, cinfo in clusters.items():\n",
    "        alive_nodes = [nid for nid in cinfo.get('nodes', []) if nid in all_nodes]\n",
    "        if alive_nodes:\n",
    "            new_c = dict(cinfo)\n",
    "            new_c['nodes'] = alive_nodes\n",
    "            new_clusters[cid] = new_c\n",
    "    return new_clusters, dead\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# HÀM TẠO ĐƯỜNG ĐI ƯỚC LƯỢNG (NEAREST-NEIGHBOR) TRÊN CÁC TÂM CỤM\n",
    "# ==========================\n",
    "\n",
    "def nearest_neighbor_path(centers):\n",
    "    # centers: list of tuples, with centers[0] being base O\n",
    "    n = len(centers)\n",
    "    if n == 1:\n",
    "        return [0]\n",
    "    unvisited = set(range(1, n))\n",
    "    path = [0]\n",
    "    current = 0\n",
    "    coords = np.array(centers)\n",
    "    while unvisited:\n",
    "        dists = np.linalg.norm(coords[list(unvisited)] - coords[current], axis=1)\n",
    "        next_idx = list(unvisited)[int(np.argmin(dists))]\n",
    "        path.append(next_idx)\n",
    "        unvisited.remove(next_idx)\n",
    "        current = next_idx\n",
    "    return path\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# HÀM PHÂN CỤM LẠI (RECLUSTER) - giữ nguyên logic\n",
    "# ==========================\n",
    "\n",
    "def recluster(all_nodes, node_positions, r_sen=50, R=20):\n",
    "    ids = sorted(list(all_nodes.keys()))\n",
    "    if len(ids) == 0:\n",
    "        return {}\n",
    "    coords = np.array([node_positions[nid] for nid in ids])\n",
    "    raw_clusters = cluster_split(coords, ids, all_nodes, r_sen=r_sen, R=R)\n",
    "    clusters = {}\n",
    "    for i, c in enumerate(raw_clusters):\n",
    "        center = c['center'].tolist()\n",
    "        node_ids = c['node_ids']\n",
    "        ch = choose_cluster_head(c, all_nodes)\n",
    "        clusters[i] = {'nodes': node_ids, 'center': center, 'cluster_head': ch}\n",
    "    return clusters\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# MAIN: SIMULATION NHANH KHÔNG GA\n",
    "# ==========================\n",
    "\n",
    "def main():\n",
    "    input_dir = \"D:/Year 4/tiến hóa/project/data/output_data_kmeans\"\n",
    "    output_dir = \"D:/Year 4/tiến hóa/project/data/output_path/output_ga_multicycle_noGA\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    files = [f for f in os.listdir(input_dir) if f.endswith('.json')]\n",
    "\n",
    "    INITIAL_ENERGY = 100.0\n",
    "    v_f = 1.2\n",
    "    v_AUV = 3.0\n",
    "\n",
    "    for filename in files:\n",
    "        input_path = os.path.join(input_dir, filename)\n",
    "        print(f\"=== Đang xử lý file: {filename} ===\")\n",
    "        with open(input_path, 'r') as f:\n",
    "            clusters_in = json.load(f)\n",
    "\n",
    "        node_positions = {}\n",
    "        all_nodes = {}\n",
    "\n",
    "        all_node_ids = set()\n",
    "        for k, v in clusters_in.items():\n",
    "            for nid in v.get('nodes', []):\n",
    "                all_node_ids.add(nid)\n",
    "            ch = v.get('cluster_head')\n",
    "            if ch is not None:\n",
    "                all_node_ids.add(ch)\n",
    "\n",
    "        nodes_pos_file = os.path.join(input_dir, 'nodes_positions.json')\n",
    "        if os.path.exists(nodes_pos_file):\n",
    "            try:\n",
    "                with open(nodes_pos_file, 'r') as f:\n",
    "                    node_positions = json.load(f)\n",
    "                node_positions = {int(k): tuple(v) for k, v in node_positions.items()}\n",
    "                print(\"Đã nạp node_positions từ nodes_positions.json\")\n",
    "            except Exception:\n",
    "                print(\"Không thể đọc nodes_positions.json, sẽ tạo vị trí giả lập\")\n",
    "\n",
    "        if not node_positions:\n",
    "            for k, v in clusters_in.items():\n",
    "                center = tuple(v.get('center', (0.0, 0.0, 0.0)))\n",
    "                for nid in v.get('nodes', []):\n",
    "                    offset = np.random.normal(scale=5.0, size=3)\n",
    "                    node_positions[nid] = tuple(np.array(center) + offset)\n",
    "                ch = v.get('cluster_head')\n",
    "                if ch is not None and ch not in node_positions:\n",
    "                    node_positions[ch] = center\n",
    "            print(\"Tạo giả lập node_positions bằng center + noise (vì không tìm thấy file vị trí)\")\n",
    "\n",
    "        for nid in list(all_node_ids):\n",
    "            all_nodes[nid] = {'initial_energy': INITIAL_ENERGY, 'residual_energy': INITIAL_ENERGY}\n",
    "\n",
    "        total_nodes = len(all_nodes)\n",
    "        print(f\"Tổng số node ban đầu: {total_nodes}\")\n",
    "\n",
    "        # initial clusters: use given clusters_in, but convert keys to int\n",
    "        clusters = {int(k): {'nodes': v.get('nodes', []), 'center': v.get('center', []), 'cluster_head': v.get('cluster_head')} for k, v in clusters_in.items()}\n",
    "\n",
    "        cycle = 0\n",
    "        outputs = []\n",
    "\n",
    "        while True:\n",
    "            cycle += 1\n",
    "            alive_ratio = len(all_nodes) / total_nodes if total_nodes > 0 else 0\n",
    "            print(f\"\n",
    "--- Cycle {cycle} --- | alive_ratio = {alive_ratio*100:.2f}% ({len(all_nodes)}/{total_nodes})\")\n",
    "            if alive_ratio < 0.9:\n",
    "                print(\"Dừng mô phỏng: tỉ lệ node sống < 90%\")\n",
    "                break\n",
    "\n",
    "            # recluster using current alive nodes (so CH selection uses updated residual energy)\n",
    "            clusters = recluster(all_nodes, node_positions)\n",
    "            if len(clusters) == 0:\n",
    "                print(\"Không còn cụm (không còn node). Dừng.\")\n",
    "                break\n",
    "\n",
    "            # build centers list with base O at index 0\n",
    "            sorted_keys = sorted(clusters.keys(), key=lambda x: int(x))\n",
    "            centers = [(0.0, 0.0, 0.0)]\n",
    "            index_to_ch = [None]\n",
    "            for k in sorted_keys:\n",
    "                centers.append(tuple(clusters[k]['center']))\n",
    "                index_to_ch.append(clusters[k]['cluster_head'])\n",
    "\n",
    "            # compute an approximate path using nearest neighbor on centers\n",
    "            path_indices = nearest_neighbor_path(centers)\n",
    "            # compute travel time for this path\n",
    "            best_time = travel_time(path_indices, centers, v_f, v_AUV)\n",
    "            # compute energy consumption for this cycle\n",
    "            energy_report = compute_energy(best_time)\n",
    "\n",
    "            # update energy per node\n",
    "            update_energy(all_nodes, clusters, energy_report)\n",
    "\n",
    "            # remove dead nodes\n",
    "            clusters, dead_nodes = remove_dead_nodes(all_nodes, clusters)\n",
    "            for d in dead_nodes:\n",
    "                if d in node_positions:\n",
    "                    del node_positions[d]\n",
    "\n",
    "            outputs.append({\n",
    "                'cycle': cycle,\n",
    "                'alive_nodes': len(all_nodes),\n",
    "                'num_clusters': len(clusters),\n",
    "                'path_center_indices': path_indices,\n",
    "                'path_cluster_head_ids': [index_to_ch[idx] if idx!=0 else 'O' for idx in path_indices],\n",
    "                'best_time_est': best_time,\n",
    "                'energy_report': energy_report,\n",
    "                'dead_nodes': dead_nodes\n",
    "            })\n",
    "\n",
    "            print(f\"Num clusters: {len(clusters)} | path (centers idx): {path_indices} | CH path: {[index_to_ch[idx] if idx!=0 else 'O' for idx in path_indices]}\")\n",
    "            if dead_nodes:\n",
    "                print(\"Nodes chết trong chu kỳ này:\", dead_nodes)\n",
    "\n",
    "        # save outputs\n",
    "        out_filename = os.path.join(output_dir, f\"noGA_multicycle_result_{os.path.splitext(filename)[0]}.json\")\n",
    "        meta = {\n",
    "            'input_file': filename,\n",
    "            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'initial_total_nodes': total_nodes,\n",
    "            'cycles_completed': cycle - 1,\n",
    "            'outputs': outputs\n",
    "        }\n",
    "        with open(out_filename, 'w') as f:\n",
    "            json.dump(meta, f, indent=4)\n",
    "\n",
    "        print(f\"Kết quả đã lưu: {out_filename}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f5a6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# ==========================\n",
    "# MỤC TIÊU: Phiên bản NHANH (KHÔNG GA)\n",
    "# - Mỗi chu kỳ: phân cụm lại (cluster_split), chọn CH (choose_cluster_head)\n",
    "# - Tính đường đi ước lượng bằng heuristic nearest-neighbor tới các tâm cụm\n",
    "# - Dùng compute_energy(best_time) (bạn đã có) để tính năng lượng tiêu thụ\n",
    "# - Cập nhật năng lượng nodes, loại node chết\n",
    "# - Lặp đến khi tỉ lệ node sống < 0.9\n",
    "# ==========================\n",
    "\n",
    "# ==========================\n",
    "# HÀM TỐC ĐỘ VÀ THỜI GIAN (giữ nguyên từ mã gốc)\n",
    "# ==========================\n",
    "\n",
    "def compute_vs(p1, p2, v_f, v_AUV):\n",
    "    x1, y1, z1 = p1\n",
    "    x2, y2, z2 = p2\n",
    "    Lx, Ly, Lz = x2 - x1, y2 - y1, z2 - z1\n",
    "    L_mag = math.sqrt(Lx**2 + Ly**2 + Lz**2)\n",
    "    if L_mag == 0:\n",
    "        return v_AUV\n",
    "    cos_beta = Lz / L_mag\n",
    "    cos_beta = np.clip(cos_beta, -1, 1)\n",
    "    beta = math.acos(cos_beta)\n",
    "    inner = np.clip((v_f * cos_beta) / v_AUV, -1, 1)\n",
    "    angle = beta + math.acos(inner)\n",
    "    v_s = abs(math.cos(angle) * v_AUV / cos_beta)\n",
    "    return v_s\n",
    "\n",
    "\n",
    "def travel_time(path, coords, v_f, v_AUV):\n",
    "    total_time = 0.0\n",
    "    if len(path) <= 1:\n",
    "        return 0.0\n",
    "    for i in range(len(path) - 1):\n",
    "        p1, p2 = coords[path[i]], coords[path[i + 1]]\n",
    "        d = np.linalg.norm(np.array(p2) - np.array(p1))\n",
    "        v_s = compute_vs(tuple(p1), tuple(p2), v_f, v_AUV)\n",
    "        total_time += d / max(v_s, 1e-9)\n",
    "    # quay lại điểm đầu\n",
    "    p1, p2 = coords[path[-1]], coords[path[0]]\n",
    "    d = np.linalg.norm(np.array(p2) - np.array(p1))\n",
    "    v_s = compute_vs(tuple(p1), tuple(p2), v_f, v_AUV)\n",
    "    total_time += d / max(v_s, 1e-9)\n",
    "    return total_time\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# HÀM CLUSTER (giữ nguyên logic của bạn)\n",
    "# ==========================\n",
    "\n",
    "def cluster_split(nodes, node_ids, node_data=None, r_sen=50, R=20, max_depth=10, depth=0):\n",
    "    center = np.mean(nodes, axis=0)\n",
    "    dists = np.linalg.norm(nodes - center, axis=1)\n",
    "    if (len(nodes) <= R and np.all(dists <= r_sen)) or depth >= max_depth:\n",
    "        return [{\n",
    "            \"node_ids\": node_ids,\n",
    "            \"nodes\": nodes,\n",
    "            \"center\": center,\n",
    "            \"node_data\": node_data if node_data else {}\n",
    "        }]\n",
    "\n",
    "    kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(nodes)\n",
    "\n",
    "    clusters = []\n",
    "    for i in range(2):\n",
    "        sub_nodes = nodes[labels == i]\n",
    "        sub_ids = [node_ids[j] for j in range(len(node_ids)) if labels[j] == i]\n",
    "        sub_node_data = {}\n",
    "        if node_data:\n",
    "            for node_id in sub_ids:\n",
    "                if node_id in node_data:\n",
    "                    sub_node_data[node_id] = node_data[node_id]\n",
    "        clusters += cluster_split(sub_nodes, sub_ids, sub_node_data, r_sen, R, max_depth, depth + 1)\n",
    "\n",
    "    return clusters\n",
    "\n",
    "\n",
    "def choose_cluster_head(cluster, node_data_dict):\n",
    "    nodes = cluster[\"nodes\"]\n",
    "    center = cluster[\"center\"]\n",
    "    node_ids = cluster[\"node_ids\"]\n",
    "\n",
    "    dists_to_center = np.linalg.norm(nodes - center, axis=1)\n",
    "    max_Q = -1\n",
    "    best_cluster_head = node_ids[0]\n",
    "\n",
    "    for i, node_id in enumerate(node_ids):\n",
    "        if node_id in node_data_dict:\n",
    "            node_info = node_data_dict[node_id]\n",
    "            E_current = node_info.get('residual_energy', 100.0)\n",
    "            E0 = node_info.get('initial_energy', 100.0)\n",
    "            if E_current <= 0:\n",
    "                E_current = 0.1\n",
    "            energy_ratio = E0 / E_current\n",
    "            d_tocenter = dists_to_center[i]\n",
    "            Q = d_tocenter ** energy_ratio\n",
    "            if Q > max_Q:\n",
    "                max_Q = Q\n",
    "                best_cluster_head = node_id\n",
    "        else:\n",
    "            # fallback: choose nearest to center\n",
    "            if i == 0 or dists_to_center[i] < dists_to_center[node_ids.index(best_cluster_head)]:\n",
    "                best_cluster_head = node_id\n",
    "    return best_cluster_head\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# HÀM NĂNG LƯỢNG (giữ nguyên compute_energy)\n",
    "# ==========================\n",
    "\n",
    "def compute_energy(best_time):\n",
    "    G, L, n = 100, 1024, 4\n",
    "    P_t, P_r, P_idle, DR, DR_i = 1.6e-3, 0.8e-3, 0.1e-3, 4000, 1e6\n",
    "    E_tx_MN = G * P_t * L / DR\n",
    "    E_idle_MN = (best_time - G * L / DR) * P_idle\n",
    "    E_total_MN = E_tx_MN + E_idle_MN\n",
    "    E_rx_TN = G * P_r * L * n / DR\n",
    "    E_tx_TN = G * P_t * L * n / DR_i\n",
    "    E_idle_TN = (best_time - (G * L * n / DR) - (G * L * n / DR_i)) * P_idle\n",
    "    E_total_TN = E_rx_TN + E_tx_TN + E_idle_TN\n",
    "    return {\n",
    "        \"Member\": {\"E_tx\": E_tx_MN, \"E_idle\": E_idle_MN, \"E_total\": E_total_MN},\n",
    "        \"Target\": {\"E_rx\": E_rx_TN, \"E_tx\": E_tx_TN, \"E_idle\": E_idle_TN, \"E_total\": E_total_TN}\n",
    "    }\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# HÀM CẬP NHẬT NĂNG LƯỢNG VÀ XOÁ NODE CHẾT\n",
    "# ==========================\n",
    "\n",
    "def update_energy(all_nodes, clusters, energy_report):\n",
    "    for cid, cinfo in clusters.items():\n",
    "        ch = cinfo.get('cluster_head')\n",
    "        nodes = cinfo.get('nodes', [])\n",
    "        for nid in nodes:\n",
    "            if nid not in all_nodes:\n",
    "                continue\n",
    "            if nid == ch:\n",
    "                all_nodes[nid]['residual_energy'] -= energy_report['Target']['E_total']\n",
    "            else:\n",
    "                all_nodes[nid]['residual_energy'] -= energy_report['Member']['E_total']\n",
    "            all_nodes[nid]['residual_energy'] = max(all_nodes[nid]['residual_energy'], 0.0)\n",
    "\n",
    "\n",
    "def remove_dead_nodes(all_nodes, clusters):\n",
    "    dead = [nid for nid, info in list(all_nodes.items()) if info['residual_energy'] <= 0]\n",
    "    for nid in dead:\n",
    "        del all_nodes[nid]\n",
    "    new_clusters = {}\n",
    "    for cid, cinfo in clusters.items():\n",
    "        alive_nodes = [nid for nid in cinfo.get('nodes', []) if nid in all_nodes]\n",
    "        if alive_nodes:\n",
    "            new_c = dict(cinfo)\n",
    "            new_c['nodes'] = alive_nodes\n",
    "            new_clusters[cid] = new_c\n",
    "    return new_clusters, dead\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# HÀM TẠO ĐƯỜNG ĐI ƯỚC LƯỢNG (NEAREST-NEIGHBOR) TRÊN CÁC TÂM CỤM\n",
    "# ==========================\n",
    "\n",
    "def nearest_neighbor_path(centers):\n",
    "    # centers: list of tuples, with centers[0] being base O\n",
    "    n = len(centers)\n",
    "    if n == 1:\n",
    "        return [0]\n",
    "    unvisited = set(range(1, n))\n",
    "    path = [0]\n",
    "    current = 0\n",
    "    coords = np.array(centers)\n",
    "    while unvisited:\n",
    "        dists = np.linalg.norm(coords[list(unvisited)] - coords[current], axis=1)\n",
    "        next_idx = list(unvisited)[int(np.argmin(dists))]\n",
    "        path.append(next_idx)\n",
    "        unvisited.remove(next_idx)\n",
    "        current = next_idx\n",
    "    return path\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# HÀM PHÂN CỤM LẠI (RECLUSTER) - giữ nguyên logic\n",
    "# ==========================\n",
    "\n",
    "def recluster(all_nodes, node_positions, r_sen=50, R=20):\n",
    "    ids = sorted(list(all_nodes.keys()))\n",
    "    if len(ids) == 0:\n",
    "        return {}\n",
    "    coords = np.array([node_positions[nid] for nid in ids])\n",
    "    raw_clusters = cluster_split(coords, ids, all_nodes, r_sen=r_sen, R=R)\n",
    "    clusters = {}\n",
    "    for i, c in enumerate(raw_clusters):\n",
    "        center = c['center'].tolist()\n",
    "        node_ids = c['node_ids']\n",
    "        ch = choose_cluster_head(c, all_nodes)\n",
    "        clusters[i] = {'nodes': node_ids, 'center': center, 'cluster_head': ch}\n",
    "    return clusters\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# MAIN: SIMULATION NHANH KHÔNG GA\n",
    "# ==========================\n",
    "\n",
    "def main():\n",
    "    input_dir = \"/kaggle/input/data-cluster2/output_data_kmeans\"\n",
    "    output_dir = \"/kaggle/working/output_ga_multicycle\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    files = [f for f in os.listdir(input_dir) if f.endswith('.json')]\n",
    "\n",
    "    INITIAL_ENERGY = 100.0\n",
    "    v_f = 1.2\n",
    "    v_AUV = 3.0\n",
    "\n",
    "    for filename in files:\n",
    "        input_path = os.path.join(input_dir, filename)\n",
    "        print(f\"=== Đang xử lý file: {filename} ===\")\n",
    "        with open(input_path, 'r') as f:\n",
    "            clusters_in = json.load(f)\n",
    "\n",
    "        node_positions = {}\n",
    "        all_nodes = {}\n",
    "\n",
    "        all_node_ids = set()\n",
    "        for k, v in clusters_in.items():\n",
    "            for nid in v.get('nodes', []):\n",
    "                all_node_ids.add(nid)\n",
    "            ch = v.get('cluster_head')\n",
    "            if ch is not None:\n",
    "                all_node_ids.add(ch)\n",
    "\n",
    "        nodes_pos_file = os.path.join(input_dir, 'nodes_positions.json')\n",
    "        if os.path.exists(nodes_pos_file):\n",
    "            try:\n",
    "                with open(nodes_pos_file, 'r') as f:\n",
    "                    node_positions = json.load(f)\n",
    "                node_positions = {int(k): tuple(v) for k, v in node_positions.items()}\n",
    "                print(\"Đã nạp node_positions từ nodes_positions.json\")\n",
    "            except Exception:\n",
    "                print(\"Không thể đọc nodes_positions.json, sẽ tạo vị trí giả lập\")\n",
    "\n",
    "        if not node_positions:\n",
    "            for k, v in clusters_in.items():\n",
    "                center = tuple(v.get('center', (0.0, 0.0, 0.0)))\n",
    "                for nid in v.get('nodes', []):\n",
    "                    offset = np.random.normal(scale=5.0, size=3)\n",
    "                    node_positions[nid] = tuple(np.array(center) + offset)\n",
    "                ch = v.get('cluster_head')\n",
    "                if ch is not None and ch not in node_positions:\n",
    "                    node_positions[ch] = center\n",
    "            print(\"Tạo giả lập node_positions bằng center + noise (vì không tìm thấy file vị trí)\")\n",
    "\n",
    "        for nid in list(all_node_ids):\n",
    "            all_nodes[nid] = {'initial_energy': INITIAL_ENERGY, 'residual_energy': INITIAL_ENERGY}\n",
    "\n",
    "        total_nodes = len(all_nodes)\n",
    "        print(f\"Tổng số node ban đầu: {total_nodes}\")\n",
    "\n",
    "        # initial clusters: use given clusters_in, but convert keys to int\n",
    "        clusters = {int(k): {'nodes': v.get('nodes', []), 'center': v.get('center', []), 'cluster_head': v.get('cluster_head')} for k, v in clusters_in.items()}\n",
    "\n",
    "        cycle = 0\n",
    "        outputs = []\n",
    "\n",
    "        while True:\n",
    "            cycle += 1\n",
    "            alive_ratio = len(all_nodes) / total_nodes if total_nodes > 0 else 0\n",
    "            print(f\"\n",
    "--- Cycle {cycle} --- | alive_ratio = {alive_ratio*100:.2f}% ({len(all_nodes)}/{total_nodes})\")\n",
    "            if alive_ratio < 0.9:\n",
    "                print(\"Dừng mô phỏng: tỉ lệ node sống < 90%\")\n",
    "                break\n",
    "\n",
    "            # recluster using current alive nodes (so CH selection uses updated residual energy)\n",
    "            clusters = recluster(all_nodes, node_positions)\n",
    "            if len(clusters) == 0:\n",
    "                print(\"Không còn cụm (không còn node). Dừng.\")\n",
    "                break\n",
    "\n",
    "            # build centers list with base O at index 0\n",
    "            sorted_keys = sorted(clusters.keys(), key=lambda x: int(x))\n",
    "            centers = [(0.0, 0.0, 0.0)]\n",
    "            index_to_ch = [None]\n",
    "            for k in sorted_keys:\n",
    "                centers.append(tuple(clusters[k]['center']))\n",
    "                index_to_ch.append(clusters[k]['cluster_head'])\n",
    "\n",
    "            # compute an approximate path using nearest neighbor on centers\n",
    "            path_indices = nearest_neighbor_path(centers)\n",
    "            # compute travel time for this path\n",
    "            best_time = travel_time(path_indices, centers, v_f, v_AUV)\n",
    "            # compute energy consumption for this cycle\n",
    "            energy_report = compute_energy(best_time)\n",
    "\n",
    "            # update energy per node\n",
    "            update_energy(all_nodes, clusters, energy_report)\n",
    "\n",
    "            # remove dead nodes\n",
    "            clusters, dead_nodes = remove_dead_nodes(all_nodes, clusters)\n",
    "            for d in dead_nodes:\n",
    "                if d in node_positions:\n",
    "                    del node_positions[d]\n",
    "\n",
    "            outputs.append({\n",
    "                'cycle': cycle,\n",
    "                'alive_nodes': len(all_nodes),\n",
    "                'num_clusters': len(clusters),\n",
    "                'path_center_indices': path_indices,\n",
    "                'path_cluster_head_ids': [index_to_ch[idx] if idx!=0 else 'O' for idx in path_indices],\n",
    "                'best_time_est': best_time,\n",
    "                'energy_report': energy_report,\n",
    "                'dead_nodes': dead_nodes\n",
    "            })\n",
    "\n",
    "            print(f\"Num clusters: {len(clusters)} | path (centers idx): {path_indices} | CH path: {[index_to_ch[idx] if idx!=0 else 'O' for idx in path_indices]}\")\n",
    "            if dead_nodes:\n",
    "                print(\"Nodes chết trong chu kỳ này:\", dead_nodes)\n",
    "\n",
    "        # save outputs\n",
    "        out_filename = os.path.join(output_dir, f\"noGA_multicycle_result_{os.path.splitext(filename)[0]}.json\")\n",
    "        meta = {\n",
    "            'input_file': filename,\n",
    "            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'initial_total_nodes': total_nodes,\n",
    "            'cycles_completed': cycle - 1,\n",
    "            'outputs': outputs\n",
    "        }\n",
    "        with open(out_filename, 'w') as f:\n",
    "            json.dump(meta, f, indent=4)\n",
    "\n",
    "        print(f\"Kết quả đã lưu: {out_filename}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
