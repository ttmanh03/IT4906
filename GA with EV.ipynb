{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2c0daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# ==========================\n",
    "# H√ÄM T√çNH TO√ÅN T·ªêC ƒê·ªò & TH·ªúI GIAN\n",
    "# ==========================\n",
    "\n",
    "def compute_vs(p1, p2, v_f, v_AUV):\n",
    "    x1, y1, z1 = p1\n",
    "    x2, y2, z2 = p2\n",
    "    Lx, Ly, Lz = x2 - x1, y2 - y1, z2 - z1\n",
    "    L_mag = math.sqrt(Lx**2 + Ly**2 + Lz**2)\n",
    "    if L_mag == 0:\n",
    "        return v_AUV\n",
    "    cos_beta = Lz / L_mag\n",
    "    cos_beta = np.clip(cos_beta, -1, 1)\n",
    "    beta = math.acos(cos_beta)\n",
    "    inner = np.clip((v_f * cos_beta) / v_AUV, -1, 1)\n",
    "    angle = beta + math.acos(inner)\n",
    "    v_s = abs(math.cos(angle) * v_AUV / cos_beta)\n",
    "    return v_s\n",
    "\n",
    "\n",
    "def travel_time(path, coords, v_f, v_AUV):\n",
    "    total_time = 0.0\n",
    "    for i in range(len(path) - 1):\n",
    "        p1, p2 = coords[path[i]], coords[path[i + 1]]\n",
    "        d = np.linalg.norm(np.array(p2) - np.array(p1))\n",
    "        v_s = compute_vs(tuple(p1), tuple(p2), v_f, v_AUV)\n",
    "        total_time += d / max(v_s, 1e-9)\n",
    "    # quay l·∫°i ƒëi·ªÉm ƒë·∫ßu\n",
    "    p1, p2 = coords[path[-1]], coords[path[0]]\n",
    "    d = np.linalg.norm(np.array(p2) - np.array(p1))\n",
    "    v_s = compute_vs(tuple(p1), tuple(p2), v_f, v_AUV)\n",
    "    total_time += d / max(v_s, 1e-9)\n",
    "    return total_time\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# L·ªöP GA (ƒë√£ ch·ªânh ƒë·ªÉ map index -> cluster_head id)\n",
    "# ==========================\n",
    "\n",
    "class ClusterTSP_GA:\n",
    "    def __init__(self, clusters, ga_params=None):\n",
    "        self.clusters = clusters\n",
    "        sorted_keys = sorted(clusters.keys(), key=lambda x: int(x))\n",
    "        self.index_to_ch = [None]\n",
    "        self.cluster_centers = [(0.0, 0.0, 0.0)]\n",
    "        for k in sorted_keys:\n",
    "            c = clusters[k]['center']\n",
    "            self.cluster_centers.append(tuple(c))\n",
    "            self.index_to_ch.append(clusters[k].get('cluster_head', None))\n",
    "\n",
    "        self.n = len(self.cluster_centers)\n",
    "\n",
    "        defaults = {\n",
    "            'pop_size': 50,\n",
    "            'generations': 200,\n",
    "            'crossover_rate': 0.8,\n",
    "            'mutation_rate': 0.2,\n",
    "            'elitism_k': 3,\n",
    "            'tournament_size': 3,\n",
    "            'crossover_type': 'OX',\n",
    "            'mutation_type': 'inversion',\n",
    "            'local_search': True,\n",
    "            'v_f': 1.2,\n",
    "            'v_AUV': 3.0,\n",
    "            'verbose': False\n",
    "        }\n",
    "        if ga_params:\n",
    "            defaults.update(ga_params)\n",
    "        self.params = defaults\n",
    "        self.best_fitness_history = []\n",
    "\n",
    "    def create_individual(self):\n",
    "        seq = list(range(1, self.n))\n",
    "        random.shuffle(seq)\n",
    "        return [0] + seq\n",
    "\n",
    "    def create_population(self):\n",
    "        return [self.create_individual() for _ in range(self.params['pop_size'])]\n",
    "\n",
    "    def fitness(self, ind):\n",
    "        total_time = travel_time(ind, self.cluster_centers, self.params['v_f'], self.params['v_AUV'])\n",
    "        return 1.0 / (total_time + 1e-9)\n",
    "\n",
    "    def tournament_selection(self, population):\n",
    "        return max(random.sample(population, self.params['tournament_size']), key=self.fitness)\n",
    "\n",
    "    def order_crossover(self, p1, p2):\n",
    "        sub1, sub2 = p1[1:], p2[1:]\n",
    "        a, b = sorted(random.sample(range(len(sub1)), 2))\n",
    "        c1, c2 = [-1]*len(sub1), [-1]*len(sub1)\n",
    "        c1[a:b], c2[a:b] = sub1[a:b], sub2[a:b]\n",
    "        ptr = b\n",
    "        for x in sub2[b:]+sub2[:b]:\n",
    "            if x not in c1:\n",
    "                c1[ptr % len(sub1)] = x\n",
    "                ptr += 1\n",
    "        ptr = b\n",
    "        for x in sub1[b:]+sub1[:b]:\n",
    "            if x not in c2:\n",
    "                c2[ptr % len(sub2)] = x\n",
    "                ptr += 1\n",
    "        return [0]+c1, [0]+c2\n",
    "\n",
    "    def inversion_mutation(self, ind):\n",
    "        i, j = sorted(random.sample(range(1, len(ind)), 2))\n",
    "        ind[i:j+1] = list(reversed(ind[i:j+1]))\n",
    "        return ind\n",
    "\n",
    "    def evolve(self):\n",
    "        pop = self.create_population()\n",
    "        best = max(pop, key=self.fitness)\n",
    "        best_time = travel_time(best, self.cluster_centers, self.params['v_f'], self.params['v_AUV'])\n",
    "        for _ in range(self.params['generations']):\n",
    "            fitnesses = [self.fitness(ind) for ind in pop]\n",
    "            best_gen = pop[np.argmax(fitnesses)]\n",
    "            gen_best_time = travel_time(best_gen, self.cluster_centers, self.params['v_f'], self.params['v_AUV'])\n",
    "            if gen_best_time < best_time:\n",
    "                best, best_time = best_gen.copy(), gen_best_time\n",
    "            elite_idx = np.argsort(fitnesses)[-self.params['elitism_k']:]\n",
    "            new_pop = [pop[i].copy() for i in elite_idx]\n",
    "            while len(new_pop) < self.params['pop_size']:\n",
    "                p1, p2 = self.tournament_selection(pop), self.tournament_selection(pop)\n",
    "                c1, c2 = self.order_crossover(p1, p2) if random.random() < self.params['crossover_rate'] else (p1.copy(), p2.copy())\n",
    "                if random.random() < self.params['mutation_rate']:\n",
    "                    c1 = self.inversion_mutation(c1)\n",
    "                if random.random() < self.params['mutation_rate']:\n",
    "                    c2 = self.inversion_mutation(c2)\n",
    "                new_pop += [c1, c2]\n",
    "            pop = new_pop[:self.params['pop_size']]\n",
    "        mapped_path = ['O' if idx == 0 else self.index_to_ch[idx] for idx in best]\n",
    "        return best, mapped_path, best_time\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# H√ÄM NƒÇNG L∆Ø·ª¢NG\n",
    "# ==========================\n",
    "\n",
    "def compute_energy(best_time):\n",
    "    G, L, n = 100, 1024, 4\n",
    "    P_t, P_r, P_idle, DR, DR_i = 1.6e-3, 0.8e-3, 0.1e-3, 4000, 1e6\n",
    "    E_tx_MN = G * P_t * L / DR\n",
    "    E_idle_MN = (best_time - G * L / DR) * P_idle\n",
    "    E_total_MN = E_tx_MN + E_idle_MN\n",
    "    E_rx_TN = G * P_r * L * n / DR\n",
    "    E_tx_TN = G * P_t * L * n / DR_i\n",
    "    E_idle_TN = (best_time - (G * L * n / DR) - (G * L * n / DR_i)) * P_idle\n",
    "    E_total_TN = E_rx_TN + E_tx_TN + E_idle_TN\n",
    "    E_idle_solo = (best_time - (G * L * n / DR_i)) * P_idle\n",
    "    E_total_SOLO = E_tx_TN + E_idle_solo\n",
    "    return {\n",
    "        \"Member\": {\"E_tx\": E_tx_MN, \"E_idle\": E_idle_MN, \"E_total\": E_total_MN},\n",
    "        \"Target\": {\"E_rx\": E_rx_TN, \"E_tx\": E_tx_TN, \"E_idle\": E_idle_TN, \"E_total\": E_total_TN},\n",
    "        \"Solo\": {\"E_tx\": E_tx_TN, \"E_idle\": E_idle_solo, \"E_total\": E_total_SOLO}\n",
    "    }\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# H√ÄM PH√ÇN C·ª§M\n",
    "# ==========================\n",
    "\n",
    "def calculate_objective_function(nodes, labels, centers):\n",
    "    numerator = 0\n",
    "    for i in range(2):\n",
    "        cluster_nodes = nodes[labels == i]\n",
    "        if len(cluster_nodes) > 0:\n",
    "            distances = np.linalg.norm(cluster_nodes - centers[i], axis=1)\n",
    "            numerator += np.sum(distances)\n",
    "    denominator = np.linalg.norm(centers[0] - centers[1])\n",
    "    if denominator == 0:\n",
    "        return float('inf')\n",
    "    return numerator / denominator\n",
    "\n",
    "\n",
    "def check_subgroup_threshold(nodes, r_sen):\n",
    "    if len(nodes) <= 1:\n",
    "        return True\n",
    "    max_distance = 0\n",
    "    for i in range(len(nodes)):\n",
    "        for j in range(i + 1, len(nodes)):\n",
    "            dist = np.linalg.norm(nodes[i] - nodes[j])\n",
    "            max_distance = max(max_distance, dist)\n",
    "    return max_distance <= r_sen\n",
    "\n",
    "\n",
    "def kmeans_with_best_T(nodes, N=30):\n",
    "    best_T = float('inf')\n",
    "    best_labels = None\n",
    "    best_centers = None\n",
    "    for _ in range(N):\n",
    "        kmeans = KMeans(n_clusters=2, n_init=1)\n",
    "        labels = kmeans.fit_predict(nodes)\n",
    "        centers = kmeans.cluster_centers_\n",
    "        T = calculate_objective_function(nodes, labels, centers)\n",
    "        if T < best_T:\n",
    "            best_T = T\n",
    "            best_labels = labels.copy()\n",
    "            best_centers = centers.copy()\n",
    "    return best_labels, best_centers, best_T\n",
    "\n",
    "\n",
    "def cluster_split(nodes, node_ids, node_data=None, r_sen=60, R=20, N=30, max_depth=10, depth=0):\n",
    "    size_ok = len(nodes) <= R\n",
    "    distance_ok = check_subgroup_threshold(nodes, r_sen)\n",
    "    \n",
    "    if (size_ok and distance_ok) or depth >= max_depth:\n",
    "        center = np.mean(nodes, axis=0)\n",
    "        return [{\n",
    "            \"node_ids\": node_ids,\n",
    "            \"nodes\": nodes,\n",
    "            \"center\": center,\n",
    "            \"node_data\": node_data if node_data else {}\n",
    "        }]\n",
    "    \n",
    "    labels, centers, best_T = kmeans_with_best_T(nodes, N)\n",
    "    clusters = []\n",
    "    for i in range(2):\n",
    "        sub_nodes = nodes[labels == i]\n",
    "        sub_ids = [node_ids[j] for j in range(len(node_ids)) if labels[j] == i]\n",
    "        sub_node_data = {}\n",
    "        if node_data:\n",
    "            for node_id in sub_ids:\n",
    "                if node_id in node_data:\n",
    "                    sub_node_data[node_id] = node_data[node_id]\n",
    "        clusters += cluster_split(sub_nodes, sub_ids, sub_node_data, r_sen, R, N, max_depth, depth + 1)\n",
    "    return clusters\n",
    "\n",
    "\n",
    "def choose_cluster_head(cluster_info, node_data=None):\n",
    "    nodes = cluster_info[\"nodes\"]\n",
    "    center = cluster_info[\"center\"]\n",
    "    node_ids = cluster_info[\"node_ids\"]\n",
    "    \n",
    "    if node_data and len(node_data) > 0:\n",
    "        max_energy = -1\n",
    "        ch_id = node_ids[0]\n",
    "        for nid in node_ids:\n",
    "            if nid in node_data and \"residual_energy\" in node_data[nid]:\n",
    "                if node_data[nid][\"residual_energy\"] > max_energy:\n",
    "                    max_energy = node_data[nid][\"residual_energy\"]\n",
    "                    ch_id = nid\n",
    "        return ch_id\n",
    "    else:\n",
    "        distances = np.linalg.norm(nodes - center, axis=1)\n",
    "        min_idx = np.argmin(distances)\n",
    "        return node_ids[min_idx]\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# H√ÄM QU·∫¢N L√ù NƒÇNG L∆Ø·ª¢NG\n",
    "# ==========================\n",
    "\n",
    "def update_energy(all_nodes, clusters, energy_report):\n",
    "    for cid, cinfo in clusters.items():\n",
    "        nodes = cinfo.get('nodes', [])\n",
    "        ch = cinfo.get('cluster_head')\n",
    "        \n",
    "        if len(nodes) == 1:\n",
    "            nid = nodes[0]\n",
    "            if nid in all_nodes:\n",
    "                all_nodes[nid]['residual_energy'] -= energy_report['Solo']['E_total']\n",
    "                if all_nodes[nid]['residual_energy'] < 0:\n",
    "                    all_nodes[nid]['residual_energy'] = 0.0\n",
    "        else:\n",
    "            for nid in nodes:\n",
    "                if nid not in all_nodes:\n",
    "                    continue\n",
    "                if nid == ch:\n",
    "                    all_nodes[nid]['residual_energy'] -= energy_report['Target']['E_total']\n",
    "                else:\n",
    "                    all_nodes[nid]['residual_energy'] -= energy_report['Member']['E_total']\n",
    "                if all_nodes[nid]['residual_energy'] < 0:\n",
    "                    all_nodes[nid]['residual_energy'] = 0.0\n",
    "\n",
    "\n",
    "def remove_dead_nodes(all_nodes, clusters):\n",
    "    dead = [nid for nid, info in list(all_nodes.items()) if info['residual_energy'] <= 0]\n",
    "    for nid in dead:\n",
    "        del all_nodes[nid]\n",
    "    new_clusters = {}\n",
    "    for cid, cinfo in clusters.items():\n",
    "        alive_nodes = [nid for nid in cinfo.get('nodes', []) if nid in all_nodes]\n",
    "        if alive_nodes:\n",
    "            new_c = dict(cinfo)\n",
    "            new_c['nodes'] = alive_nodes\n",
    "            new_clusters[cid] = new_c\n",
    "    return new_clusters, dead\n",
    "\n",
    "\n",
    "def recluster(all_nodes, node_positions, r_sen=50, R=20):\n",
    "    ids = sorted(list(all_nodes.keys()))\n",
    "    if len(ids) == 0:\n",
    "        return {}\n",
    "    coords = np.array([node_positions[nid] for nid in ids])\n",
    "    raw_clusters = cluster_split(coords, ids, all_nodes, r_sen=r_sen, R=R)\n",
    "    clusters = {}\n",
    "    for i, c in enumerate(raw_clusters):\n",
    "        center = c['center'].tolist()\n",
    "        node_ids = c['node_ids']\n",
    "        ch = choose_cluster_head(c, all_nodes)\n",
    "        clusters[i] = {'nodes': node_ids, 'center': center, 'cluster_head': ch}\n",
    "    return clusters\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# H√ÄM V·∫º BI·ªÇU ƒê·ªí REAL-TIME\n",
    "# ==========================\n",
    "\n",
    "def plot_realtime_analysis(outputs, total_nodes, INITIAL_ENERGY, filename, output_dir, cycle):\n",
    "    \"\"\"\n",
    "    V·∫Ω bi·ªÉu ƒë·ªì theo th·ªùi gian th·ª±c sau m·ªói chu k·ª≥\n",
    "    \"\"\"\n",
    "    if len(outputs) == 0:\n",
    "        return\n",
    "    \n",
    "    cycles = [o['cycle'] for o in outputs]\n",
    "    alive_nodes = [o['alive_nodes'] for o in outputs]\n",
    "    cumulative_dead = [total_nodes - a for a in alive_nodes]\n",
    "    total_energy_remaining = [o['total_energy_remaining'] for o in outputs]\n",
    "    travel_times = [o['best_time'] for o in outputs]\n",
    "    \n",
    "    # T√¨m chu k·ª≥ ƒë·∫ßu ti√™n c√≥ node ch·∫øt\n",
    "    first_death_cycle = None\n",
    "    for o in outputs:\n",
    "        if o['dead_nodes']:\n",
    "            first_death_cycle = o['cycle']\n",
    "            break\n",
    "    \n",
    "    # T·∫°o figure\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle(f'Real-time Monitoring - {filename} (Chu k·ª≥ {cycle})', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Bi·ªÉu ƒë·ªì 1: S·ªë node s·ªëng\n",
    "    axes[0, 0].plot(cycles, alive_nodes, 'b-o', linewidth=2, markersize=6)\n",
    "    axes[0, 0].axhline(y=total_nodes * 0.9, color='r', linestyle='--', \n",
    "                       label=f'Ng∆∞·ª°ng 10% ({int(total_nodes * 0.1)} nodes)')\n",
    "    axes[0, 0].set_xlabel('Chu k·ª≥', fontsize=12)\n",
    "    axes[0, 0].set_ylabel('S·ªë node s·ªëng', fontsize=12)\n",
    "    axes[0, 0].set_title('S·ªë node s·ªëng theo th·ªùi gian', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].set_ylim(bottom=0, top=total_nodes * 1.1)\n",
    "    \n",
    "    # Bi·ªÉu ƒë·ªì 2: S·ªë node ch·∫øt t√≠ch l≈©y\n",
    "    axes[0, 1].plot(cycles, cumulative_dead, 'r-s', linewidth=2, markersize=6)\n",
    "    axes[0, 1].set_xlabel('Chu k·ª≥', fontsize=12)\n",
    "    axes[0, 1].set_ylabel('S·ªë node ch·∫øt (t√≠ch l≈©y)', fontsize=12)\n",
    "    axes[0, 1].set_title('S·ªë node ch·∫øt t√≠ch l≈©y theo th·ªùi gian', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    axes[0, 1].set_ylim(bottom=0)\n",
    "    \n",
    "    if first_death_cycle:\n",
    "        axes[0, 1].axvline(x=first_death_cycle, color='orange', linestyle='--', \n",
    "                          label=f'Chu k·ª≥ ƒë·∫ßu ti√™n: {first_death_cycle}')\n",
    "        axes[0, 1].legend()\n",
    "    \n",
    "    # Bi·ªÉu ƒë·ªì 3: T·ªïng nƒÉng l∆∞·ª£ng m·∫°ng\n",
    "    axes[1, 0].plot(cycles, total_energy_remaining, 'g-^', linewidth=2, markersize=6)\n",
    "    axes[1, 0].set_xlabel('Chu k·ª≥', fontsize=12)\n",
    "    axes[1, 0].set_ylabel('T·ªïng nƒÉng l∆∞·ª£ng c√≤n l·∫°i (J)', fontsize=12)\n",
    "    axes[1, 0].set_title('NƒÉng l∆∞·ª£ng t·ªïng th·ªÉ m·∫°ng', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    axes[1, 0].set_ylim(bottom=0)\n",
    "    \n",
    "    # Bi·ªÉu ƒë·ªì 4: Th·ªùi gian di chuy·ªÉn AUV\n",
    "    axes[1, 1].plot(cycles, travel_times, 'm-d', linewidth=2, markersize=6)\n",
    "    axes[1, 1].set_xlabel('Chu k·ª≥', fontsize=12)\n",
    "    axes[1, 1].set_ylabel('Th·ªùi gian di chuy·ªÉn (s)', fontsize=12)\n",
    "    axes[1, 1].set_title('Th·ªùi gian chu k·ª≥ AUV', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    if len(travel_times) > 0:\n",
    "        avg_time = np.mean(travel_times)\n",
    "        axes[1, 1].axhline(y=avg_time, color='r', linestyle='--', \n",
    "                          label=f'TB: {avg_time:.2f}s')\n",
    "        axes[1, 1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \"\"\"# L∆∞u bi·ªÉu ƒë·ªì v·ªõi t√™n duy nh·∫•t cho m·ªói chu k·ª≥\n",
    "    chart_filename = os.path.join(output_dir, \n",
    "                                  f\"realtime_cycle{cycle:03d}_{os.path.splitext(filename)[0]}.png\")\n",
    "    plt.savefig(chart_filename, dpi=300, bbox_inches='tight')\"\"\"\n",
    "    \n",
    "    # C≈©ng l∆∞u b·∫£n \"latest\" ƒë·ªÉ d·ªÖ theo d√µi\n",
    "    latest_filename = os.path.join(output_dir, \n",
    "                                   f\"realtime_latest_{os.path.splitext(filename)[0]}.png\")\n",
    "    plt.savefig(latest_filename, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    plt.close()\n",
    "    \n",
    "    #return chart_filename\n",
    "\n",
    "\n",
    "def save_realtime_results(outputs, meta_info, output_file):\n",
    "    \"\"\"\n",
    "    L∆∞u k·∫øt qu·∫£ theo th·ªùi gian th·ª±c\n",
    "    \"\"\"\n",
    "    meta_info['outputs'] = outputs\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(meta_info, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# MAIN v·ªõi Real-time Monitoring\n",
    "# ==========================\n",
    "\n",
    "def main():\n",
    "    input_dir = \"D:/Year 4/ti·∫øn h√≥a/project/data/output_data_kmeans\"\n",
    "    output_dir = \"D:/Year 4/ti·∫øn h√≥a/project/data/output_path/output_ga_multicycle\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    files = [f for f in os.listdir(input_dir) if f.endswith('.json')]\n",
    "\n",
    "    ga_params = {\n",
    "        'pop_size': 40,\n",
    "        'generations': 200,\n",
    "        'crossover_rate': 0.8,\n",
    "        'mutation_rate': 0.2,\n",
    "        'elitism_k': 3,\n",
    "        'local_search': True,\n",
    "        'v_f': 1.2,\n",
    "        'v_AUV': 3.0,\n",
    "        'verbose': False\n",
    "    }\n",
    "\n",
    "    INITIAL_ENERGY = 100.0\n",
    "\n",
    "    for filename in files:\n",
    "        input_path = os.path.join(input_dir, filename)\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"ƒêANG X·ª¨ L√ù FILE: {filename}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        with open(input_path, 'r') as f:\n",
    "            clusters_in = json.load(f)\n",
    "\n",
    "        node_positions = {}\n",
    "        all_nodes = {}\n",
    "\n",
    "        # Collect all node ids\n",
    "        all_node_ids = set()\n",
    "        for k, v in clusters_in.items():\n",
    "            for nid in v.get('nodes', []):\n",
    "                all_node_ids.add(nid)\n",
    "            ch = v.get('cluster_head')\n",
    "            if ch is not None:\n",
    "                all_node_ids.add(ch)\n",
    "\n",
    "        # Load node positions\n",
    "        nodes_pos_file = \"D:/Year 4/ti·∫øn h√≥a/project/data/input_data_evenly_distributed/nodes_20.json\"\n",
    "        if os.path.exists(nodes_pos_file):\n",
    "            try:\n",
    "                with open(nodes_pos_file, 'r', encoding='utf-8') as f:\n",
    "                    nodes_data = json.load(f)\n",
    "                \n",
    "                node_positions = {}\n",
    "                for node in nodes_data:\n",
    "                    node_id = node['id']\n",
    "                    node_positions[node_id] = (node['x'], node['y'], node['z'])\n",
    "                \n",
    "                print(f\"‚úì ƒê√£ load {len(node_positions)} node positions t·ª´ {os.path.basename(nodes_pos_file)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚úó L·ªói khi ƒë·ªçc file v·ªã tr√≠: {e}\")\n",
    "\n",
    "        # Create approximate positions if needed\n",
    "        if not node_positions:\n",
    "            for k, v in clusters_in.items():\n",
    "                center = tuple(v.get('center', (0.0, 0.0, 0.0)))\n",
    "                for nid in v.get('nodes', []):\n",
    "                    offset = np.random.normal(scale=5.0, size=3)\n",
    "                    node_positions[nid] = tuple(np.array(center) + offset)\n",
    "                ch = v.get('cluster_head')\n",
    "                if ch is not None and ch not in node_positions:\n",
    "                    node_positions[ch] = center\n",
    "            print(\"‚ö† ƒê√£ t·∫°o v·ªã tr√≠ gi·∫£ l·∫≠p cho c√°c nodes\")\n",
    "\n",
    "        # Initialize energy\n",
    "        for nid in list(all_node_ids):\n",
    "            all_nodes[nid] = {\n",
    "                'initial_energy': INITIAL_ENERGY, \n",
    "                'residual_energy': INITIAL_ENERGY\n",
    "            }\n",
    "\n",
    "        total_nodes = len(all_nodes)\n",
    "        print(f\"‚úì T·ªïng s·ªë node ban ƒë·∫ßu: {total_nodes}\")\n",
    "\n",
    "        # Initialize clusters\n",
    "        clusters = {}\n",
    "        for k, v in clusters_in.items():\n",
    "            clusters[int(k)] = {\n",
    "                'nodes': v.get('nodes', []), \n",
    "                'center': v.get('center', []), \n",
    "                'cluster_head': v.get('cluster_head')\n",
    "            }\n",
    "\n",
    "        # Prepare output file\n",
    "        out_filename = os.path.join(output_dir, \n",
    "                                    f\"multicycle_result_{os.path.splitext(filename)[0]}.json\")\n",
    "        \n",
    "        # Meta info\n",
    "        meta_info = {\n",
    "            'input_file': filename,\n",
    "            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'initial_total_nodes': total_nodes,\n",
    "            'cycles': 0,\n",
    "            'total_operation_time': 0.0,\n",
    "            'first_death_cycle': None,\n",
    "            'first_death_time': None,\n",
    "            'final_alive_nodes': 0,\n",
    "            'survival_rate': 0.0\n",
    "        }\n",
    "\n",
    "        cycle = 0\n",
    "        outputs = []\n",
    "        cumulative_time = 0.0\n",
    "        first_death_cycle = None\n",
    "        first_death_time = None\n",
    "\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"B·∫ÆT ƒê·∫¶U M√î PH·ªéNG CHU K·ª≤\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "\n",
    "        # Main simulation loop\n",
    "        while True:\n",
    "            cycle += 1\n",
    "            print(f\"\\n{'‚îÄ'*70}\")\n",
    "            print(f\"CHU K·ª≤ {cycle}\")\n",
    "            print(f\"{'‚îÄ'*70}\")\n",
    "\n",
    "            alive_ratio = len(all_nodes) / total_nodes if total_nodes > 0 else 0\n",
    "            print(f\"T·ªâ l·ªá node s·ªëng: {alive_ratio*100:.2f}% ({len(all_nodes)}/{total_nodes})\")\n",
    "            \n",
    "            if alive_ratio < 0.1:\n",
    "                print(\"\\n‚ö† D·ª™NG: T·ªâ l·ªá node s·ªëng < 10%\")\n",
    "                break\n",
    "\n",
    "            if len(clusters) == 0:\n",
    "                print(\"\\n‚ö† D·ª™NG: Kh√¥ng c√≤n c·ª•m n√†o\")\n",
    "                break\n",
    "\n",
    "            # Run GA\n",
    "            print(f\"ƒêang ch·∫°y GA v·ªõi {len(clusters)} c·ª•m...\", end=\" \")\n",
    "            ga = ClusterTSP_GA(clusters, ga_params)\n",
    "            best_indices, best_mapped_path, best_time = ga.evolve()\n",
    "            print(\"‚úì\")\n",
    "\n",
    "            cumulative_time += best_time\n",
    "            energy_report = compute_energy(best_time)\n",
    "\n",
    "            # Update energies\n",
    "            update_energy(all_nodes, clusters, energy_report)\n",
    "\n",
    "            # Remove dead nodes\n",
    "            clusters, dead_nodes = remove_dead_nodes(all_nodes, clusters)\n",
    "            for d in dead_nodes:\n",
    "                if d in node_positions:\n",
    "                    del node_positions[d]\n",
    "\n",
    "            # Calculate total energy\n",
    "            total_energy_remaining = sum(node['residual_energy'] for node in all_nodes.values())\n",
    "\n",
    "            # Track first death\n",
    "            if dead_nodes and first_death_cycle is None:\n",
    "                first_death_cycle = cycle\n",
    "                first_death_time = cumulative_time\n",
    "\n",
    "            # Log output\n",
    "            output_entry = {\n",
    "                'cycle': cycle,\n",
    "                'num_clusters': len(clusters),\n",
    "                'best_path_indices': best_indices,\n",
    "                'best_path_node_ids': best_mapped_path,\n",
    "                'best_time': best_time,\n",
    "                'cumulative_time': cumulative_time,\n",
    "                'dead_nodes': dead_nodes,\n",
    "                'alive_nodes': len(all_nodes),\n",
    "                'total_energy_remaining': total_energy_remaining\n",
    "            }\n",
    "            outputs.append(output_entry)\n",
    "\n",
    "            # Print cycle summary\n",
    "            print(f\"‚îú‚îÄ S·ªë c·ª•m: {len(clusters)}\")\n",
    "            print(f\"‚îú‚îÄ ƒê∆∞·ªùng ƒëi: {best_mapped_path}\")\n",
    "            print(f\"‚îú‚îÄ Th·ªùi gian chu k·ª≥: {best_time:.2f}s\")\n",
    "            print(f\"‚îú‚îÄ Th·ªùi gian t√≠ch l≈©y: {cumulative_time:.2f}s ({cumulative_time/3600:.2f}h)\")\n",
    "            print(f\"‚îú‚îÄ NƒÉng l∆∞·ª£ng c√≤n l·∫°i: {total_energy_remaining:.2f}J\")\n",
    "            \n",
    "            if dead_nodes:\n",
    "                print(f\"‚îî‚îÄ ‚ö† Node ch·∫øt: {len(dead_nodes)} node(s) - {dead_nodes}\")\n",
    "            else:\n",
    "                print(f\"‚îî‚îÄ ‚úì Kh√¥ng c√≥ node ch·∫øt\")\n",
    "\n",
    "            # ===== REAL-TIME UPDATES =====\n",
    "            \n",
    "            # 1. Save results to file\n",
    "            meta_info.update({\n",
    "                'cycles': cycle,\n",
    "                'total_operation_time': cumulative_time,\n",
    "                'first_death_cycle': first_death_cycle,\n",
    "                'first_death_time': first_death_time,\n",
    "                'final_alive_nodes': len(all_nodes),\n",
    "                'survival_rate': (len(all_nodes)/total_nodes)*100\n",
    "            })\n",
    "            save_realtime_results(outputs, meta_info, out_filename)\n",
    "            \n",
    "            # 2. Plot real-time chart\n",
    "            \"\"\"if cycle % 1 == 0:  # C√≥ th·ªÉ ƒëi·ªÅu ch·ªânh t·∫ßn su·∫•t v·∫Ω (m·ªói N chu k·ª≥)\n",
    "                chart_file = plot_realtime_analysis(\n",
    "                    outputs, total_nodes, INITIAL_ENERGY, filename, output_dir, cycle\n",
    "                )\n",
    "                print(f\"    üìä ƒê√£ c·∫≠p nh·∫≠t bi·ªÉu ƒë·ªì: {os.path.basename(chart_file)}\")\n",
    "            \n",
    "            print(f\"    üíæ ƒê√£ l∆∞u k·∫øt qu·∫£: {os.path.basename(out_filename)}\")\"\"\"\n",
    "            plot_realtime_analysis(\n",
    "                    outputs, total_nodes, INITIAL_ENERGY, filename, output_dir, cycle\n",
    "                )\n",
    "\n",
    "            # Recluster if nodes still alive\n",
    "            if len(all_nodes) > 0:\n",
    "                clusters = recluster(all_nodes, node_positions)\n",
    "                for k, v in clusters.items():\n",
    "                    clusters[k]['center'] = [float(x) for x in v['center']]\n",
    "\n",
    "        # ===== K·∫æT TH√öC M√î PH·ªéNG =====\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"PH√ÇN T√çCH K·∫æT QU·∫¢ CU·ªêI C√ôNG\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"T·ªïng s·ªë chu k·ª≥: {cycle - 1}\")\n",
    "        print(f\"T·ªïng th·ªùi gian ho·∫°t ƒë·ªông: {cumulative_time:.2f}s ({cumulative_time/3600:.2f} gi·ªù)\")\n",
    "        \n",
    "        if first_death_cycle:\n",
    "            print(f\"\\nChu k·ª≥ ƒë·∫ßu ti√™n c√≥ node ch·∫øt: {first_death_cycle}\")\n",
    "            print(f\"Th·ªùi gian ƒë·∫øn l√∫c ch·∫øt ƒë·∫ßu ti√™n: {first_death_time:.2f}s ({first_death_time/3600:.2f} gi·ªù)\")\n",
    "            print(f\"T·ª∑ l·ªá th·ªùi gian: {(first_death_time/cumulative_time)*100:.2f}% t·ªïng th·ªùi gian\")\n",
    "        else:\n",
    "            print(\"\\nKh√¥ng c√≥ node n√†o ch·∫øt trong qu√° tr√¨nh m√¥ ph·ªèng\")\n",
    "        \n",
    "        print(f\"\\nS·ªë node c√≤n s·ªëng cu·ªëi c√πng: {len(all_nodes)}/{total_nodes}\")\n",
    "        print(f\"S·ªë node ƒë√£ ch·∫øt: {total_nodes - len(all_nodes)}\")\n",
    "        print(f\"T·ª∑ l·ªá s·ªëng s√≥t: {(len(all_nodes)/total_nodes)*100:.2f}%\")\n",
    "        \n",
    "        # Th·ªëng k√™ v·ªÅ th·ªùi gian chu k·ª≥\n",
    "        if outputs:\n",
    "            cycle_times = [o['best_time'] for o in outputs]\n",
    "            print(f\"\\nTh·ªùi gian chu k·ª≥ trung b√¨nh: {np.mean(cycle_times):.2f}s\")\n",
    "            print(f\"Th·ªùi gian chu k·ª≥ ng·∫Øn nh·∫•t: {np.min(cycle_times):.2f}s\")\n",
    "            print(f\"Th·ªùi gian chu k·ª≥ d√†i nh·∫•t: {np.max(cycle_times):.2f}s\")\n",
    "            print(f\"ƒê·ªô l·ªách chu·∫©n: {np.std(cycle_times):.2f}s\")\n",
    "        \n",
    "        # Th·ªëng k√™ v·ªÅ s·ªë node ch·∫øt m·ªói chu k·ª≥\n",
    "        deaths_per_cycle = [len(o['dead_nodes']) for o in outputs if o['dead_nodes']]\n",
    "        if deaths_per_cycle:\n",
    "            print(f\"\\nS·ªë node ch·∫øt trung b√¨nh/chu k·ª≥ (khi c√≥ ch·∫øt): {np.mean(deaths_per_cycle):.2f}\")\n",
    "            print(f\"S·ªë node ch·∫øt nhi·ªÅu nh·∫•t trong 1 chu k·ª≥: {np.max(deaths_per_cycle)}\")\n",
    "        \n",
    "        print(f\"{'='*70}\")\n",
    "\n",
    "        # Save final results\n",
    "        meta_info.update({\n",
    "            'cycles': cycle - 1,\n",
    "            'total_operation_time': cumulative_time,\n",
    "            'first_death_cycle': first_death_cycle,\n",
    "            'first_death_time': first_death_time,\n",
    "            'final_alive_nodes': len(all_nodes),\n",
    "            'survival_rate': (len(all_nodes)/total_nodes)*100,\n",
    "            'outputs': outputs\n",
    "        })\n",
    "        \n",
    "        with open(out_filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(meta_info, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "        print(f\"\\n‚úì K·∫øt qu·∫£ cu·ªëi c√πng ƒë√£ l∆∞u: {out_filename}\")\n",
    "        \n",
    "        # Create final comprehensive chart\n",
    "        if outputs:\n",
    "            print(\"\\nüìä ƒêang t·∫°o bi·ªÉu ƒë·ªì t·ªïng h·ª£p cu·ªëi c√πng...\")\n",
    "            final_chart = plot_final_analysis(outputs, total_nodes, INITIAL_ENERGY, \n",
    "                                              filename, output_dir)\n",
    "            print(f\"‚úì ƒê√£ l∆∞u bi·ªÉu ƒë·ªì t·ªïng h·ª£p: {os.path.basename(final_chart)}\")\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"HO√ÄN TH√ÄNH X·ª¨ L√ù FILE: {filename}\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "\n",
    "\n",
    "def plot_final_analysis(outputs, total_nodes, INITIAL_ENERGY, filename, output_dir):\n",
    "    \"\"\"\n",
    "    V·∫Ω bi·ªÉu ƒë·ªì t·ªïng h·ª£p chi ti·∫øt cu·ªëi c√πng v·ªõi nhi·ªÅu th√¥ng tin h∆°n\n",
    "    \"\"\"\n",
    "    if len(outputs) == 0:\n",
    "        return None\n",
    "    \n",
    "    cycles = [o['cycle'] for o in outputs]\n",
    "    alive_nodes = [o['alive_nodes'] for o in outputs]\n",
    "    cumulative_dead = [total_nodes - a for a in alive_nodes]\n",
    "    total_energy_remaining = [o['total_energy_remaining'] for o in outputs]\n",
    "    travel_times = [o['best_time'] for o in outputs]\n",
    "    num_clusters = [o['num_clusters'] for o in outputs]\n",
    "    \n",
    "    # T√¨m chu k·ª≥ ƒë·∫ßu ti√™n c√≥ node ch·∫øt\n",
    "    first_death_cycle = None\n",
    "    for o in outputs:\n",
    "        if o['dead_nodes']:\n",
    "            first_death_cycle = o['cycle']\n",
    "            break\n",
    "    \n",
    "    # T·∫°o figure v·ªõi 6 subplots\n",
    "    fig = plt.figure(figsize=(20, 12))\n",
    "    gs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    fig.suptitle(f'Ph√¢n t√≠ch t·ªïng h·ª£p - {filename} ({len(outputs)} chu k·ª≥)', \n",
    "                 fontsize=18, fontweight='bold', y=0.995)\n",
    "    \n",
    "    # Bi·ªÉu ƒë·ªì 1: S·ªë node s·ªëng\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax1.plot(cycles, alive_nodes, 'b-o', linewidth=2, markersize=5)\n",
    "    ax1.axhline(y=total_nodes * 0.9, color='r', linestyle='--', \n",
    "                label=f'Ng∆∞·ª°ng 10% ({int(total_nodes * 0.1)} nodes)')\n",
    "    ax1.fill_between(cycles, 0, alive_nodes, alpha=0.3, color='blue')\n",
    "    ax1.set_xlabel('Chu k·ª≥', fontsize=11)\n",
    "    ax1.set_ylabel('S·ªë node s·ªëng', fontsize=11)\n",
    "    ax1.set_title('S·ªë node s·ªëng theo th·ªùi gian', fontsize=13, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.legend()\n",
    "    ax1.set_ylim(bottom=0, top=total_nodes * 1.1)\n",
    "    \n",
    "    # Bi·ªÉu ƒë·ªì 2: S·ªë node ch·∫øt t√≠ch l≈©y\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax2.plot(cycles, cumulative_dead, 'r-s', linewidth=2, markersize=5)\n",
    "    ax2.fill_between(cycles, 0, cumulative_dead, alpha=0.3, color='red')\n",
    "    ax2.set_xlabel('Chu k·ª≥', fontsize=11)\n",
    "    ax2.set_ylabel('S·ªë node ch·∫øt (t√≠ch l≈©y)', fontsize=11)\n",
    "    ax2.set_title('S·ªë node ch·∫øt t√≠ch l≈©y theo th·ªùi gian', fontsize=13, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_ylim(bottom=0)\n",
    "    \n",
    "    if first_death_cycle:\n",
    "        ax2.axvline(x=first_death_cycle, color='orange', linestyle='--', linewidth=2,\n",
    "                   label=f'Chu k·ª≥ ƒë·∫ßu ti√™n: {first_death_cycle}')\n",
    "        ax2.legend()\n",
    "    \n",
    "    # Bi·ªÉu ƒë·ªì 3: T·ªïng nƒÉng l∆∞·ª£ng m·∫°ng\n",
    "    ax3 = fig.add_subplot(gs[1, 0])\n",
    "    ax3.plot(cycles, total_energy_remaining, 'g-^', linewidth=2, markersize=5)\n",
    "    ax3.fill_between(cycles, 0, total_energy_remaining, alpha=0.3, color='green')\n",
    "    ax3.set_xlabel('Chu k·ª≥', fontsize=11)\n",
    "    ax3.set_ylabel('T·ªïng nƒÉng l∆∞·ª£ng c√≤n l·∫°i (J)', fontsize=11)\n",
    "    ax3.set_title('NƒÉng l∆∞·ª£ng t·ªïng th·ªÉ m·∫°ng', fontsize=13, fontweight='bold')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.set_ylim(bottom=0)\n",
    "    \n",
    "    # Bi·ªÉu ƒë·ªì 4: Th·ªùi gian di chuy·ªÉn AUV\n",
    "    ax4 = fig.add_subplot(gs[1, 1])\n",
    "    ax4.plot(cycles, travel_times, 'm-d', linewidth=2, markersize=5)\n",
    "    ax4.set_xlabel('Chu k·ª≥', fontsize=11)\n",
    "    ax4.set_ylabel('Th·ªùi gian di chuy·ªÉn (s)', fontsize=11)\n",
    "    ax4.set_title('Th·ªùi gian chu k·ª≥ AUV', fontsize=13, fontweight='bold')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    if len(travel_times) > 0:\n",
    "        avg_time = np.mean(travel_times)\n",
    "        ax4.axhline(y=avg_time, color='r', linestyle='--', linewidth=2,\n",
    "                   label=f'Trung b√¨nh: {avg_time:.2f}s')\n",
    "        ax4.legend()\n",
    "    \n",
    "    # Bi·ªÉu ƒë·ªì 5: S·ªë c·ª•m theo chu k·ª≥\n",
    "    ax5 = fig.add_subplot(gs[2, 0])\n",
    "    ax5.plot(cycles, num_clusters, 'c-o', linewidth=2, markersize=5)\n",
    "    ax5.fill_between(cycles, 0, num_clusters, alpha=0.3, color='cyan')\n",
    "    ax5.set_xlabel('Chu k·ª≥', fontsize=11)\n",
    "    ax5.set_ylabel('S·ªë c·ª•m', fontsize=11)\n",
    "    ax5.set_title('S·ªë c·ª•m theo chu k·ª≥', fontsize=13, fontweight='bold')\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    ax5.set_ylim(bottom=0)\n",
    "    \n",
    "    # Bi·ªÉu ƒë·ªì 6: Th·ªëng k√™ t·ªïng h·ª£p\n",
    "    ax6 = fig.add_subplot(gs[2, 1])\n",
    "    ax6.axis('off')\n",
    "    \n",
    "    # T√≠nh to√°n c√°c th·ªëng k√™\n",
    "    total_cycles = len(outputs)\n",
    "    total_time = outputs[-1]['cumulative_time']\n",
    "    avg_cycle_time = np.mean(travel_times)\n",
    "    total_deaths = total_nodes - alive_nodes[-1]\n",
    "    survival_rate = (alive_nodes[-1] / total_nodes) * 100\n",
    "    \n",
    "    stats_text = f\"\"\"\n",
    "    TH·ªêNG K√ä T·ªîNG H·ª¢P\n",
    "    {'‚îÄ' * 40}\n",
    "    \n",
    "    T·ªïng s·ªë chu k·ª≥: {total_cycles}\n",
    "    T·ªïng th·ªùi gian: {total_time:.2f}s ({total_time/3600:.2f} gi·ªù)\n",
    "    Th·ªùi gian TB/chu k·ª≥: {avg_cycle_time:.2f}s\n",
    "    \n",
    "    Node ban ƒë·∫ßu: {total_nodes}\n",
    "    Node c√≤n s·ªëng: {alive_nodes[-1]}\n",
    "    Node ƒë√£ ch·∫øt: {total_deaths}\n",
    "    T·ª∑ l·ªá s·ªëng s√≥t: {survival_rate:.2f}%\n",
    "    \n",
    "    Chu k·ª≥ ch·∫øt ƒë·∫ßu ti√™n: {first_death_cycle if first_death_cycle else 'N/A'}\n",
    "    \n",
    "    S·ªë c·ª•m trung b√¨nh: {np.mean(num_clusters):.1f}\n",
    "    S·ªë c·ª•m min/max: {np.min(num_clusters)}/{np.max(num_clusters)}\n",
    "    \n",
    "    Th·ªùi gian chu k·ª≥ min: {np.min(travel_times):.2f}s\n",
    "    Th·ªùi gian chu k·ª≥ max: {np.max(travel_times):.2f}s\n",
    "    ƒê·ªô l·ªách chu·∫©n: {np.std(travel_times):.2f}s\n",
    "    \"\"\"\n",
    "    \n",
    "    ax6.text(0.1, 0.5, stats_text, fontsize=11, family='monospace',\n",
    "             verticalalignment='center', bbox=dict(boxstyle='round', \n",
    "             facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    # L∆∞u bi·ªÉu ƒë·ªì t·ªïng h·ª£p\n",
    "    final_chart_filename = os.path.join(output_dir, \n",
    "                                        f\"final_analysis_{os.path.splitext(filename)[0]}.png\")\n",
    "    plt.savefig(final_chart_filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return final_chart_filename\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76c78a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# ==========================\n",
    "# H√ÄM T√çNH TO√ÅN T·ªêC ƒê·ªò & TH·ªúI GIAN\n",
    "# ==========================\n",
    "\n",
    "def compute_vs(p1, p2, v_f, v_AUV):\n",
    "    x1, y1, z1 = p1\n",
    "    x2, y2, z2 = p2\n",
    "    Lx, Ly, Lz = x2 - x1, y2 - y1, z2 - z1\n",
    "    L_mag = math.sqrt(Lx**2 + Ly**2 + Lz**2)\n",
    "    if L_mag == 0:\n",
    "        return v_AUV\n",
    "    cos_beta = Lz / L_mag\n",
    "    cos_beta = np.clip(cos_beta, -1, 1)\n",
    "    beta = math.acos(cos_beta)\n",
    "    inner = np.clip((v_f * cos_beta) / v_AUV, -1, 1)\n",
    "    angle = beta + math.acos(inner)\n",
    "    v_s = abs(math.cos(angle) * v_AUV / cos_beta)\n",
    "    return v_s\n",
    "\n",
    "\n",
    "def travel_time(path, coords, v_f, v_AUV):\n",
    "    total_time = 0.0\n",
    "    for i in range(len(path) - 1):\n",
    "        p1, p2 = coords[path[i]], coords[path[i + 1]]\n",
    "        d = np.linalg.norm(np.array(p2) - np.array(p1))\n",
    "        v_s = compute_vs(tuple(p1), tuple(p2), v_f, v_AUV)\n",
    "        total_time += d / max(v_s, 1e-9)\n",
    "    # quay l·∫°i ƒëi·ªÉm ƒë·∫ßu\n",
    "    p1, p2 = coords[path[-1]], coords[path[0]]\n",
    "    d = np.linalg.norm(np.array(p2) - np.array(p1))\n",
    "    v_s = compute_vs(tuple(p1), tuple(p2), v_f, v_AUV)\n",
    "    total_time += d / max(v_s, 1e-9)\n",
    "    return total_time\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# L·ªöP GA (ƒë√£ ch·ªânh ƒë·ªÉ map index -> cluster_head id)\n",
    "# ==========================\n",
    "\n",
    "class ClusterTSP_GA:\n",
    "    def __init__(self, clusters, ga_params=None):\n",
    "        self.clusters = clusters\n",
    "        sorted_keys = sorted(clusters.keys(), key=lambda x: int(x))\n",
    "        self.index_to_ch = [None]\n",
    "        self.cluster_centers = [(0.0, 0.0, 0.0)]\n",
    "        for k in sorted_keys:\n",
    "            c = clusters[k]['center']\n",
    "            self.cluster_centers.append(tuple(c))\n",
    "            self.index_to_ch.append(clusters[k].get('cluster_head', None))\n",
    "\n",
    "        self.n = len(self.cluster_centers)\n",
    "\n",
    "        defaults = {\n",
    "            'pop_size': 50,\n",
    "            'generations': 200,\n",
    "            'crossover_rate': 0.8,\n",
    "            'mutation_rate': 0.2,\n",
    "            'elitism_k': 3,\n",
    "            'tournament_size': 3,\n",
    "            'crossover_type': 'OX',\n",
    "            'mutation_type': 'inversion',\n",
    "            'local_search': True,\n",
    "            'v_f': 1.2,\n",
    "            'v_AUV': 3.0,\n",
    "            'verbose': False\n",
    "        }\n",
    "        if ga_params:\n",
    "            defaults.update(ga_params)\n",
    "        self.params = defaults\n",
    "        self.best_fitness_history = []\n",
    "\n",
    "    def create_individual(self):\n",
    "        seq = list(range(1, self.n))\n",
    "        random.shuffle(seq)\n",
    "        return [0] + seq\n",
    "\n",
    "    def create_population(self):\n",
    "        return [self.create_individual() for _ in range(self.params['pop_size'])]\n",
    "\n",
    "    def fitness(self, ind):\n",
    "        total_time = travel_time(ind, self.cluster_centers, self.params['v_f'], self.params['v_AUV'])\n",
    "        return 1.0 / (total_time + 1e-9)\n",
    "\n",
    "    def tournament_selection(self, population):\n",
    "        return max(random.sample(population, self.params['tournament_size']), key=self.fitness)\n",
    "\n",
    "    def order_crossover(self, p1, p2):\n",
    "        sub1, sub2 = p1[1:], p2[1:]\n",
    "        a, b = sorted(random.sample(range(len(sub1)), 2))\n",
    "        c1, c2 = [-1]*len(sub1), [-1]*len(sub1)\n",
    "        c1[a:b], c2[a:b] = sub1[a:b], sub2[a:b]\n",
    "        ptr = b\n",
    "        for x in sub2[b:]+sub2[:b]:\n",
    "            if x not in c1:\n",
    "                c1[ptr % len(sub1)] = x\n",
    "                ptr += 1\n",
    "        ptr = b\n",
    "        for x in sub1[b:]+sub1[:b]:\n",
    "            if x not in c2:\n",
    "                c2[ptr % len(sub2)] = x\n",
    "                ptr += 1\n",
    "        return [0]+c1, [0]+c2\n",
    "\n",
    "    def inversion_mutation(self, ind):\n",
    "        i, j = sorted(random.sample(range(1, len(ind)), 2))\n",
    "        ind[i:j+1] = list(reversed(ind[i:j+1]))\n",
    "        return ind\n",
    "\n",
    "    def evolve(self):\n",
    "        pop = self.create_population()\n",
    "        best = max(pop, key=self.fitness)\n",
    "        best_time = travel_time(best, self.cluster_centers, self.params['v_f'], self.params['v_AUV'])\n",
    "        for _ in range(self.params['generations']):\n",
    "            fitnesses = [self.fitness(ind) for ind in pop]\n",
    "            best_gen = pop[np.argmax(fitnesses)]\n",
    "            gen_best_time = travel_time(best_gen, self.cluster_centers, self.params['v_f'], self.params['v_AUV'])\n",
    "            if gen_best_time < best_time:\n",
    "                best, best_time = best_gen.copy(), gen_best_time\n",
    "            elite_idx = np.argsort(fitnesses)[-self.params['elitism_k']:]\n",
    "            new_pop = [pop[i].copy() for i in elite_idx]\n",
    "            while len(new_pop) < self.params['pop_size']:\n",
    "                p1, p2 = self.tournament_selection(pop), self.tournament_selection(pop)\n",
    "                c1, c2 = self.order_crossover(p1, p2) if random.random() < self.params['crossover_rate'] else (p1.copy(), p2.copy())\n",
    "                if random.random() < self.params['mutation_rate']:\n",
    "                    c1 = self.inversion_mutation(c1)\n",
    "                if random.random() < self.params['mutation_rate']:\n",
    "                    c2 = self.inversion_mutation(c2)\n",
    "                new_pop += [c1, c2]\n",
    "            pop = new_pop[:self.params['pop_size']]\n",
    "        mapped_path = ['O' if idx == 0 else self.index_to_ch[idx] for idx in best]\n",
    "        return best, mapped_path, best_time\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# H√ÄM NƒÇNG L∆Ø·ª¢NG\n",
    "# ==========================\n",
    "\n",
    "def compute_energy(best_time):\n",
    "    G, L, n = 100, 1024, 4\n",
    "    P_t, P_r, P_idle, DR, DR_i = 1.6e-3, 0.8e-3, 0.1e-3, 4000, 1e6\n",
    "    E_tx_MN = G * P_t * L / DR\n",
    "    E_idle_MN = (best_time - G * L / DR) * P_idle\n",
    "    E_total_MN = E_tx_MN + E_idle_MN\n",
    "    E_rx_TN = G * P_r * L * n / DR\n",
    "    E_tx_TN = G * P_t * L * n / DR_i\n",
    "    E_idle_TN = (best_time - (G * L * n / DR) - (G * L * n / DR_i)) * P_idle\n",
    "    E_total_TN = E_rx_TN + E_tx_TN + E_idle_TN\n",
    "    E_idle_solo = (best_time - (G * L * n / DR_i)) * P_idle\n",
    "    E_total_SOLO = E_tx_TN + E_idle_solo\n",
    "    return {\n",
    "        \"Member\": {\"E_tx\": E_tx_MN, \"E_idle\": E_idle_MN, \"E_total\": E_total_MN},\n",
    "        \"Target\": {\"E_rx\": E_rx_TN, \"E_tx\": E_tx_TN, \"E_idle\": E_idle_TN, \"E_total\": E_total_TN},\n",
    "        \"Solo\": {\"E_tx\": E_tx_TN, \"E_idle\": E_idle_solo, \"E_total\": E_total_SOLO}\n",
    "    }\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# H√ÄM PH√ÇN C·ª§M\n",
    "# ==========================\n",
    "\n",
    "def calculate_objective_function(nodes, labels, centers):\n",
    "    numerator = 0\n",
    "    for i in range(2):\n",
    "        cluster_nodes = nodes[labels == i]\n",
    "        if len(cluster_nodes) > 0:\n",
    "            distances = np.linalg.norm(cluster_nodes - centers[i], axis=1)\n",
    "            numerator += np.sum(distances)\n",
    "    denominator = np.linalg.norm(centers[0] - centers[1])\n",
    "    if denominator == 0:\n",
    "        return float('inf')\n",
    "    return numerator / denominator\n",
    "\n",
    "\n",
    "def check_subgroup_threshold(nodes, r_sen):\n",
    "    if len(nodes) <= 1:\n",
    "        return True\n",
    "    max_distance = 0\n",
    "    for i in range(len(nodes)):\n",
    "        for j in range(i + 1, len(nodes)):\n",
    "            dist = np.linalg.norm(nodes[i] - nodes[j])\n",
    "            max_distance = max(max_distance, dist)\n",
    "    return max_distance <= r_sen\n",
    "\n",
    "\n",
    "def kmeans_with_best_T(nodes, N=30):\n",
    "    best_T = float('inf')\n",
    "    best_labels = None\n",
    "    best_centers = None\n",
    "    for _ in range(N):\n",
    "        kmeans = KMeans(n_clusters=2, n_init=1)\n",
    "        labels = kmeans.fit_predict(nodes)\n",
    "        centers = kmeans.cluster_centers_\n",
    "        T = calculate_objective_function(nodes, labels, centers)\n",
    "        if T < best_T:\n",
    "            best_T = T\n",
    "            best_labels = labels.copy()\n",
    "            best_centers = centers.copy()\n",
    "    return best_labels, best_centers, best_T\n",
    "\n",
    "\n",
    "def cluster_split(nodes, node_ids, node_data=None, r_sen=60, R=20, N=30, max_depth=10, depth=0):\n",
    "    size_ok = len(nodes) <= R\n",
    "    distance_ok = check_subgroup_threshold(nodes, r_sen)\n",
    "    \n",
    "    if (size_ok and distance_ok) or depth >= max_depth:\n",
    "        center = np.mean(nodes, axis=0)\n",
    "        return [{\n",
    "            \"node_ids\": node_ids,\n",
    "            \"nodes\": nodes,\n",
    "            \"center\": center,\n",
    "            \"node_data\": node_data if node_data else {}\n",
    "        }]\n",
    "    \n",
    "    labels, centers, best_T = kmeans_with_best_T(nodes, N)\n",
    "    clusters = []\n",
    "    for i in range(2):\n",
    "        sub_nodes = nodes[labels == i]\n",
    "        sub_ids = [node_ids[j] for j in range(len(node_ids)) if labels[j] == i]\n",
    "        sub_node_data = {}\n",
    "        if node_data:\n",
    "            for node_id in sub_ids:\n",
    "                if node_id in node_data:\n",
    "                    sub_node_data[node_id] = node_data[node_id]\n",
    "        clusters += cluster_split(sub_nodes, sub_ids, sub_node_data, r_sen, R, N, max_depth, depth + 1)\n",
    "    return clusters\n",
    "\n",
    "\n",
    "def choose_cluster_head(cluster_info, node_data=None):\n",
    "    nodes = cluster_info[\"nodes\"]\n",
    "    center = cluster_info[\"center\"]\n",
    "    node_ids = cluster_info[\"node_ids\"]\n",
    "    \n",
    "    if node_data and len(node_data) > 0:\n",
    "        max_energy = -1\n",
    "        ch_id = node_ids[0]\n",
    "        for nid in node_ids:\n",
    "            if nid in node_data and \"residual_energy\" in node_data[nid]:\n",
    "                if node_data[nid][\"residual_energy\"] > max_energy:\n",
    "                    max_energy = node_data[nid][\"residual_energy\"]\n",
    "                    ch_id = nid\n",
    "        return ch_id\n",
    "    else:\n",
    "        distances = np.linalg.norm(nodes - center, axis=1)\n",
    "        min_idx = np.argmin(distances)\n",
    "        return node_ids[min_idx]\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# H√ÄM QU·∫¢N L√ù NƒÇNG L∆Ø·ª¢NG\n",
    "# ==========================\n",
    "\n",
    "def update_energy(all_nodes, clusters, energy_report):\n",
    "    for cid, cinfo in clusters.items():\n",
    "        nodes = cinfo.get('nodes', [])\n",
    "        ch = cinfo.get('cluster_head')\n",
    "        \n",
    "        if len(nodes) == 1:\n",
    "            nid = nodes[0]\n",
    "            if nid in all_nodes:\n",
    "                all_nodes[nid]['residual_energy'] -= energy_report['Solo']['E_total']\n",
    "                if all_nodes[nid]['residual_energy'] < 0:\n",
    "                    all_nodes[nid]['residual_energy'] = 0.0\n",
    "        else:\n",
    "            for nid in nodes:\n",
    "                if nid not in all_nodes:\n",
    "                    continue\n",
    "                if nid == ch:\n",
    "                    all_nodes[nid]['residual_energy'] -= energy_report['Target']['E_total']\n",
    "                else:\n",
    "                    all_nodes[nid]['residual_energy'] -= energy_report['Member']['E_total']\n",
    "                if all_nodes[nid]['residual_energy'] < 0:\n",
    "                    all_nodes[nid]['residual_energy'] = 0.0\n",
    "\n",
    "\n",
    "def remove_dead_nodes(all_nodes, clusters):\n",
    "    dead = [nid for nid, info in list(all_nodes.items()) if info['residual_energy'] <= 0]\n",
    "    for nid in dead:\n",
    "        del all_nodes[nid]\n",
    "    new_clusters = {}\n",
    "    for cid, cinfo in clusters.items():\n",
    "        alive_nodes = [nid for nid in cinfo.get('nodes', []) if nid in all_nodes]\n",
    "        if alive_nodes:\n",
    "            new_c = dict(cinfo)\n",
    "            new_c['nodes'] = alive_nodes\n",
    "            new_clusters[cid] = new_c\n",
    "    return new_clusters, dead\n",
    "\n",
    "\n",
    "def recluster(all_nodes, node_positions, r_sen=50, R=20):\n",
    "    \"\"\"Th·ª±c hi·ªán ph√¢n c·ª•m l·∫°i to√†n b·ªô m·∫°ng\"\"\"\n",
    "    ids = sorted(list(all_nodes.keys()))\n",
    "    if len(ids) == 0:\n",
    "        return {}\n",
    "    coords = np.array([node_positions[nid] for nid in ids])\n",
    "    raw_clusters = cluster_split(coords, ids, all_nodes, r_sen=r_sen, R=R)\n",
    "    clusters = {}\n",
    "    for i, c in enumerate(raw_clusters):\n",
    "        center = c['center'].tolist()\n",
    "        node_ids = c['node_ids']\n",
    "        ch = choose_cluster_head(c, all_nodes)\n",
    "        clusters[i] = {'nodes': node_ids, 'center': center, 'cluster_head': ch}\n",
    "    return clusters\n",
    "\n",
    "\n",
    "def update_cluster_heads_only(clusters, all_nodes, node_positions):\n",
    "    \"\"\"\n",
    "    Ch·ªâ c·∫≠p nh·∫≠t cluster head cho c√°c c·ª•m hi·ªán c√≥\n",
    "    (kh√¥ng thay ƒë·ªïi c·∫•u tr√∫c c·ª•m)\n",
    "    \"\"\"\n",
    "    for cid, cinfo in clusters.items():\n",
    "        node_ids = cinfo['nodes']\n",
    "        center = np.array(cinfo['center'])\n",
    "        \n",
    "        # T·∫°o cluster_info ƒë·ªÉ s·ª≠ d·ª•ng h√†m choose_cluster_head\n",
    "        cluster_info = {\n",
    "            'nodes': np.array([node_positions[nid] for nid in node_ids]),\n",
    "            'center': center,\n",
    "            'node_ids': node_ids,\n",
    "            'node_data': {nid: all_nodes[nid] for nid in node_ids if nid in all_nodes}\n",
    "        }\n",
    "        \n",
    "        # Ch·ªçn cluster head m·ªõi d·ª±a tr√™n nƒÉng l∆∞·ª£ng\n",
    "        new_ch = choose_cluster_head(cluster_info, all_nodes)\n",
    "        clusters[cid]['cluster_head'] = new_ch\n",
    "    \n",
    "    return clusters\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# H√ÄM V·∫º BI·ªÇU ƒê·ªí REAL-TIME\n",
    "# ==========================\n",
    "\n",
    "def plot_realtime_analysis(outputs, total_nodes, INITIAL_ENERGY, filename, output_dir, cycle):\n",
    "    \"\"\"\n",
    "    V·∫Ω bi·ªÉu ƒë·ªì theo th·ªùi gian th·ª±c sau m·ªói chu k·ª≥\n",
    "    \"\"\"\n",
    "    if len(outputs) == 0:\n",
    "        return\n",
    "    \n",
    "    cycles = [o['cycle'] for o in outputs]\n",
    "    alive_nodes = [o['alive_nodes'] for o in outputs]\n",
    "    cumulative_dead = [total_nodes - a for a in alive_nodes]\n",
    "    total_energy_remaining = [o['total_energy_remaining'] for o in outputs]\n",
    "    travel_times = [o['best_time'] for o in outputs]\n",
    "    \n",
    "    # T√¨m chu k·ª≥ ƒë·∫ßu ti√™n c√≥ node ch·∫øt\n",
    "    first_death_cycle = None\n",
    "    for o in outputs:\n",
    "        if o['dead_nodes']:\n",
    "            first_death_cycle = o['cycle']\n",
    "            break\n",
    "    \n",
    "    # T·∫°o figure\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle(f'Real-time Monitoring - {filename} (Chu k·ª≥ {cycle})', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Bi·ªÉu ƒë·ªì 1: S·ªë node s·ªëng\n",
    "    axes[0, 0].plot(cycles, alive_nodes, 'b-o', linewidth=2, markersize=6)\n",
    "    axes[0, 0].axhline(y=total_nodes * 0.9, color='r', linestyle='--', \n",
    "                       label=f'Ng∆∞·ª°ng 10% ({int(total_nodes * 0.1)} nodes)')\n",
    "    axes[0, 0].set_xlabel('Chu k·ª≥', fontsize=12)\n",
    "    axes[0, 0].set_ylabel('S·ªë node s·ªëng', fontsize=12)\n",
    "    axes[0, 0].set_title('S·ªë node s·ªëng theo th·ªùi gian', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].set_ylim(bottom=0, top=total_nodes * 1.1)\n",
    "    \n",
    "    # Bi·ªÉu ƒë·ªì 2: S·ªë node ch·∫øt t√≠ch l≈©y\n",
    "    axes[0, 1].plot(cycles, cumulative_dead, 'r-s', linewidth=2, markersize=6)\n",
    "    axes[0, 1].set_xlabel('Chu k·ª≥', fontsize=12)\n",
    "    axes[0, 1].set_ylabel('S·ªë node ch·∫øt (t√≠ch l≈©y)', fontsize=12)\n",
    "    axes[0, 1].set_title('S·ªë node ch·∫øt t√≠ch l≈©y theo th·ªùi gian', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    axes[0, 1].set_ylim(bottom=0)\n",
    "    \n",
    "    if first_death_cycle:\n",
    "        axes[0, 1].axvline(x=first_death_cycle, color='orange', linestyle='--', \n",
    "                          label=f'Chu k·ª≥ ƒë·∫ßu ti√™n: {first_death_cycle}')\n",
    "        axes[0, 1].legend()\n",
    "    \n",
    "    # Bi·ªÉu ƒë·ªì 3: T·ªïng nƒÉng l∆∞·ª£ng m·∫°ng\n",
    "    axes[1, 0].plot(cycles, total_energy_remaining, 'g-^', linewidth=2, markersize=6)\n",
    "    axes[1, 0].set_xlabel('Chu k·ª≥', fontsize=12)\n",
    "    axes[1, 0].set_ylabel('T·ªïng nƒÉng l∆∞·ª£ng c√≤n l·∫°i (J)', fontsize=12)\n",
    "    axes[1, 0].set_title('NƒÉng l∆∞·ª£ng t·ªïng th·ªÉ m·∫°ng', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    axes[1, 0].set_ylim(bottom=0)\n",
    "    \n",
    "    # Bi·ªÉu ƒë·ªì 4: Th·ªùi gian di chuy·ªÉn AUV\n",
    "    axes[1, 1].plot(cycles, travel_times, 'm-d', linewidth=2, markersize=6)\n",
    "    axes[1, 1].set_xlabel('Chu k·ª≥', fontsize=12)\n",
    "    axes[1, 1].set_ylabel('Th·ªùi gian di chuy·ªÉn (s)', fontsize=12)\n",
    "    axes[1, 1].set_title('Th·ªùi gian chu k·ª≥ AUV', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    if len(travel_times) > 0:\n",
    "        avg_time = np.mean(travel_times)\n",
    "        axes[1, 1].axhline(y=avg_time, color='r', linestyle='--', \n",
    "                          label=f'TB: {avg_time:.2f}s')\n",
    "        axes[1, 1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # L∆∞u b·∫£n \"latest\" ƒë·ªÉ d·ªÖ theo d√µi\n",
    "    latest_filename = os.path.join(output_dir, \n",
    "                                   f\"realtime_latest_{os.path.splitext(filename)[0]}.png\")\n",
    "    plt.savefig(latest_filename, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def save_realtime_results(outputs, meta_info, output_file):\n",
    "    \"\"\"\n",
    "    L∆∞u k·∫øt qu·∫£ theo th·ªùi gian th·ª±c\n",
    "    \"\"\"\n",
    "    meta_info['outputs'] = outputs\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(meta_info, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# MAIN v·ªõi Real-time Monitoring\n",
    "# ==========================\n",
    "\n",
    "def main():\n",
    "    input_dir = \"D:/Year 4/ti·∫øn h√≥a/project/data/output_data_kmeans\"\n",
    "    output_dir = \"D:/Year 4/ti·∫øn h√≥a/project/data/output_path/output_ga_multicycle\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    files = [f for f in os.listdir(input_dir) if f.endswith('.json')]\n",
    "\n",
    "    ga_params = {\n",
    "        'pop_size': 40,\n",
    "        'generations': 200,\n",
    "        'crossover_rate': 0.8,\n",
    "        'mutation_rate': 0.2,\n",
    "        'elitism_k': 3,\n",
    "        'local_search': True,\n",
    "        'v_f': 1.2,\n",
    "        'v_AUV': 3.0,\n",
    "        'verbose': False\n",
    "    }\n",
    "\n",
    "    INITIAL_ENERGY = 100.0\n",
    "\n",
    "    for filename in files:\n",
    "        input_path = os.path.join(input_dir, filename)\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"ƒêANG X·ª¨ L√ù FILE: {filename}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        with open(input_path, 'r') as f:\n",
    "            clusters_in = json.load(f)\n",
    "\n",
    "        node_positions = {}\n",
    "        all_nodes = {}\n",
    "\n",
    "        # Collect all node ids\n",
    "        all_node_ids = set()\n",
    "        for k, v in clusters_in.items():\n",
    "            for nid in v.get('nodes', []):\n",
    "                all_node_ids.add(nid)\n",
    "            ch = v.get('cluster_head')\n",
    "            if ch is not None:\n",
    "                all_node_ids.add(ch)\n",
    "\n",
    "        # Load node positions\n",
    "        nodes_pos_file = \"D:/Year 4/ti·∫øn h√≥a/project/data/input_data_evenly_distributed/nodes_20.json\"\n",
    "        if os.path.exists(nodes_pos_file):\n",
    "            try:\n",
    "                with open(nodes_pos_file, 'r', encoding='utf-8') as f:\n",
    "                    nodes_data = json.load(f)\n",
    "                \n",
    "                node_positions = {}\n",
    "                for node in nodes_data:\n",
    "                    node_id = node['id']\n",
    "                    node_positions[node_id] = (node['x'], node['y'], node['z'])\n",
    "                \n",
    "                print(f\"‚úì ƒê√£ load {len(node_positions)} node positions t·ª´ {os.path.basename(nodes_pos_file)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚úó L·ªói khi ƒë·ªçc file v·ªã tr√≠: {e}\")\n",
    "\n",
    "        # Create approximate positions if needed\n",
    "        if not node_positions:\n",
    "            for k, v in clusters_in.items():\n",
    "                center = tuple(v.get('center', (0.0, 0.0, 0.0)))\n",
    "                for nid in v.get('nodes', []):\n",
    "                    offset = np.random.normal(scale=5.0, size=3)\n",
    "                    node_positions[nid] = tuple(np.array(center) + offset)\n",
    "                ch = v.get('cluster_head')\n",
    "                if ch is not None and ch not in node_positions:\n",
    "                    node_positions[ch] = center\n",
    "            print(\"‚ö† ƒê√£ t·∫°o v·ªã tr√≠ gi·∫£ l·∫≠p cho c√°c nodes\")\n",
    "\n",
    "        # Initialize energy\n",
    "        for nid in list(all_node_ids):\n",
    "            all_nodes[nid] = {\n",
    "                'initial_energy': INITIAL_ENERGY, \n",
    "                'residual_energy': INITIAL_ENERGY\n",
    "            }\n",
    "\n",
    "        total_nodes = len(all_nodes)\n",
    "        print(f\"‚úì T·ªïng s·ªë node ban ƒë·∫ßu: {total_nodes}\")\n",
    "\n",
    "        # Initialize clusters\n",
    "        clusters = {}\n",
    "        for k, v in clusters_in.items():\n",
    "            clusters[int(k)] = {\n",
    "                'nodes': v.get('nodes', []), \n",
    "                'center': v.get('center', []), \n",
    "                'cluster_head': v.get('cluster_head')\n",
    "            }\n",
    "\n",
    "        # Prepare output file\n",
    "        out_filename = os.path.join(output_dir, \n",
    "                                    f\"multicycle_result_{os.path.splitext(filename)[0]}.json\")\n",
    "        \n",
    "        # Meta info\n",
    "        meta_info = {\n",
    "            'input_file': filename,\n",
    "            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'initial_total_nodes': total_nodes,\n",
    "            'cycles': 0,\n",
    "            'reclustering_count': 0,\n",
    "            'total_operation_time': 0.0,\n",
    "            'first_death_cycle': None,\n",
    "            'first_death_time': None,\n",
    "            'final_alive_nodes': 0,\n",
    "            'survival_rate': 0.0\n",
    "        }\n",
    "\n",
    "        cycle = 0\n",
    "        outputs = []\n",
    "        cumulative_time = 0.0\n",
    "        first_death_cycle = None\n",
    "        first_death_time = None\n",
    "        reclustering_count = 0\n",
    "\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"B·∫ÆT ƒê·∫¶U M√î PH·ªéNG CHU K·ª≤\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "\n",
    "        # Main simulation loop\n",
    "        while True:\n",
    "            cycle += 1\n",
    "            print(f\"\\n{'‚îÄ'*70}\")\n",
    "            print(f\"CHU K·ª≤ {cycle}\")\n",
    "            print(f\"{'‚îÄ'*70}\")\n",
    "\n",
    "            alive_ratio = len(all_nodes) / total_nodes if total_nodes > 0 else 0\n",
    "            print(f\"T·ªâ l·ªá node s·ªëng: {alive_ratio*100:.2f}% ({len(all_nodes)}/{total_nodes})\")\n",
    "            \n",
    "            if alive_ratio < 0.1:\n",
    "                print(\"\\n‚ö† D·ª™NG: T·ªâ l·ªá node s·ªëng < 10%\")\n",
    "                break\n",
    "\n",
    "            if len(clusters) == 0:\n",
    "                print(\"\\n‚ö† D·ª™NG: Kh√¥ng c√≤n c·ª•m n√†o\")\n",
    "                break\n",
    "\n",
    "            # Run GA\n",
    "            print(f\"ƒêang ch·∫°y GA v·ªõi {len(clusters)} c·ª•m...\", end=\" \")\n",
    "            ga = ClusterTSP_GA(clusters, ga_params)\n",
    "            best_indices, best_mapped_path, best_time = ga.evolve()\n",
    "            print(\"‚úì\")\n",
    "\n",
    "            cumulative_time += best_time\n",
    "            energy_report = compute_energy(best_time)\n",
    "\n",
    "            # Update energies\n",
    "            update_energy(all_nodes, clusters, energy_report)\n",
    "\n",
    "            # Remove dead nodes\n",
    "            clusters, dead_nodes = remove_dead_nodes(all_nodes, clusters)\n",
    "            \n",
    "            # ===== ƒêI·ªÇM THAY ƒê·ªîI CH√çNH =====\n",
    "            # Quy·∫øt ƒë·ªãnh c√≥ ph√¢n c·ª•m l·∫°i hay ch·ªâ c·∫≠p nh·∫≠t cluster head\n",
    "            if dead_nodes:\n",
    "                # C√≥ node ch·∫øt -> ph√¢n c·ª•m l·∫°i to√†n b·ªô\n",
    "                print(f\"‚ö† Ph√°t hi·ªán {len(dead_nodes)} node ch·∫øt -> Th·ª±c hi·ªán PH√ÇN C·ª§M L·∫†I\")\n",
    "                reclustering_count += 1\n",
    "                \n",
    "                # X√≥a v·ªã tr√≠ c·ªßa c√°c node ƒë√£ ch·∫øt\n",
    "                for d in dead_nodes:\n",
    "                    if d in node_positions:\n",
    "                        del node_positions[d]\n",
    "                \n",
    "                # Ph√¢n c·ª•m l·∫°i to√†n b·ªô m·∫°ng\n",
    "                if len(all_nodes) > 0:\n",
    "                    clusters = recluster(all_nodes, node_positions)\n",
    "                    for k, v in clusters.items():\n",
    "                        clusters[k]['center'] = [float(x) for x in v['center']]\n",
    "                    print(f\"  ‚Üí ƒê√£ ph√¢n c·ª•m l·∫°i: {len(clusters)} c·ª•m m·ªõi\")\n",
    "            else:\n",
    "                # Kh√¥ng c√≥ node ch·∫øt -> ch·ªâ c·∫≠p nh·∫≠t cluster head\n",
    "                print(\"‚úì Kh√¥ng c√≥ node ch·∫øt -> Ch·ªâ C·∫¨P NH·∫¨T CLUSTER HEAD\")\n",
    "                clusters = update_cluster_heads_only(clusters, all_nodes, node_positions)\n",
    "                print(f\"  ‚Üí ƒê√£ c·∫≠p nh·∫≠t cluster head cho {len(clusters)} c·ª•m\")\n",
    "\n",
    "            # Calculate total energy\n",
    "            total_energy_remaining = sum(node['residual_energy'] for node in all_nodes.values())\n",
    "\n",
    "            # Track first death\n",
    "            if dead_nodes and first_death_cycle is None:\n",
    "                first_death_cycle = cycle\n",
    "                first_death_time = cumulative_time\n",
    "\n",
    "            # Log output\n",
    "            output_entry = {\n",
    "                'cycle': cycle,\n",
    "                'num_clusters': len(clusters),\n",
    "                'best_path_indices': best_indices,\n",
    "                'best_path_node_ids': best_mapped_path,\n",
    "                'best_time': best_time,\n",
    "                'cumulative_time': cumulative_time,\n",
    "                'dead_nodes': dead_nodes,\n",
    "                'alive_nodes': len(all_nodes),\n",
    "                'total_energy_remaining': total_energy_remaining,\n",
    "                'reclustered': bool(dead_nodes)\n",
    "            }\n",
    "            outputs.append(output_entry)\n",
    "\n",
    "            # Print cycle summary\n",
    "            print(f\"‚îú‚îÄ S·ªë c·ª•m: {len(clusters)}\")\n",
    "            print(f\"‚îú‚îÄ ƒê∆∞·ªùng ƒëi: {best_mapped_path}\")\n",
    "            print(f\"‚îú‚îÄ Th·ªùi gian chu k·ª≥: {best_time:.2f}s\")\n",
    "            print(f\"‚îú‚îÄ Th·ªùi gian t√≠ch l≈©y: {cumulative_time:.2f}s ({cumulative_time/3600:.2f}h)\")\n",
    "            print(f\"‚îú‚îÄ NƒÉng l∆∞·ª£ng c√≤n l·∫°i: {total_energy_remaining:.2f}J\")\n",
    "            \n",
    "            if dead_nodes:\n",
    "                print(f\"‚îî‚îÄ ‚ö† Node ch·∫øt: {len(dead_nodes)} node(s) - {dead_nodes}\")\n",
    "            else:\n",
    "                print(f\"‚îî‚îÄ ‚úì Kh√¥ng c√≥ node ch·∫øt\")\n",
    "\n",
    "            # ===== REAL-TIME UPDATES =====\n",
    "            \n",
    "            # 1. Save results to file\n",
    "            meta_info.update({\n",
    "                'cycles': cycle,\n",
    "                'reclustering_count': reclustering_count,\n",
    "                'total_operation_time': cumulative_time,\n",
    "                'first_death_cycle': first_death_cycle,\n",
    "                'first_death_time': first_death_time,\n",
    "                'final_alive_nodes': len(all_nodes),\n",
    "                'survival_rate': (len(all_nodes)/total_nodes)*100\n",
    "            })\n",
    "            save_realtime_results(outputs, meta_info, out_filename)\n",
    "            \n",
    "            # 2. Plot real-time chart\n",
    "            plot_realtime_analysis(\n",
    "                outputs, total_nodes, INITIAL_ENERGY, filename, output_dir, cycle\n",
    "            )\n",
    "\n",
    "        # ===== K·∫æT TH√öC M√î PH·ªéNG =====\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"PH√ÇN T√çCH K·∫æT QU·∫¢ CU·ªêI C√ôNG\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"T·ªïng s·ªë chu k·ª≥: {cycle - 1}\")\n",
    "        print(f\"S·ªë l·∫ßn ph√¢n c·ª•m l·∫°i: {reclustering_count}\")\n",
    "        print(f\"T·ªïng th·ªùi gian ho·∫°t ƒë·ªông: {cumulative_time:.2f}s ({cumulative_time/3600:.2f} gi·ªù)\")\n",
    "        \n",
    "        if first_death_cycle:\n",
    "            print(f\"\\nChu k·ª≥ ƒë·∫ßu ti√™n c√≥ node ch·∫øt: {first_death_cycle}\")\n",
    "            print(f\"Th·ªùi gian ƒë·∫øn l√∫c ch·∫øt ƒë·∫ßu ti√™n: {first_death_time:.2f}s ({first_death_time/3600:.2f} gi·ªù)\")\n",
    "            print(f\"T·ª∑ l·ªá th·ªùi gian: {(first_death_time/cumulative_time)*100:.2f}% t·ªïng th·ªùi gian\")\n",
    "        else:\n",
    "            print(\"\\nKh√¥ng c√≥ node n√†o ch·∫øt trong qu√° tr√¨nh m√¥ ph·ªèng\")\n",
    "        \n",
    "        print(f\"\\nS·ªë node c√≤n s·ªëng cu·ªëi c√πng: {len(all_nodes)}/{total_nodes}\")\n",
    "        print(f\"S·ªë node ƒë√£ ch·∫øt: {total_nodes - len(all_nodes)}\")\n",
    "        print(f\"T·ª∑ l·ªá s·ªëng s√≥t: {(len(all_nodes)/total_nodes)*100:.2f}%\")\n",
    "        \n",
    "        # Th·ªëng k√™ v·ªÅ th·ªùi gian chu k·ª≥\n",
    "        if outputs:\n",
    "            cycle_times = [o['best_time'] for o in outputs]\n",
    "            print(f\"\\nTh·ªùi gian chu k·ª≥ trung b√¨nh: {np.mean(cycle_times):.2f}s\")\n",
    "            print(f\"Th·ªùi gian chu k·ª≥ ng·∫Øn nh·∫•t: {np.min(cycle_times):.2f}s\")\n",
    "            print(f\"Th·ªùi gian chu k·ª≥ d√†i nh·∫•t: {np.max(cycle_times):.2f}s\")\n",
    "            print(f\"ƒê·ªô l·ªách chu·∫©n: {np.std(cycle_times):.2f}s\")\n",
    "        \n",
    "        # Th·ªëng k√™ v·ªÅ s·ªë node ch·∫øt m·ªói chu k·ª≥\n",
    "        deaths_per_cycle = [len(o['dead_nodes']) for o in outputs if o['dead_nodes']]\n",
    "        if deaths_per_cycle:\n",
    "            print(f\"\\nS·ªë node ch·∫øt trung b√¨nh/chu k·ª≥ (khi c√≥ ch·∫øt): {np.mean(deaths_per_cycle):.2f}\")\n",
    "            print(f\"S·ªë node ch·∫øt nhi·ªÅu nh·∫•t trong 1 chu k·ª≥: {np.max(deaths_per_cycle)}\")\n",
    "        \n",
    "        # Th·ªëng k√™ v·ªÅ ph√¢n c·ª•m\n",
    "        print(f\"\\nT·ª∑ l·ªá ph√¢n c·ª•m l·∫°i: {(reclustering_count/(cycle-1))*100:.2f}% ({reclustering_count}/{cycle-1} chu k·ª≥)\")\n",
    "        \n",
    "        print(f\"{'='*70}\")\n",
    "\n",
    "        # Save final results\n",
    "        meta_info.update({\n",
    "            'cycles': cycle - 1,\n",
    "            'reclustering_count': reclustering_count,\n",
    "            'total_operation_time': cumulative_time,\n",
    "            'first_death_cycle': first_death_cycle,\n",
    "            'first_death_time': first_death_time,\n",
    "            'final_alive_nodes': len(all_nodes),\n",
    "            'survival_rate': (len(all_nodes)/total_nodes)*100,\n",
    "            'outputs': outputs\n",
    "        })\n",
    "        \n",
    "        with open(out_filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(meta_info, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "        print(f\"\\n‚úì K·∫øt qu·∫£ cu·ªëi c√πng ƒë√£ l∆∞u: {out_filename}\")\n",
    "        \n",
    "        # Create final comprehensive chart\n",
    "        if outputs:\n",
    "            print(\"\\nüìä ƒêang t·∫°o bi·ªÉu ƒë·ªì t·ªïng h·ª£p cu·ªëi c√πng...\")\n",
    "            final_chart = plot_final_analysis(outputs, total_nodes, INITIAL_ENERGY, \n",
    "                                              filename, output_dir)\n",
    "            print(f\"‚úì ƒê√£ l∆∞u bi·ªÉu ƒë·ªì t·ªïng h·ª£p: {os.path.basename(final_chart)}\")\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"HO√ÄN TH√ÄNH X·ª¨ L√ù FILE: {filename}\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "\n",
    "\n",
    "def plot_final_analysis(outputs, total_nodes, INITIAL_ENERGY, filename, output_dir):\n",
    "    \"\"\"\n",
    "    V·∫Ω bi·ªÉu ƒë·ªì t·ªïng h·ª£p chi ti·∫øt cu·ªëi c√πng v·ªõi nhi·ªÅu th√¥ng tin h∆°n\n",
    "    \"\"\"\n",
    "    if len(outputs) == 0:\n",
    "        return None\n",
    "    \n",
    "    cycles = [o['cycle'] for o in outputs]\n",
    "    alive_nodes = [o['alive_nodes'] for o in outputs]\n",
    "    cumulative_dead = [total_nodes - a for a in alive_nodes]\n",
    "    total_energy_remaining = [o['total_energy_remaining'] for o in outputs]\n",
    "    travel_times = [o['best_time'] for o in outputs]\n",
    "    num_clusters = [o['num_clusters'] for o in outputs]\n",
    "    reclustered_cycles = [o['cycle'] for o in outputs if o.get('reclustered', False)]\n",
    "    \n",
    "    # T√¨m chu k·ª≥ ƒë·∫ßu ti√™n c√≥ node ch·∫øt\n",
    "    first_death_cycle = None\n",
    "    for o in outputs:\n",
    "        if o['dead_nodes']:\n",
    "            first_death_cycle = o['cycle']\n",
    "            break\n",
    "    \n",
    "    # T·∫°o figure v·ªõi 6 subplots\n",
    "    fig = plt.figure(figsize=(20, 12))\n",
    "    gs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    fig.suptitle(f'Ph√¢n t√≠ch t·ªïng h·ª£p - {filename} ({len(outputs)} chu k·ª≥)', \n",
    "                 fontsize=18, fontweight='bold', y=0.995)\n",
    "    \n",
    "    # Bi·ªÉu ƒë·ªì 1: S·ªë node s·ªëng\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax1.plot(cycles, alive_nodes, 'b-o', linewidth=2, markersize=5)\n",
    "    ax1.axhline(y=total_nodes * 0.9, color='r', linestyle='--', \n",
    "                label=f'Ng∆∞·ª°ng 10% ({int(total_nodes * 0.1)} nodes)')\n",
    "    ax1.fill_between(cycles, 0, alive_nodes, alpha=0.3, color='blue')\n",
    "    \n",
    "    # ƒê√°nh d·∫•u c√°c chu k·ª≥ ph√¢n c·ª•m l·∫°i\n",
    "    for rc in reclustered_cycles:\n",
    "        ax1.axvline(x=rc, color='orange', alpha=0.3, linestyle=':')\n",
    "    \n",
    "    ax1.set_xlabel('Chu k·ª≥', fontsize=11)\n",
    "    ax1.set_ylabel('S·ªë node s·ªëng', fontsize=11)\n",
    "    ax1.set_title('S·ªë node s·ªëng theo th·ªùi gian', fontsize=13, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.legend()\n",
    "    ax1.set_ylim(bottom=0, top=total_nodes * 1.1)\n",
    "    \n",
    "    # Bi·ªÉu ƒë·ªì 2: S·ªë node ch·∫øt t√≠ch l≈©y\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax2.plot(cycles, cumulative_dead, 'r-s', linewidth=2, markersize=5)\n",
    "    ax2.fill_between(cycles, 0, cumulative_dead, alpha=0.3, color='red')\n",
    "    ax2.set_xlabel('Chu k·ª≥', fontsize=11)\n",
    "    ax2.set_ylabel('S·ªë node ch·∫øt (t√≠ch l≈©y)', fontsize=11)\n",
    "    ax2.set_title('S·ªë node ch·∫øt t√≠ch l≈©y theo th·ªùi gian', fontsize=13, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_ylim(bottom=0)\n",
    "    \n",
    "    if first_death_cycle:\n",
    "        ax2.axvline(x=first_death_cycle, color='orange', linestyle='--', linewidth=2,\n",
    "                   label=f'Chu k·ª≥ ƒë·∫ßu ti√™n: {first_death_cycle}')\n",
    "        ax2.legend()\n",
    "    \n",
    "    # Bi·ªÉu ƒë·ªì 3: T·ªïng nƒÉng l∆∞·ª£ng m·∫°ng\n",
    "    ax3 = fig.add_subplot(gs[1, 0])\n",
    "    ax3.plot(cycles, total_energy_remaining, 'g-^', linewidth=2, markersize=5)\n",
    "    ax3.fill_between(cycles, 0, total_energy_remaining, alpha=0.3, color='green')\n",
    "    ax3.set_xlabel('Chu k·ª≥', fontsize=11)\n",
    "    ax3.set_ylabel('T·ªïng nƒÉng l∆∞·ª£ng c√≤n l·∫°i (J)', fontsize=11)\n",
    "    ax3.set_title('NƒÉng l∆∞·ª£ng t·ªïng th·ªÉ m·∫°ng', fontsize=13, fontweight='bold')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.set_ylim(bottom=0)\n",
    "    \n",
    "    # Bi·ªÉu ƒë·ªì 4: Th·ªùi gian di chuy·ªÉn AUV\n",
    "    ax4 = fig.add_subplot(gs[1, 1])\n",
    "    ax4.plot(cycles, travel_times, 'm-d', linewidth=2, markersize=5)\n",
    "    ax4.set_xlabel('Chu k·ª≥', fontsize=11)\n",
    "    ax4.set_ylabel('Th·ªùi gian di chuy·ªÉn (s)', fontsize=11)\n",
    "    ax4.set_title('Th·ªùi gian chu k·ª≥ AUV', fontsize=13, fontweight='bold')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    if len(travel_times) > 0:\n",
    "        avg_time = np.mean(travel_times)\n",
    "        ax4.axhline(y=avg_time, color='r', linestyle='--', linewidth=2,\n",
    "                   label=f'Trung b√¨nh: {avg_time:.2f}s')\n",
    "        ax4.legend()\n",
    "    \n",
    "    # Bi·ªÉu ƒë·ªì 5: S·ªë c·ª•m theo chu k·ª≥\n",
    "    ax5 = fig.add_subplot(gs[2, 0])\n",
    "    ax5.plot(cycles, num_clusters, 'c-o', linewidth=2, markersize=5)\n",
    "    ax5.fill_between(cycles, 0, num_clusters, alpha=0.3, color='cyan')\n",
    "    \n",
    "    # ƒê√°nh d·∫•u c√°c chu k·ª≥ ph√¢n c·ª•m l·∫°i\n",
    "    for rc in reclustered_cycles:\n",
    "        ax5.axvline(x=rc, color='red', alpha=0.5, linestyle='--', linewidth=1.5)\n",
    "    \n",
    "    ax5.set_xlabel('Chu k·ª≥', fontsize=11)\n",
    "    ax5.set_ylabel('S·ªë c·ª•m', fontsize=11)\n",
    "    ax5.set_title('S·ªë c·ª•m theo chu k·ª≥ (ƒë·ªè: ph√¢n c·ª•m l·∫°i)', fontsize=13, fontweight='bold')\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    ax5.set_ylim(bottom=0)\n",
    "    \n",
    "    # Bi·ªÉu ƒë·ªì 6: Th·ªëng k√™ t·ªïng h·ª£p\n",
    "    ax6 = fig.add_subplot(gs[2, 1])\n",
    "    ax6.axis('off')\n",
    "    \n",
    "    # T√≠nh to√°n c√°c th·ªëng k√™\n",
    "    total_cycles = len(outputs)\n",
    "    total_time = outputs[-1]['cumulative_time']\n",
    "    avg_cycle_time = np.mean(travel_times)\n",
    "    total_deaths = total_nodes - alive_nodes[-1]\n",
    "    survival_rate = (alive_nodes[-1] / total_nodes) * 100\n",
    "    reclustering_count = len(reclustered_cycles)\n",
    "    \n",
    "    stats_text = f\"\"\"\n",
    "    TH·ªêNG K√ä T·ªîNG H·ª¢P\n",
    "    {'‚îÄ' * 40}\n",
    "    \n",
    "    T·ªïng s·ªë chu k·ª≥: {total_cycles}\n",
    "    T·ªïng th·ªùi gian: {total_time:.2f}s ({total_time/3600:.2f} gi·ªù)\n",
    "    Th·ªùi gian TB/chu k·ª≥: {avg_cycle_time:.2f}s\n",
    "    \n",
    "    Node ban ƒë·∫ßu: {total_nodes}\n",
    "    Node c√≤n s·ªëng: {alive_nodes[-1]}\n",
    "    Node ƒë√£ ch·∫øt: {total_deaths}\n",
    "    T·ª∑ l·ªá s·ªëng s√≥t: {survival_rate:.2f}%\n",
    "    \n",
    "    Chu k·ª≥ ch·∫øt ƒë·∫ßu ti√™n: {first_death_cycle if first_death_cycle else 'N/A'}\n",
    "    \n",
    "    S·ªë l·∫ßn ph√¢n c·ª•m l·∫°i: {reclustering_count}\n",
    "    T·ª∑ l·ªá ph√¢n c·ª•m l·∫°i: {(reclustering_count/total_cycles)*100:.1f}%\n",
    "    \n",
    "    S·ªë c·ª•m trung b√¨nh: {np.mean(num_clusters):.1f}\n",
    "    S·ªë c·ª•m min/max: {np.min(num_clusters)}/{np.max(num_clusters)}\n",
    "    \n",
    "    Th·ªùi gian chu k·ª≥ min: {np.min(travel_times):.2f}s\n",
    "    Th·ªùi gian chu k·ª≥ max: {np.max(travel_times):.2f}s\n",
    "    ƒê·ªô l·ªách chu·∫©n: {np.std(travel_times):.2f}s\n",
    "    \"\"\"\n",
    "    \n",
    "    ax6.text(0.1, 0.5, stats_text, fontsize=11, family='monospace',\n",
    "             verticalalignment='center', bbox=dict(boxstyle='round', \n",
    "             facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    # L∆∞u bi·ªÉu ƒë·ªì t·ªïng h·ª£p\n",
    "    final_chart_filename = os.path.join(output_dir, \n",
    "                                        f\"final_analysis_{os.path.splitext(filename)[0]}.png\")\n",
    "    plt.savefig(final_chart_filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return final_chart_filename\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
